{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Skin-Cancer-Diagnosis/blob/main/Skin_Cancer_Diagnosis_using_ISIC_2018_Dataset_Class_Weight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUusDE1Z9TNb"
      },
      "source": [
        "Prepare the dataset. \n",
        "Currently, we use skin cancer ISIC dataset from Kaggle https://www.kaggle.com/datasets/nodoubttome/skin-cancer9-classesisic\n",
        "\n",
        "Tutorial for how to load Kaggle dataset can be found in https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "9f59ff14-0a45-4f80-a990-247d5cb10457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR2MJBYq-oiB",
        "outputId": "e8a47192-291a-43fa-bf3d-403b2d36d117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "!pip install imbalanced-learn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3mnEebdJH6Ex"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "num_classes = 7\n",
        "#df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aFSe3uekK67v"
      },
      "outputs": [],
      "source": [
        "#decode one hot label\n",
        "df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "#drop one-hot column\n",
        "df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "#make filepaths of the image\n",
        "dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38f3dgvyBqFM"
      },
      "source": [
        "Label Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2IncA-_o_n5w",
        "outputId": "4e036df6-9a81-4e99-d5a4-3bb2dbafcc1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'DF'),\n",
              " Text(0, 0, 'VASC'),\n",
              " Text(0, 0, 'AKIEC'),\n",
              " Text(0, 0, 'BCC'),\n",
              " Text(0, 0, 'BKL'),\n",
              " Text(0, 0, 'MEL'),\n",
              " Text(0, 0, 'NV')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = df_train['Labels'].value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(row['Labels'] == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df_train['Labels'].unique())\n",
        "#for label in labels:\n",
        "#    plot_images_per_label(df_train, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "df_train = df_train.drop_duplicates(subset=['lesion_id'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKjC59JOB_6d"
      },
      "source": [
        "Prepare X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 128\n",
        "IMAGE_H = 128\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3jyCpXnlFoQK"
      },
      "outputs": [],
      "source": [
        "#TIME CONSUMING OPERATION\n",
        "#from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "#X = []\n",
        "#for img in df['FilePaths']:\n",
        "    #img_arr = load_img(img, target_size=IMG_SIZE)\n",
        "#    with load_img(img, target_size=IMG_SIZE) as img_arr:\n",
        "#      X.append(img_to_array(img_arr))\n",
        "\n",
        "#X = np.array(X)\n",
        "df_train['image'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "df_val['image'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UZyZMydSgvZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3270acca-2838-464d-af85-572a2b0d856e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7470, 128, 128, 3)\n",
            "(193, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "X_train = np.asarray(df_train['image'].tolist())\n",
        "X_val = np.asarray(df_val['image'].tolist())\n",
        "print(np.array(X_train).shape)\n",
        "print(np.array(X_val).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RAxUkXy8ueYG"
      },
      "outputs": [],
      "source": [
        "#Normalization\n",
        "#X_train_mean = np.mean(X_train)\n",
        "#X_train_std = np.std(X_train)\n",
        "\n",
        "#X_train = (X_train - X_train_mean)/X_train_std\n",
        "#X_val = (X_val - X_train_mean)/X_train_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uqYLmicGAjZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c383d8a-4cec-4449-9e6a-269c6e94d096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'NV': 5403, 'BKL': 727, 'MEL': 614, 'BCC': 327, 'AKIEC': 228, 'VASC': 98, 'DF': 73})\n",
            "(7470,)\n"
          ]
        }
      ],
      "source": [
        "y_train = np.array(df_train['Labels'].values)\n",
        "\n",
        "# summarize class distribution\n",
        "from collections import Counter\n",
        "counter = Counter(y_train)\n",
        "print(counter)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kEuVIGc3g859",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a07bd2f-3ea8-405b-8629-6bc50c903250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'NV': 123, 'BKL': 22, 'MEL': 21, 'BCC': 15, 'AKIEC': 8, 'VASC': 3, 'DF': 1})\n",
            "(193,)\n"
          ]
        }
      ],
      "source": [
        "y_val = np.array(df_val['Labels'].values)\n",
        "print(Counter(y_val))\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QfvEVGIQhIr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927c4f1f-97bf-4ee5-df1d-09abc339a5cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, ..., 5, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#label encoding\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_val = label_encoder.fit_transform(y_val)\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                 classes=np.unique(y_train),\n",
        "                                                 y=y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLHRj-xqk98R",
        "outputId": "472aa5c8-5a0f-402a-8ae3-a6b7c2191174"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.68045113,  3.26343381,  1.46787188, 14.6183953 ,  1.73801768,\n",
              "        0.19750932, 10.88921283])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = {i : class_weights[i] for i in range(7)}"
      ],
      "metadata": {
        "id": "EAIOkkQogqZI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8Jc9A3IgwHS",
        "outputId": "1f99f31d-edb3-4c0d-b664-ed690b326ffb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 4.680451127819549,\n",
              " 1: 3.2634338138925294,\n",
              " 2: 1.467871880526626,\n",
              " 3: 14.61839530332681,\n",
              " 4: 1.7380176826430898,\n",
              " 5: 0.197509320218926,\n",
              " 6: 10.889212827988338}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZv-B-ygCD57"
      },
      "source": [
        "#SMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RDskF1wjGffh"
      },
      "outputs": [],
      "source": [
        "def SMOTE_Data(X, y):\n",
        "  sm = SMOTE(random_state=42, k_neighbors=6)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, IMAGE_W * IMAGE_H * 3)), y)\n",
        "  X_resampled.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brshqGvOCDJL",
        "outputId": "da9a2f74-bf60-483a-e30d-fbffc3df885f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37821, 49152)\n",
            "(37821,)\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train) #beware of the actual parameter\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GfOtcbV5vVZ",
        "outputId": "487a7fd6-dc53-4ae0-b489-cd90351f0f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({5: 5403, 4: 5403, 2: 5403, 3: 5403, 0: 5403, 1: 5403, 6: 5403})\n"
          ]
        }
      ],
      "source": [
        "counter = Counter(y_train)\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl-nmACZOZpg",
        "outputId": "4fb5daa4-29e8-4f2e-8f5f-de02f92218f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (37821, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "print('X_train shape: ',X_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi8RRUWEBD3s",
        "outputId": "4451daeb-0165-40d7-b76a-c4c90fcbe1fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4986, 32, 32, 3)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-Xqj-WQ90L_"
      },
      "outputs": [],
      "source": [
        "#optional\n",
        "X=X_train\n",
        "y=y_train\n",
        "\n",
        "from numpy import moveaxis\n",
        "dec_x = moveaxis(X, 3, 1)\n",
        "dec_x = dec_x.astype('float32') / 255.\n",
        "#dec_x = X_train \n",
        "dec_y = y\n",
        "\n",
        "#create counter for encoder\n",
        "counter = sorted(counter.items())\n",
        "counter = [value for _, value in counter]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kMMmX7r-fV5",
        "outputId": "d3648cdf-7d3e-4255-d712-dec90b542d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(torch.version.cuda) #10.1\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "\n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "\n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 1000       # how many epochs to run for\n",
        "args['batch_size'] = 12   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "\n",
        "args['patience'] = 20\n",
        "\n",
        "## create encoder model and decoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            \n",
        "            #nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),\n",
        "            \n",
        "            #3d and 32 by 32\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 1, 0, bias=False),\n",
        "            \n",
        "            nn.BatchNorm2d(self.dim_h * 8), # 40 X 8 = 320\n",
        "            #nn.ReLU(True),\n",
        "            nn.LeakyReLU(0.2, inplace=True) )#,\n",
        "            #nn.Conv2d(self.dim_h * 8, 1, 2, 1, 0, bias=False))\n",
        "            #nn.Conv2d(self.dim_h * 8, 1, 4, 1, 0, bias=False))\n",
        "        # final layer is fully connected\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('enc')\n",
        "        #print('input ',x.size()) #torch.Size([100, 3,32,32])\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        #print('aft squeeze ',x.size()) #torch.Size([128, 320])\n",
        "        #aft squeeze  torch.Size([100, 320])\n",
        "        x = self.fc(x)\n",
        "        #print('out ',x.size()) #torch.Size([128, 20])\n",
        "        #out  torch.Size([100, 300])\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**4 * 8 * 8),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 16, self.dim_h * 8, 4),\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, 3, 4, stride=2, padding=2),\n",
        "            #nn.Sigmoid())\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('dec')\n",
        "        #print('input ',x.size())\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**4, 8, 8)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"functions to create SMOTE images\"\"\"\n",
        "\n",
        "def biased_get_class(c):\n",
        "    \n",
        "    xbeg = dec_x[dec_y == c]\n",
        "    ybeg = dec_y[dec_y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "\n",
        "    # determining the number of samples to generate\n",
        "    #n_to_sample = 10 \n",
        "\n",
        "    # fitting the model\n",
        "    n_neigh = 5 + 1\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "#xsamp, ysamp = SM(xclass,yclass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHtLISURIMTg",
        "outputId": "233e5edf-bf0b-46f0-8bfd-f436597063bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Epoch: 0 \tTrain Loss: 0.460336 \tmse loss: 0.240478 \tmse2 loss: 0.219858\n",
            "Saving..\n",
            "Epoch: 1 \tTrain Loss: 0.135306 \tmse loss: 0.070629 \tmse2 loss: 0.064677\n",
            "Saving..\n",
            "Epoch: 2 \tTrain Loss: 0.109741 \tmse loss: 0.058832 \tmse2 loss: 0.050909\n",
            "Saving..\n",
            "Epoch: 3 \tTrain Loss: 0.095568 \tmse loss: 0.049689 \tmse2 loss: 0.045879\n",
            "Saving..\n",
            "Epoch: 4 \tTrain Loss: 0.085469 \tmse loss: 0.045838 \tmse2 loss: 0.039631\n",
            "Saving..\n",
            "Epoch: 5 \tTrain Loss: 0.078804 \tmse loss: 0.043548 \tmse2 loss: 0.035256\n",
            "Saving..\n",
            "Epoch: 6 \tTrain Loss: 0.075646 \tmse loss: 0.041972 \tmse2 loss: 0.033674\n",
            "Saving..\n",
            "Epoch: 7 \tTrain Loss: 0.073979 \tmse loss: 0.040878 \tmse2 loss: 0.033101\n",
            "Saving..\n",
            "Epoch: 8 \tTrain Loss: 0.065938 \tmse loss: 0.037266 \tmse2 loss: 0.028672\n",
            "Saving..\n",
            "Epoch: 9 \tTrain Loss: 0.061393 \tmse loss: 0.035039 \tmse2 loss: 0.026353\n",
            "Saving..\n",
            "Epoch: 10 \tTrain Loss: 0.060747 \tmse loss: 0.034673 \tmse2 loss: 0.026074\n",
            "Saving..\n",
            "Epoch: 11 \tTrain Loss: 0.057085 \tmse loss: 0.032988 \tmse2 loss: 0.024097\n",
            "Saving..\n",
            "Epoch: 12 \tTrain Loss: 0.054603 \tmse loss: 0.032039 \tmse2 loss: 0.022565\n",
            "Saving..\n",
            "Epoch: 13 \tTrain Loss: 0.050429 \tmse loss: 0.029791 \tmse2 loss: 0.020638\n",
            "Saving..\n",
            "Epoch: 14 \tTrain Loss: 0.046142 \tmse loss: 0.027602 \tmse2 loss: 0.018541\n",
            "Saving..\n",
            "Epoch: 15 \tTrain Loss: 0.046039 \tmse loss: 0.027895 \tmse2 loss: 0.018143\n",
            "Saving..\n",
            "Epoch: 16 \tTrain Loss: 0.043569 \tmse loss: 0.026308 \tmse2 loss: 0.017261\n",
            "Saving..\n",
            "Epoch: 17 \tTrain Loss: 0.043104 \tmse loss: 0.026006 \tmse2 loss: 0.017098\n",
            "Saving..\n",
            "Epoch: 18 \tTrain Loss: 0.040572 \tmse loss: 0.024558 \tmse2 loss: 0.016013\n",
            "Saving..\n",
            "Epoch: 19 \tTrain Loss: 0.038300 \tmse loss: 0.023391 \tmse2 loss: 0.014909\n",
            "Saving..\n",
            "Epoch: 20 \tTrain Loss: 0.036967 \tmse loss: 0.022767 \tmse2 loss: 0.014200\n",
            "Saving..\n",
            "Epoch: 21 \tTrain Loss: 0.036967 \tmse loss: 0.022921 \tmse2 loss: 0.014046\n",
            "Epoch: 22 \tTrain Loss: 0.035027 \tmse loss: 0.021855 \tmse2 loss: 0.013172\n",
            "Saving..\n",
            "Epoch: 23 \tTrain Loss: 0.033657 \tmse loss: 0.021259 \tmse2 loss: 0.012399\n",
            "Saving..\n",
            "Epoch: 24 \tTrain Loss: 0.032991 \tmse loss: 0.020740 \tmse2 loss: 0.012252\n",
            "Saving..\n",
            "Epoch: 25 \tTrain Loss: 0.031015 \tmse loss: 0.019649 \tmse2 loss: 0.011366\n",
            "Saving..\n",
            "Epoch: 26 \tTrain Loss: 0.030275 \tmse loss: 0.019245 \tmse2 loss: 0.011030\n",
            "Saving..\n",
            "Epoch: 27 \tTrain Loss: 0.029004 \tmse loss: 0.018351 \tmse2 loss: 0.010652\n",
            "Saving..\n",
            "Epoch: 28 \tTrain Loss: 0.028609 \tmse loss: 0.018064 \tmse2 loss: 0.010545\n",
            "Saving..\n",
            "Epoch: 29 \tTrain Loss: 0.027706 \tmse loss: 0.017893 \tmse2 loss: 0.009813\n",
            "Saving..\n",
            "Epoch: 30 \tTrain Loss: 0.025469 \tmse loss: 0.016538 \tmse2 loss: 0.008932\n",
            "Saving..\n",
            "Epoch: 31 \tTrain Loss: 0.026071 \tmse loss: 0.016664 \tmse2 loss: 0.009408\n",
            "Epoch: 32 \tTrain Loss: 0.025624 \tmse loss: 0.016482 \tmse2 loss: 0.009142\n",
            "Epoch: 33 \tTrain Loss: 0.024203 \tmse loss: 0.015747 \tmse2 loss: 0.008456\n",
            "Saving..\n",
            "Epoch: 34 \tTrain Loss: 0.024451 \tmse loss: 0.015649 \tmse2 loss: 0.008803\n",
            "Epoch: 35 \tTrain Loss: 0.023914 \tmse loss: 0.015583 \tmse2 loss: 0.008331\n",
            "Saving..\n",
            "Epoch: 36 \tTrain Loss: 0.021918 \tmse loss: 0.014221 \tmse2 loss: 0.007696\n",
            "Saving..\n",
            "Epoch: 37 \tTrain Loss: 0.022003 \tmse loss: 0.014464 \tmse2 loss: 0.007538\n",
            "Epoch: 38 \tTrain Loss: 0.021623 \tmse loss: 0.014253 \tmse2 loss: 0.007370\n",
            "Saving..\n",
            "Epoch: 39 \tTrain Loss: 0.021462 \tmse loss: 0.013977 \tmse2 loss: 0.007485\n",
            "Saving..\n",
            "Epoch: 40 \tTrain Loss: 0.021446 \tmse loss: 0.014052 \tmse2 loss: 0.007394\n",
            "Saving..\n",
            "Epoch: 41 \tTrain Loss: 0.019796 \tmse loss: 0.013020 \tmse2 loss: 0.006776\n",
            "Saving..\n",
            "Epoch: 42 \tTrain Loss: 0.019911 \tmse loss: 0.013204 \tmse2 loss: 0.006707\n",
            "Epoch: 43 \tTrain Loss: 0.020062 \tmse loss: 0.013419 \tmse2 loss: 0.006643\n",
            "Epoch: 44 \tTrain Loss: 0.019150 \tmse loss: 0.012785 \tmse2 loss: 0.006364\n",
            "Saving..\n",
            "Epoch: 45 \tTrain Loss: 0.018729 \tmse loss: 0.012455 \tmse2 loss: 0.006274\n",
            "Saving..\n",
            "Epoch: 46 \tTrain Loss: 0.019136 \tmse loss: 0.012741 \tmse2 loss: 0.006395\n",
            "Epoch: 47 \tTrain Loss: 0.017625 \tmse loss: 0.011815 \tmse2 loss: 0.005809\n",
            "Saving..\n",
            "Epoch: 48 \tTrain Loss: 0.018012 \tmse loss: 0.012037 \tmse2 loss: 0.005975\n",
            "Epoch: 49 \tTrain Loss: 0.017280 \tmse loss: 0.011525 \tmse2 loss: 0.005755\n",
            "Saving..\n",
            "Epoch: 50 \tTrain Loss: 0.017411 \tmse loss: 0.011715 \tmse2 loss: 0.005696\n",
            "Epoch: 51 \tTrain Loss: 0.017844 \tmse loss: 0.011775 \tmse2 loss: 0.006069\n",
            "Epoch: 52 \tTrain Loss: 0.016566 \tmse loss: 0.011062 \tmse2 loss: 0.005504\n",
            "Saving..\n",
            "Epoch: 53 \tTrain Loss: 0.016378 \tmse loss: 0.010894 \tmse2 loss: 0.005484\n",
            "Saving..\n",
            "Epoch: 54 \tTrain Loss: 0.017184 \tmse loss: 0.011550 \tmse2 loss: 0.005633\n",
            "Epoch: 55 \tTrain Loss: 0.015793 \tmse loss: 0.010701 \tmse2 loss: 0.005092\n",
            "Saving..\n",
            "Epoch: 56 \tTrain Loss: 0.015438 \tmse loss: 0.010300 \tmse2 loss: 0.005138\n",
            "Saving..\n",
            "Epoch: 57 \tTrain Loss: 0.016157 \tmse loss: 0.010662 \tmse2 loss: 0.005495\n",
            "Epoch: 58 \tTrain Loss: 0.015244 \tmse loss: 0.010235 \tmse2 loss: 0.005009\n",
            "Saving..\n",
            "Epoch: 59 \tTrain Loss: 0.014930 \tmse loss: 0.010095 \tmse2 loss: 0.004835\n",
            "Saving..\n",
            "Epoch: 60 \tTrain Loss: 0.015409 \tmse loss: 0.010347 \tmse2 loss: 0.005062\n",
            "Epoch: 61 \tTrain Loss: 0.015219 \tmse loss: 0.010300 \tmse2 loss: 0.004919\n",
            "Epoch: 62 \tTrain Loss: 0.014006 \tmse loss: 0.009613 \tmse2 loss: 0.004393\n",
            "Saving..\n",
            "Epoch: 63 \tTrain Loss: 0.014490 \tmse loss: 0.009821 \tmse2 loss: 0.004669\n",
            "Epoch: 64 \tTrain Loss: 0.014394 \tmse loss: 0.009778 \tmse2 loss: 0.004616\n",
            "Epoch: 65 \tTrain Loss: 0.014505 \tmse loss: 0.009847 \tmse2 loss: 0.004658\n",
            "Epoch: 66 \tTrain Loss: 0.014208 \tmse loss: 0.009588 \tmse2 loss: 0.004620\n",
            "Epoch: 67 \tTrain Loss: 0.013376 \tmse loss: 0.009139 \tmse2 loss: 0.004237\n",
            "Saving..\n",
            "Epoch: 68 \tTrain Loss: 0.013505 \tmse loss: 0.009141 \tmse2 loss: 0.004364\n",
            "Epoch: 69 \tTrain Loss: 0.013663 \tmse loss: 0.009328 \tmse2 loss: 0.004335\n",
            "Epoch: 70 \tTrain Loss: 0.013582 \tmse loss: 0.009176 \tmse2 loss: 0.004407\n",
            "Epoch: 71 \tTrain Loss: 0.013027 \tmse loss: 0.008761 \tmse2 loss: 0.004266\n",
            "Saving..\n",
            "Epoch: 72 \tTrain Loss: 0.012496 \tmse loss: 0.008503 \tmse2 loss: 0.003993\n",
            "Saving..\n",
            "Epoch: 73 \tTrain Loss: 0.012871 \tmse loss: 0.008745 \tmse2 loss: 0.004126\n",
            "Epoch: 74 \tTrain Loss: 0.012556 \tmse loss: 0.008532 \tmse2 loss: 0.004024\n",
            "Epoch: 75 \tTrain Loss: 0.013121 \tmse loss: 0.008932 \tmse2 loss: 0.004188\n",
            "Epoch: 76 \tTrain Loss: 0.012304 \tmse loss: 0.008359 \tmse2 loss: 0.003945\n",
            "Saving..\n",
            "Epoch: 77 \tTrain Loss: 0.011884 \tmse loss: 0.008084 \tmse2 loss: 0.003800\n",
            "Saving..\n",
            "Epoch: 78 \tTrain Loss: 0.012064 \tmse loss: 0.008280 \tmse2 loss: 0.003783\n",
            "Epoch: 79 \tTrain Loss: 0.012178 \tmse loss: 0.008239 \tmse2 loss: 0.003939\n",
            "Epoch: 80 \tTrain Loss: 0.012322 \tmse loss: 0.008342 \tmse2 loss: 0.003980\n",
            "Epoch: 81 \tTrain Loss: 0.012100 \tmse loss: 0.008222 \tmse2 loss: 0.003878\n",
            "Epoch: 82 \tTrain Loss: 0.011397 \tmse loss: 0.007763 \tmse2 loss: 0.003634\n",
            "Saving..\n",
            "Epoch: 83 \tTrain Loss: 0.011462 \tmse loss: 0.007844 \tmse2 loss: 0.003618\n",
            "Epoch: 84 \tTrain Loss: 0.012527 \tmse loss: 0.008553 \tmse2 loss: 0.003975\n",
            "Epoch: 85 \tTrain Loss: 0.011341 \tmse loss: 0.007850 \tmse2 loss: 0.003490\n",
            "Saving..\n",
            "Epoch: 86 \tTrain Loss: 0.010976 \tmse loss: 0.007601 \tmse2 loss: 0.003375\n",
            "Saving..\n",
            "Epoch: 87 \tTrain Loss: 0.010960 \tmse loss: 0.007536 \tmse2 loss: 0.003424\n",
            "Saving..\n",
            "Epoch: 88 \tTrain Loss: 0.010934 \tmse loss: 0.007500 \tmse2 loss: 0.003434\n",
            "Saving..\n",
            "Epoch: 89 \tTrain Loss: 0.010952 \tmse loss: 0.007504 \tmse2 loss: 0.003448\n",
            "Epoch: 90 \tTrain Loss: 0.010898 \tmse loss: 0.007466 \tmse2 loss: 0.003432\n",
            "Saving..\n",
            "Epoch: 91 \tTrain Loss: 0.010589 \tmse loss: 0.007292 \tmse2 loss: 0.003296\n",
            "Saving..\n",
            "Epoch: 92 \tTrain Loss: 0.010472 \tmse loss: 0.007210 \tmse2 loss: 0.003261\n",
            "Saving..\n",
            "Epoch: 93 \tTrain Loss: 0.010358 \tmse loss: 0.007162 \tmse2 loss: 0.003197\n",
            "Saving..\n",
            "Epoch: 94 \tTrain Loss: 0.010446 \tmse loss: 0.007190 \tmse2 loss: 0.003256\n",
            "Epoch: 95 \tTrain Loss: 0.010558 \tmse loss: 0.007315 \tmse2 loss: 0.003243\n",
            "Epoch: 96 \tTrain Loss: 0.010062 \tmse loss: 0.006993 \tmse2 loss: 0.003069\n",
            "Saving..\n",
            "Epoch: 97 \tTrain Loss: 0.010361 \tmse loss: 0.007120 \tmse2 loss: 0.003241\n",
            "Epoch: 98 \tTrain Loss: 0.011163 \tmse loss: 0.007587 \tmse2 loss: 0.003575\n",
            "Epoch: 99 \tTrain Loss: 0.010155 \tmse loss: 0.007001 \tmse2 loss: 0.003154\n",
            "/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_enc.pth\n",
            "/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_dec.pth\n"
          ]
        }
      ],
      "source": [
        "#Begin the training\n",
        "batch_size = args['batch_size']\n",
        "patience = args['patience']\n",
        "encoder = Encoder(args)\n",
        "decoder = Decoder(args)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "decoder = decoder.to(device)\n",
        "encoder = encoder.to(device)\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "#decoder loss function\n",
        "criterion = nn.MSELoss()\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "num_workers = 0\n",
        "\n",
        "#torch.Tensor returns float so if want long then use torch.tensor\n",
        "tensor_x = torch.Tensor(dec_x)\n",
        "tensor_y = torch.tensor(dec_y,dtype=torch.long)\n",
        "mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "    batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "t0 = time.time()\n",
        "if args['train']:\n",
        "    enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "    dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "    for epoch in range(args['epochs']):\n",
        "        train_loss = 0.0\n",
        "        tmse_loss = 0.0\n",
        "        tdiscr_loss = 0.0\n",
        "        # train for one epoch -- set nets to train mode\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "    \n",
        "        for images,labs in train_loader:\n",
        "        \n",
        "            # zero gradients for each batch\n",
        "            encoder.zero_grad()\n",
        "            decoder.zero_grad()\n",
        "            images, labs = images.to(device), labs.to(device)\n",
        "            labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "            # run images\n",
        "            z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "        \n",
        "            x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "            mse = criterion(x_hat,images)\n",
        "                    \n",
        "            resx = []\n",
        "            resy = []\n",
        "        \n",
        "            tc = np.random.choice(num_classes,1)\n",
        "            #tc = 9\n",
        "            xbeg = dec_x[dec_y == tc]\n",
        "            ybeg = dec_y[dec_y == tc] \n",
        "            xlen = len(xbeg)\n",
        "            nsamp = min(xlen, 100)\n",
        "            ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "            xclass = xbeg[ind]\n",
        "            yclass = ybeg[ind]\n",
        "        \n",
        "            xclen = len(xclass)\n",
        "            xcminus = np.arange(1,xclen)\n",
        "            \n",
        "            xcplus = np.append(xcminus,0)\n",
        "            xcnew = (xclass[[xcplus],:])\n",
        "            xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "        \n",
        "            xcnew = torch.Tensor(xcnew)\n",
        "            xcnew = xcnew.to(device)\n",
        "        \n",
        "            #encode xclass to feature space\n",
        "            xclass = torch.Tensor(xclass)\n",
        "            xclass = xclass.to(device)\n",
        "            xclass = encoder(xclass)\n",
        "        \n",
        "            xclass = xclass.detach().cpu().numpy()\n",
        "        \n",
        "            xc_enc = (xclass[[xcplus],:])\n",
        "            xc_enc = np.squeeze(xc_enc)\n",
        "        \n",
        "            xc_enc = torch.Tensor(xc_enc)\n",
        "            xc_enc = xc_enc.to(device)\n",
        "            \n",
        "            ximg = decoder(xc_enc)\n",
        "            \n",
        "            mse2 = criterion(ximg,xcnew)\n",
        "        \n",
        "            comb_loss = mse2 + mse\n",
        "            comb_loss.backward()\n",
        "        \n",
        "            enc_optim.step()\n",
        "            dec_optim.step()\n",
        "        \n",
        "            train_loss += comb_loss.item()*images.size(0)\n",
        "            tmse_loss += mse.item()*images.size(0)\n",
        "            tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "        train_loss = train_loss/len(train_loader)\n",
        "        tmse_loss = tmse_loss/len(train_loader)\n",
        "        tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "        print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "                train_loss,tmse_loss,tdiscr_loss))\n",
        "        \n",
        "    \n",
        "    \n",
        "        #store the best encoder and decoder models\n",
        "        #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "        #necessary for illustration purposes\n",
        "        if train_loss < best_loss:\n",
        "            print('Saving..')\n",
        "            patience = args['patience']\n",
        "            path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/bst_enc.pth'\n",
        "            path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/bst_dec.pth'\n",
        "          \n",
        "            torch.save(encoder.state_dict(), path_enc)\n",
        "            torch.save(decoder.state_dict(), path_dec)\n",
        "    \n",
        "            best_loss = train_loss\n",
        "        else:\n",
        "            patience -= 1\n",
        "\n",
        "        if patience == 0:\n",
        "            print('Out of patience. \\n')\n",
        "            break\n",
        "    \n",
        "    \n",
        "    #in addition, store the final model (may not be the best) for\n",
        "    #informational purposes\n",
        "    path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_enc.pth'\n",
        "    path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_dec.pth'\n",
        "    print(path_enc)\n",
        "    print(path_dec)\n",
        "    torch.save(encoder.state_dict(), path_enc)\n",
        "    torch.save(decoder.state_dict(), path_dec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoqPIVKqF5Ug",
        "outputId": "5e2d2d09-4032-4d5e-c744-70f5fe20b6fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train imgs shape  (4986, 3, 32, 32)\n",
            "decy  (4986,)\n",
            "(11732, 3072)\n",
            "(11732,)\n"
          ]
        }
      ],
      "source": [
        "#Generate artificial images\n",
        "import torch\n",
        "np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "#path on the computer where the models are stored\n",
        "modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/'\n",
        "\n",
        "encf = []\n",
        "decf = []\n",
        "for p in range(1):\n",
        "    enc = modpth + '/bst_enc.pth'\n",
        "    dec = modpth + '/bst_dec.pth'\n",
        "    encf.append(enc)\n",
        "    decf.append(dec)\n",
        "\n",
        "for m in range(1):\n",
        "    print('train imgs shape ',dec_x.shape) #(45000,3,32,32)\n",
        "    print('decy ',dec_y.shape)\n",
        "    \n",
        "    #generate some images \n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    path_enc = encf[m]\n",
        "    path_dec = decf[m]\n",
        "\n",
        "    encoder = Encoder(args)\n",
        "    encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "    encoder = encoder.to(device)\n",
        "\n",
        "    decoder = Decoder(args)\n",
        "    decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "    decoder = decoder.to(device)\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    imbal = counter#[114, 376, 95, 438, 357, 462, 77, 181, 139]\n",
        "\n",
        "    resx = []\n",
        "    resy = []\n",
        "\n",
        "    for i in [0,1,2,3,4,6]: #skip class 5 since it's max class\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        xclass, yclass = biased_get_class(i)\n",
        "#        print(xclass.shape) #(500, 3, 32, 32)\n",
        "#        print(yclass[0]) #(500,)\n",
        "            \n",
        "        #encode xclass to feature space\n",
        "        xclass = torch.Tensor(xclass)\n",
        "        xclass = xclass.to(device)\n",
        "        xclass = encoder(xclass)\n",
        "            \n",
        "        xclass = xclass.detach().cpu().numpy()\n",
        "        n = imbal[5] - imbal[i]\n",
        "        xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "#        print(xsamp.shape) #(4500, 600)\n",
        "#        print(len(ysamp)) #4500\n",
        "        ysamp = np.array(ysamp)\n",
        "    \n",
        "        \"\"\"to generate samples for resnet\"\"\"   \n",
        "        xsamp = torch.Tensor(xsamp)\n",
        "        xsamp = xsamp.to(device)\n",
        "        ximg = decoder(xsamp)\n",
        "\n",
        "        ximn = ximg.detach().cpu().numpy()\n",
        "#        print(ximn.shape) \n",
        "        resx.append(ximn)\n",
        "        resy.append(ysamp)\n",
        "    \n",
        "    resx1 = np.vstack(resx)\n",
        "    resy1 = np.hstack(resy)\n",
        "#    print(resx1.shape) #(34720, 3, 32, 32)\n",
        "\n",
        "    resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "#    print(resx1.shape) #(34720, 3072)\n",
        "    \n",
        "    dec_x1 = dec_x.reshape(dec_x.shape[0],-1)\n",
        "#    print('decx1 ',dec_x1.shape)\n",
        "    combx = np.vstack((resx1,dec_x1))\n",
        "    comby = np.hstack((resy1,dec_y))\n",
        "\n",
        "    print(combx.shape) #(45000, 3, 32, 32)\n",
        "    print(comby.shape) #(45000,)\n",
        "#    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76bpFBQcHLIY",
        "outputId": "778df4ec-f880-41df-c474-8c2f533b4c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape:  (11732, 32, 32, 3)\n",
            "Counter({0: 1676, 1: 1676, 2: 1676, 3: 1676, 4: 1676, 6: 1676, 5: 1676})\n"
          ]
        }
      ],
      "source": [
        "X_train = combx.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "X_train = moveaxis(X_train, 1, 3)\n",
        "print('X_train shape: ',X_train.shape)\n",
        "y_train = comby\n",
        "print(Counter(comby))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SqyvSgX8sLO"
      },
      "outputs": [],
      "source": [
        "X_train = X_train * 255\n",
        "X_train = X_train.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US0KkIaVlTdU"
      },
      "source": [
        "#Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_a_lPCqbibaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af68ffc-1610-4463-fdf5-9cff60f341eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape:  (37821, 1)\n"
          ]
        }
      ],
      "source": [
        "y_train = y_train.reshape(-1, 1)\n",
        "y_val = y_val.reshape(-1, 1)\n",
        "print('y_train shape: ',y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ja5ZmgbCvDw5"
      },
      "outputs": [],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "y_val = to_categorical(y_val, num_classes = num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ioaoIkk4G2pf"
      },
      "outputs": [],
      "source": [
        "#X_val = X_val.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9QM00erNGU32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d50125ca-b4b9-4da4-fad8-8c40d5c15aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37821, 128, 128, 3)\n",
            "(37821, 7)\n",
            "(193, 128, 128, 3)\n",
            "(193, 7)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6qneWL_Bs2U",
        "outputId": "22c2c4ff-5544-4dd8-b69a-af96b4b97616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data:  (9814, 32, 32, 3)\n",
            "Remaining Data:  (201, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.02, stratify=y, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vai7M7WSXVY4",
        "outputId": "b9bc1199-a518-4a8b-9d6e-4d6038efbafe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Data:  (416, 32, 32, 3)\n",
            "Val Data:  (416, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# stratified val and test (50%) \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_rem, y_rem, test_size=0.5, stratify=y_rem, random_state=1)\n",
        "\n",
        "print('Test Data: ', X_test.shape)\n",
        "print('Val Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I15HgVuhjFlm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVVOQPNiHXHw",
        "outputId": "a1e60310-4f3b-4063-8465-4d7120d225c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data:  (2015, 32, 32, 3)\n",
            "Test Data:  (224, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "#optional\n",
        "# stratified train and test (10%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Test Data: ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_oaUYYgJNV7",
        "outputId": "ca2f393a-0599-4cfc-b330-45d723f2bb06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data:  (3369, 32, 32, 3)\n",
            "Val Data:  (375, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "#optional\n",
        "# stratified train and val (10%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify=y, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Val Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZklPzWxCCtTW"
      },
      "source": [
        "Create and compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jFShRvTHnqi"
      },
      "outputs": [],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Classification\n",
        "Model from https://github.com/AnasBrital98/CNN-From-Scratch/tree/master/Inception-V3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#USe TF.data\n",
        "import tensorflow as tf\n",
        "training_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "validation_data = tf.data.Dataset.from_tensor_slices((X_val, y_val))"
      ],
      "metadata": {
        "id": "A8eRZiucdYnP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autotune = tf.data.AUTOTUNE\n",
        "train_data_batches = training_data.shuffle(buffer_size=40000).batch(32).prefetch(buffer_size=autotune)\n",
        "valid_data_batches = validation_data.shuffle(buffer_size=10000).batch(32).prefetch(buffer_size=autotune)"
      ],
      "metadata": {
        "id": "7xalxBh-3LNC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "rescale_layer = tf.keras.Sequential([layers.experimental.preprocessing.Rescaling(1./255)])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2), \n",
        "  layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3)),\n",
        "  layers.experimental.preprocessing.RandomTranslation(0.3, 0.3, fill_mode='reflect', interpolation='bilinear',)\n",
        "])"
      ],
      "metadata": {
        "id": "Ge4UmF5R0a7V"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model.h5'\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=10, verbose=0, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=20,monitor='val_accuracy')"
      ],
      "metadata": {
        "id": "mu6rr5apdJtf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rwwLiXUSG0IZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5408b3d2-6768-4e10-d38c-f48b9bd0167f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n",
            "Epoch 1/1000\n",
            "1182/1182 [==============================] - ETA: 0s - loss: 7.9243 - accuracy: 0.1477\n",
            "Epoch 1: val_accuracy improved from -inf to 0.00518, saving model to /content/drive/MyDrive/PHD/Model/best_model.h5\n",
            "1182/1182 [==============================] - 55s 35ms/step - loss: 7.9243 - accuracy: 0.1477 - val_loss: 4.1608 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 2/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.7290 - accuracy: 0.1580\n",
            "Epoch 2: val_accuracy did not improve from 0.00518\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.7293 - accuracy: 0.1580 - val_loss: 3.6219 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 3/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.6847 - accuracy: 0.1605\n",
            "Epoch 3: val_accuracy did not improve from 0.00518\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.6850 - accuracy: 0.1605 - val_loss: 3.9271 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 4/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.6156 - accuracy: 0.1665\n",
            "Epoch 4: val_accuracy did not improve from 0.00518\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.6162 - accuracy: 0.1665 - val_loss: 3.5731 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 5/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.5735 - accuracy: 0.1701\n",
            "Epoch 5: val_accuracy did not improve from 0.00518\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.5746 - accuracy: 0.1701 - val_loss: 5.0237 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 6/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.5591 - accuracy: 0.1730\n",
            "Epoch 6: val_accuracy did not improve from 0.00518\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.5600 - accuracy: 0.1730 - val_loss: 3.9162 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 7/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.5248 - accuracy: 0.1735\n",
            "Epoch 7: val_accuracy improved from 0.00518 to 0.01036, saving model to /content/drive/MyDrive/PHD/Model/best_model.h5\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 7.5256 - accuracy: 0.1735 - val_loss: 3.7154 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 8/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.5147 - accuracy: 0.1776\n",
            "Epoch 8: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.5148 - accuracy: 0.1775 - val_loss: 3.2371 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 9/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.4815 - accuracy: 0.1764\n",
            "Epoch 9: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.4812 - accuracy: 0.1764 - val_loss: 3.6396 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 10/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.4598 - accuracy: 0.1794\n",
            "Epoch 10: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.4593 - accuracy: 0.1794 - val_loss: 3.3828 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 11/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.4545 - accuracy: 0.1821\n",
            "Epoch 11: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.4554 - accuracy: 0.1822 - val_loss: 4.3974 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 12/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.4459 - accuracy: 0.1810\n",
            "Epoch 12: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.4456 - accuracy: 0.1811 - val_loss: 3.7197 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 13/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.4396 - accuracy: 0.1828\n",
            "Epoch 13: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.4401 - accuracy: 0.1830 - val_loss: 3.1615 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 14/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.4282 - accuracy: 0.1806\n",
            "Epoch 14: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.4275 - accuracy: 0.1806 - val_loss: 4.2022 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 15/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3896 - accuracy: 0.1835\n",
            "Epoch 15: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3906 - accuracy: 0.1836 - val_loss: 3.2032 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 16/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3990 - accuracy: 0.1854\n",
            "Epoch 16: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.4002 - accuracy: 0.1854 - val_loss: 3.5283 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 17/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3987 - accuracy: 0.1846\n",
            "Epoch 17: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3997 - accuracy: 0.1846 - val_loss: 3.4446 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 18/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3810 - accuracy: 0.1847\n",
            "Epoch 18: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3813 - accuracy: 0.1847 - val_loss: 4.2543 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 19/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3844 - accuracy: 0.1835\n",
            "Epoch 19: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3836 - accuracy: 0.1835 - val_loss: 3.0855 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 20/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3672 - accuracy: 0.1853\n",
            "Epoch 20: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3652 - accuracy: 0.1852 - val_loss: 3.2007 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 21/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3693 - accuracy: 0.1857\n",
            "Epoch 21: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3685 - accuracy: 0.1857 - val_loss: 3.6654 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 22/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3539 - accuracy: 0.1863\n",
            "Epoch 22: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3543 - accuracy: 0.1863 - val_loss: 3.4012 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 23/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3375 - accuracy: 0.1910\n",
            "Epoch 23: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3370 - accuracy: 0.1910 - val_loss: 2.8980 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 24/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3602 - accuracy: 0.1872\n",
            "Epoch 24: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3600 - accuracy: 0.1872 - val_loss: 3.2180 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 25/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3448 - accuracy: 0.1868\n",
            "Epoch 25: val_accuracy did not improve from 0.01036\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3444 - accuracy: 0.1869 - val_loss: 3.2893 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 26/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3304 - accuracy: 0.1865\n",
            "Epoch 26: val_accuracy improved from 0.01036 to 0.01554, saving model to /content/drive/MyDrive/PHD/Model/best_model.h5\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 7.3312 - accuracy: 0.1865 - val_loss: 3.1807 - val_accuracy: 0.0155 - lr: 5.0000e-04\n",
            "Epoch 27/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3280 - accuracy: 0.1900\n",
            "Epoch 27: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3267 - accuracy: 0.1900 - val_loss: 3.5502 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 28/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3028 - accuracy: 0.1909\n",
            "Epoch 28: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.3028 - accuracy: 0.1908 - val_loss: 3.2025 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 29/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3158 - accuracy: 0.1862\n",
            "Epoch 29: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.3162 - accuracy: 0.1863 - val_loss: 2.8768 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 30/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.3086 - accuracy: 0.1905\n",
            "Epoch 30: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.3098 - accuracy: 0.1905 - val_loss: 2.6302 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 31/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2943 - accuracy: 0.1887\n",
            "Epoch 31: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.2938 - accuracy: 0.1887 - val_loss: 3.2133 - val_accuracy: 0.0155 - lr: 5.0000e-04\n",
            "Epoch 32/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2820 - accuracy: 0.1922\n",
            "Epoch 32: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.2824 - accuracy: 0.1921 - val_loss: 4.0059 - val_accuracy: 0.0052 - lr: 5.0000e-04\n",
            "Epoch 33/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2717 - accuracy: 0.1894\n",
            "Epoch 33: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.2708 - accuracy: 0.1894 - val_loss: 3.0809 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 34/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2769 - accuracy: 0.1907\n",
            "Epoch 34: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 36s 31ms/step - loss: 7.2778 - accuracy: 0.1908 - val_loss: 2.8987 - val_accuracy: 0.0155 - lr: 5.0000e-04\n",
            "Epoch 35/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2713 - accuracy: 0.1942\n",
            "Epoch 35: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.2710 - accuracy: 0.1942 - val_loss: 3.2984 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 36/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2611 - accuracy: 0.1929\n",
            "Epoch 36: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 37s 32ms/step - loss: 7.2606 - accuracy: 0.1930 - val_loss: 3.5899 - val_accuracy: 0.0155 - lr: 5.0000e-04\n",
            "Epoch 37/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2879 - accuracy: 0.1930\n",
            "Epoch 37: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 37s 32ms/step - loss: 7.2878 - accuracy: 0.1930 - val_loss: 3.4646 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 38/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2880 - accuracy: 0.1893\n",
            "Epoch 38: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.2873 - accuracy: 0.1893 - val_loss: 3.0215 - val_accuracy: 0.0155 - lr: 5.0000e-04\n",
            "Epoch 39/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2683 - accuracy: 0.1938\n",
            "Epoch 39: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.2676 - accuracy: 0.1937 - val_loss: 2.7730 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 40/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2403 - accuracy: 0.1963\n",
            "Epoch 40: val_accuracy did not improve from 0.01554\n",
            "1182/1182 [==============================] - 37s 32ms/step - loss: 7.2407 - accuracy: 0.1963 - val_loss: 3.1083 - val_accuracy: 0.0104 - lr: 5.0000e-04\n",
            "Epoch 41/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2190 - accuracy: 0.1936\n",
            "Epoch 41: val_accuracy improved from 0.01554 to 0.02591, saving model to /content/drive/MyDrive/PHD/Model/best_model.h5\n",
            "1182/1182 [==============================] - 40s 34ms/step - loss: 7.2185 - accuracy: 0.1936 - val_loss: 2.6164 - val_accuracy: 0.0259 - lr: 2.5000e-04\n",
            "Epoch 42/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2176 - accuracy: 0.1959\n",
            "Epoch 42: val_accuracy did not improve from 0.02591\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 7.2170 - accuracy: 0.1958 - val_loss: 2.7824 - val_accuracy: 0.0104 - lr: 2.5000e-04\n",
            "Epoch 43/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2087 - accuracy: 0.1960\n",
            "Epoch 43: val_accuracy did not improve from 0.02591\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 7.2078 - accuracy: 0.1959 - val_loss: 2.7641 - val_accuracy: 0.0259 - lr: 2.5000e-04\n",
            "Epoch 44/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2015 - accuracy: 0.1992\n",
            "Epoch 44: val_accuracy improved from 0.02591 to 0.04145, saving model to /content/drive/MyDrive/PHD/Model/best_model.h5\n",
            "1182/1182 [==============================] - 40s 34ms/step - loss: 7.2016 - accuracy: 0.1992 - val_loss: 2.5516 - val_accuracy: 0.0415 - lr: 2.5000e-04\n",
            "Epoch 45/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.2019 - accuracy: 0.1982\n",
            "Epoch 45: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 7.2019 - accuracy: 0.1982 - val_loss: 3.0474 - val_accuracy: 0.0104 - lr: 2.5000e-04\n",
            "Epoch 46/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1877 - accuracy: 0.1967\n",
            "Epoch 46: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 7.1890 - accuracy: 0.1966 - val_loss: 3.2633 - val_accuracy: 0.0104 - lr: 2.5000e-04\n",
            "Epoch 47/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1645 - accuracy: 0.1999\n",
            "Epoch 47: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 7.1639 - accuracy: 0.1999 - val_loss: 3.2416 - val_accuracy: 0.0104 - lr: 2.5000e-04\n",
            "Epoch 48/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1832 - accuracy: 0.1975\n",
            "Epoch 48: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1835 - accuracy: 0.1975 - val_loss: 2.6925 - val_accuracy: 0.0311 - lr: 2.5000e-04\n",
            "Epoch 49/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1764 - accuracy: 0.1977\n",
            "Epoch 49: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1761 - accuracy: 0.1977 - val_loss: 3.0140 - val_accuracy: 0.0104 - lr: 2.5000e-04\n",
            "Epoch 50/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1745 - accuracy: 0.1981\n",
            "Epoch 50: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1742 - accuracy: 0.1980 - val_loss: 2.9589 - val_accuracy: 0.0155 - lr: 2.5000e-04\n",
            "Epoch 51/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1578 - accuracy: 0.2009\n",
            "Epoch 51: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1585 - accuracy: 0.2009 - val_loss: 2.9755 - val_accuracy: 0.0207 - lr: 2.5000e-04\n",
            "Epoch 52/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1753 - accuracy: 0.1990\n",
            "Epoch 52: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1756 - accuracy: 0.1990 - val_loss: 3.6289 - val_accuracy: 0.0104 - lr: 2.5000e-04\n",
            "Epoch 53/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1833 - accuracy: 0.1995\n",
            "Epoch 53: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1837 - accuracy: 0.1994 - val_loss: 3.0052 - val_accuracy: 0.0104 - lr: 2.5000e-04\n",
            "Epoch 54/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1606 - accuracy: 0.2025\n",
            "Epoch 54: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1601 - accuracy: 0.2025 - val_loss: 3.0679 - val_accuracy: 0.0155 - lr: 2.5000e-04\n",
            "Epoch 55/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1338 - accuracy: 0.2003\n",
            "Epoch 55: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1351 - accuracy: 0.2004 - val_loss: 2.8500 - val_accuracy: 0.0259 - lr: 1.2500e-04\n",
            "Epoch 56/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1368 - accuracy: 0.2021\n",
            "Epoch 56: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1368 - accuracy: 0.2020 - val_loss: 2.7225 - val_accuracy: 0.0311 - lr: 1.2500e-04\n",
            "Epoch 57/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1348 - accuracy: 0.2008\n",
            "Epoch 57: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1341 - accuracy: 0.2008 - val_loss: 2.8470 - val_accuracy: 0.0155 - lr: 1.2500e-04\n",
            "Epoch 58/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1242 - accuracy: 0.2016\n",
            "Epoch 58: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1230 - accuracy: 0.2015 - val_loss: 2.6147 - val_accuracy: 0.0415 - lr: 1.2500e-04\n",
            "Epoch 59/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1160 - accuracy: 0.2037\n",
            "Epoch 59: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1155 - accuracy: 0.2037 - val_loss: 3.1222 - val_accuracy: 0.0104 - lr: 1.2500e-04\n",
            "Epoch 60/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1261 - accuracy: 0.2035\n",
            "Epoch 60: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1270 - accuracy: 0.2035 - val_loss: 2.8828 - val_accuracy: 0.0104 - lr: 1.2500e-04\n",
            "Epoch 61/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1052 - accuracy: 0.2042\n",
            "Epoch 61: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1054 - accuracy: 0.2042 - val_loss: 2.7992 - val_accuracy: 0.0259 - lr: 1.2500e-04\n",
            "Epoch 62/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1124 - accuracy: 0.2039\n",
            "Epoch 62: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1123 - accuracy: 0.2039 - val_loss: 3.1135 - val_accuracy: 0.0155 - lr: 1.2500e-04\n",
            "Epoch 63/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1061 - accuracy: 0.2027\n",
            "Epoch 63: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1063 - accuracy: 0.2026 - val_loss: 2.7329 - val_accuracy: 0.0259 - lr: 1.2500e-04\n",
            "Epoch 64/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 7.1066 - accuracy: 0.2034\n",
            "Epoch 64: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 7.1087 - accuracy: 0.2034 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.2500e-04\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# this could also be the output a different Keras model or layer\n",
        "input_shape = X_train.shape[1:]\n",
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "augmented = data_augmentation(input_tensor)\n",
        "rescale = rescale_layer(augmented)\n",
        "\n",
        "base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "x = base_model(rescale)\n",
        "\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "#x = base_model.output\n",
        "#x = GlobalAveragePooling2D()(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "x = Flatten()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(128, activation='relu')(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "#predictions = Dense(9)(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=input_tensor, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "#model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# train the model on the new data for a few epochs\n",
        "#hst = model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val, y_val))\n",
        "\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "#hst = model.fit(dataaugment.flow(X_train,y_train, batch_size=BATCH_SIZE),\n",
        "hst = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,      \n",
        "                    class_weight=class_weights,\n",
        "                    #steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6WA3NkiOqePA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa48b2e-6236-4155-f4cc-2795bf2d86aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.212, Val: 0.041\n"
          ]
        }
      ],
      "source": [
        "# load the saved model\n",
        "best_model = load_model(best_model_fpath)\n",
        "# evaluate the model\n",
        "_, train_acc = best_model.evaluate(X_train, y_train, verbose=0)\n",
        "_, test_acc = best_model.evaluate(X_val, y_val, verbose=0)\n",
        "print('Train: %.3f, Val: %.3f' % (train_acc, test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = best_model.predict(X_val)\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))"
      ],
      "metadata": {
        "id": "W3IyWjdGG4Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54df85c-8fdf-4749-bb83-227baf09a8ed"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balanced accuracy on training 0.21242167050051558\n",
            "balanced accuracy on validation 0.16226978596316574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vXnW3lmCgln3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ab81dc10-adbb-42cd-a16f-eb59d41511be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine Tune"
      ],
      "metadata": {
        "id": "B2PgksTFkOAq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "l8bZo4LoEiQf"
      },
      "outputs": [],
      "source": [
        "#finetune_model_fpath = '/content/drive/MyDrive/PHD/Model/finetune_model.h5'\n",
        "#mc_finetune = ModelCheckpoint(finetune_model_fpath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Nr1jnSM7yzJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c9bf6a-d3e1-43b0-d6e1-e18e6de6e45a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2177 - accuracy: 0.2026\n",
            "Epoch 1: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 40s 31ms/step - loss: 2.2176 - accuracy: 0.2025 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 2/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2168 - accuracy: 0.2036\n",
            "Epoch 2: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2169 - accuracy: 0.2036 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 3/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2176 - accuracy: 0.2034\n",
            "Epoch 3: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2176 - accuracy: 0.2034 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 4/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2177 - accuracy: 0.2026\n",
            "Epoch 4: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2178 - accuracy: 0.2025 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 5/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2147 - accuracy: 0.2029\n",
            "Epoch 5: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2148 - accuracy: 0.2029 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 6/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2147 - accuracy: 0.2004\n",
            "Epoch 6: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2149 - accuracy: 0.2003 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 7/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2120 - accuracy: 0.2022\n",
            "Epoch 7: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2119 - accuracy: 0.2022 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 8/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2166 - accuracy: 0.2035\n",
            "Epoch 8: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2166 - accuracy: 0.2035 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 9/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2182 - accuracy: 0.2016\n",
            "Epoch 9: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2184 - accuracy: 0.2015 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 10/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2205 - accuracy: 0.2033\n",
            "Epoch 10: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2206 - accuracy: 0.2032 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 11/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2172 - accuracy: 0.2057\n",
            "Epoch 11: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2170 - accuracy: 0.2058 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 12/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2206 - accuracy: 0.2016\n",
            "Epoch 12: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2203 - accuracy: 0.2017 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 5.0000e-05\n",
            "Epoch 13/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2112 - accuracy: 0.2022\n",
            "Epoch 13: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2111 - accuracy: 0.2022 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 5.0000e-05\n",
            "Epoch 14/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2156 - accuracy: 0.2042\n",
            "Epoch 14: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 36s 30ms/step - loss: 2.2155 - accuracy: 0.2041 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 5.0000e-05\n",
            "Epoch 15/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2154 - accuracy: 0.2035\n",
            "Epoch 15: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 2.2160 - accuracy: 0.2034 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 5.0000e-05\n",
            "Epoch 16/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2155 - accuracy: 0.2033\n",
            "Epoch 16: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 39s 33ms/step - loss: 2.2156 - accuracy: 0.2032 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 5.0000e-05\n",
            "Epoch 17/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2198 - accuracy: 0.2016\n",
            "Epoch 17: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 2.2198 - accuracy: 0.2016 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 5.0000e-05\n",
            "Epoch 18/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2166 - accuracy: 0.2016\n",
            "Epoch 18: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 39s 33ms/step - loss: 2.2167 - accuracy: 0.2015 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 5.0000e-05\n",
            "Epoch 19/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2161 - accuracy: 0.2046\n",
            "Epoch 19: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 39s 33ms/step - loss: 2.2160 - accuracy: 0.2046 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 5.0000e-05\n",
            "Epoch 20/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2142 - accuracy: 0.2019\n",
            "Epoch 20: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 39s 33ms/step - loss: 2.2139 - accuracy: 0.2021 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 5.0000e-05\n",
            "Epoch 21/1000\n",
            "1181/1182 [============================>.] - ETA: 0s - loss: 2.2180 - accuracy: 0.2015\n",
            "Epoch 21: val_accuracy did not improve from 0.04145\n",
            "1182/1182 [==============================] - 39s 33ms/step - loss: 2.2178 - accuracy: 0.2015 - val_loss: 3.2085 - val_accuracy: 0.0104 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# we chose to train the top 2 resnet blocks, i.e. we will freeze\n",
        "# the first 49 layers and unfreeze the rest:\n",
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "#model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "#hst2 = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val, y_val))\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "#hst2 = model.fit(dataaugment.flow(X_train,y_train, batch_size=BATCH_SIZE),\n",
        "hst = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        " #                   steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model\n",
        "finetune_model = load_model(best_model_fpath)\n",
        "# evaluate the model\n",
        "_, train_acc = finetune_model.evaluate(X_train, y_train, verbose=0)\n",
        "_, test_acc = finetune_model.evaluate(X_val, y_val, verbose=0)\n",
        "print('Train: %.3f, Val: %.3f' % (train_acc, test_acc))"
      ],
      "metadata": {
        "id": "1QoiQK0xECpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf5c566-015b-47da-ee55-f7b38d84852a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.212, Val: 0.041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = finetune_model.predict(X_val)\n",
        "y_train_pred = finetune_model.predict(X_train)\n",
        "\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))"
      ],
      "metadata": {
        "id": "3EeAKIX_EB9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144a4b20-94ea-4c22-fc25-5a6d49c433c6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balanced accuracy on training 0.21242167050051558\n",
            "balanced accuracy on validation 0.16226978596316574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gH92sRmlETE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c67d0f2-10ad-40bb-bd1d-80485cefe669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score on val data:  (0.23895067008839463, 0.16226978596316574, 0.03667091836734694, None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))\n",
        "#print('Score on test data: ',precision_recall_fscore_support(y_test, y_pred2, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vO1aAQBmiy0K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "19e801e5-870a-4cc4-c467-1ddf6996b493"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.title('model accuracy after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6ic95mefkpG3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4bf91609-861d-4aaa-de4d-96497e7237b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 image                                          FilePaths\n",
              "0     ISIC_0034524.jpg  /content/drive/MyDrive/PHD/Datasets/isic2018/I...\n",
              "1     ISIC_0034525.jpg  /content/drive/MyDrive/PHD/Datasets/isic2018/I...\n",
              "2     ISIC_0034526.jpg  /content/drive/MyDrive/PHD/Datasets/isic2018/I...\n",
              "3     ISIC_0034527.jpg  /content/drive/MyDrive/PHD/Datasets/isic2018/I...\n",
              "4     ISIC_0034528.jpg  /content/drive/MyDrive/PHD/Datasets/isic2018/I...\n",
              "...                ...                                                ...\n",
              "1507  ISIC_0036060.jpg  /content/drive/MyDrive/PHD/Datasets/isic2018/I...\n",
              "1508  ISIC_0036061.jpg  /content/drive/MyDrive/PHD/Datasets/isic2018/I...\n",
              "1509  ISIC_0036062.jpg  /content/drive/MyDrive/PHD/Datasets/isic2018/I...\n",
              "1510  ISIC_0036063.jpg  /content/drive/MyDrive/PHD/Datasets/isic2018/I...\n",
              "1511  ISIC_0036064.jpg  /content/drive/MyDrive/PHD/Datasets/isic2018/I...\n",
              "\n",
              "[1512 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8b249e7-7adf-441d-86e9-ee4a7ff39b7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>FilePaths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ISIC_0034524.jpg</td>\n",
              "      <td>/content/drive/MyDrive/PHD/Datasets/isic2018/I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ISIC_0034525.jpg</td>\n",
              "      <td>/content/drive/MyDrive/PHD/Datasets/isic2018/I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISIC_0034526.jpg</td>\n",
              "      <td>/content/drive/MyDrive/PHD/Datasets/isic2018/I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISIC_0034527.jpg</td>\n",
              "      <td>/content/drive/MyDrive/PHD/Datasets/isic2018/I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISIC_0034528.jpg</td>\n",
              "      <td>/content/drive/MyDrive/PHD/Datasets/isic2018/I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1507</th>\n",
              "      <td>ISIC_0036060.jpg</td>\n",
              "      <td>/content/drive/MyDrive/PHD/Datasets/isic2018/I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1508</th>\n",
              "      <td>ISIC_0036061.jpg</td>\n",
              "      <td>/content/drive/MyDrive/PHD/Datasets/isic2018/I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1509</th>\n",
              "      <td>ISIC_0036062.jpg</td>\n",
              "      <td>/content/drive/MyDrive/PHD/Datasets/isic2018/I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1510</th>\n",
              "      <td>ISIC_0036063.jpg</td>\n",
              "      <td>/content/drive/MyDrive/PHD/Datasets/isic2018/I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>ISIC_0036064.jpg</td>\n",
              "      <td>/content/drive/MyDrive/PHD/Datasets/isic2018/I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1512 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8b249e7-7adf-441d-86e9-ee4a7ff39b7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8b249e7-7adf-441d-86e9-ee4a7ff39b7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8b249e7-7adf-441d-86e9-ee4a7ff39b7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "60LYAT7VsNOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96f5676-e889-4837-d490-d008e9dbe4a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.asarray(df_test['image'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "dIX0AmEFNv3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff713c6a-aead-40d4-9204-f8f9fe00a5d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_pred2 (1512, 7)\n",
            "y_pred2 1512\n"
          ]
        }
      ],
      "source": [
        "# predicted labels\n",
        "Y_pred2 = finetune_model.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)\n",
        "# rounded labels\n",
        "y_pred2 = np.argmax(Y_pred2, axis=1)\n",
        "print(\"y_pred2\", y_pred2.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.set_index(\"image\", inplace = True)\n",
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_SMOTEoversampling.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "E4nEpmkZaTZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e47dd3f-de4f-484c-dcb0-76edd59fa689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   8   0   0   0]\n",
            " [  0   0   0  15   0   0   0]\n",
            " [  0   0   0  19   1   0   2]\n",
            " [  0   0   0   1   0   0   0]\n",
            " [  1   0   0  17   2   0   1]\n",
            " [  0   0   0 104   0   5  14]\n",
            " [  0   0   0   3   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1))\n",
        "\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "gVtvW3YeaLlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "da513b66-5c8d-4f8b-b224-65a7c8428867"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Ey-1yjWGeKs7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "55988e3d-2c35-4d9a-af37-753d3c64af70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'AKIEC'),\n",
              " Text(0, 0, 'BCC'),\n",
              " Text(0, 0, 'BKL'),\n",
              " Text(0, 0, 'DF'),\n",
              " Text(0, 0, 'MEL'),\n",
              " Text(0, 0, 'NV'),\n",
              " Text(0, 0, 'VASC')]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RcRGeofw-8tK",
        "uZv-B-ygCD57",
        "cNBXx28B9yGu",
        "US0KkIaVlTdU",
        "0jrJ33lUDkCM",
        "3K908bbiYwbS"
      ],
      "machine_shape": "hm",
      "name": "Skin Cancer Diagnosis using ISIC 2018 Dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}