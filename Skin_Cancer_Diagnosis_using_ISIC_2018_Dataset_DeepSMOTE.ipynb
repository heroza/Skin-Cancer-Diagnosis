{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Skin-Cancer-Diagnosis/blob/main/Skin_Cancer_Diagnosis_using_ISIC_2018_Dataset_DeepSMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUusDE1Z9TNb"
      },
      "source": [
        "Prepare the dataset. \n",
        "Currently, we use skin cancer ISIC dataset from Kaggle https://www.kaggle.com/datasets/nodoubttome/skin-cancer9-classesisic\n",
        "\n",
        "Tutorial for how to load Kaggle dataset can be found in https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "e92bbdf6-086d-48dd-bda4-e565dad8b2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR2MJBYq-oiB",
        "outputId": "eedc39ce-f581-47d6-93ed-ece284a78f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "!pip install imbalanced-learn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3mnEebdJH6Ex"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "num_classes = 7\n",
        "#df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aFSe3uekK67v"
      },
      "outputs": [],
      "source": [
        "#decode one hot label\n",
        "df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "#drop one-hot column\n",
        "df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "#make filepaths of the image\n",
        "dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38f3dgvyBqFM"
      },
      "source": [
        "Label Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "2IncA-_o_n5w",
        "outputId": "42f8c3a2-5745-4217-e096-9d2fa4adc91f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'DF'),\n",
              " Text(0, 0, 'VASC'),\n",
              " Text(0, 0, 'AKIEC'),\n",
              " Text(0, 0, 'BCC'),\n",
              " Text(0, 0, 'BKL'),\n",
              " Text(0, 0, 'MEL'),\n",
              " Text(0, 0, 'NV')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = df_train['Labels'].value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(row['Labels'] == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df_train['Labels'].unique())\n",
        "#for label in labels:\n",
        "#    plot_images_per_label(df_train, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h35T8vKRVV1Y"
      },
      "source": [
        "Manual undersampling majority class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BeldhlTdVQlT"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=.6).index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKjC59JOB_6d"
      },
      "source": [
        "Prepare X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 56\n",
        "IMAGE_H = 56\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3jyCpXnlFoQK"
      },
      "outputs": [],
      "source": [
        "#TIME CONSUMING OPERATION\n",
        "#from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "#X = []\n",
        "#for img in df['FilePaths']:\n",
        "    #img_arr = load_img(img, target_size=IMG_SIZE)\n",
        "#    with load_img(img, target_size=IMG_SIZE) as img_arr:\n",
        "#      X.append(img_to_array(img_arr))\n",
        "\n",
        "#X = np.array(X)\n",
        "df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UZyZMydSgvZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e90ac87-004c-4134-af2f-9ab4fa426cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5992, 56, 56, 3)\n",
            "(193, 56, 56, 3)\n"
          ]
        }
      ],
      "source": [
        "X_train = np.asarray(df_train['image_px'].tolist())\n",
        "X_val = np.asarray(df_val['image_px'].tolist())\n",
        "print(np.array(X_train).shape)\n",
        "print(np.array(X_val).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uqYLmicGAjZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d299e0-9427-4c5c-a8e8-0c36005a64c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'NV': 2682, 'MEL': 1113, 'BKL': 1099, 'BCC': 514, 'AKIEC': 327, 'VASC': 142, 'DF': 115})\n",
            "(5992,)\n"
          ]
        }
      ],
      "source": [
        "y_train = np.array(df_train['Labels'].values)\n",
        "\n",
        "# summarize class distribution\n",
        "from collections import Counter\n",
        "counter = Counter(y_train)\n",
        "print(counter)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kEuVIGc3g859",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3688f7a0-cb8c-4e8c-902b-d00764a976ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'NV': 123, 'BKL': 22, 'MEL': 21, 'BCC': 15, 'AKIEC': 8, 'VASC': 3, 'DF': 1})\n",
            "(193,)\n"
          ]
        }
      ],
      "source": [
        "y_val = np.array(df_val['Labels'].values)\n",
        "print(Counter(y_val))\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QfvEVGIQhIr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c915b7-6c57-417a-cb36-f5b94e56a86c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 4, ..., 4, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#label encoding\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_val = label_encoder.fit_transform(y_val)\n",
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZv-B-ygCD57"
      },
      "source": [
        "#SMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDskF1wjGffh"
      },
      "outputs": [],
      "source": [
        "def SMOTE_Data(X, y):\n",
        "  sm = SMOTE(random_state=42, k_neighbors=5)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, IMAGE_W * IMAGE_H * 3)), y)\n",
        "  X_resampled.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brshqGvOCDJL",
        "outputId": "69cd1efa-ecf2-4066-fcb2-6e76150c29a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32851, 150528)\n",
            "(32851,)\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train) #beware of the actual parameter\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GfOtcbV5vVZ",
        "outputId": "835b01d9-1627-4c85-fde0-c4a58a2ace7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({5: 4693, 4: 4693, 2: 4693, 3: 4693, 0: 4693, 1: 4693, 6: 4693})\n"
          ]
        }
      ],
      "source": [
        "counter = Counter(y_train)\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl-nmACZOZpg",
        "outputId": "b35b1691-9cd5-4b83-ccf6-2b4cfdfd8fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape:  (32851, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "print('X_train shape: ',X_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RAxUkXy8ueYG"
      },
      "outputs": [],
      "source": [
        "#Normalization\n",
        "X_train_mean = np.mean(X_train)\n",
        "X_train_std = np.std(X_train)\n",
        "\n",
        "X_train = (X_train - X_train_mean)/X_train_std\n",
        "X_val = (X_val - X_train_mean)/X_train_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "h-Xqj-WQ90L_"
      },
      "outputs": [],
      "source": [
        "#optional\n",
        "#X=X_train\n",
        "#y=y_train\n",
        "\n",
        "from numpy import moveaxis\n",
        "X_train = moveaxis(X_train, 3, 1)\n",
        "#X_train = X_train.astype('float32') / 255.\n",
        "#dec_x = X_train \n",
        "#dec_y = y\n",
        "\n",
        "#create counter for encoder\n",
        "counter = sorted(counter.items())\n",
        "counter = [value for _, value in counter]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0kMMmX7r-fV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732253cb-d6c5-4cf5-a85e-b19beee801b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(torch.version.cuda) #10.1\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "\n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "\n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 12   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "\n",
        "args['patience'] = 20\n",
        "\n",
        "## create encoder model and decoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        #[(W−K+2P)/S]+1.\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 224 > 112\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),# > 56\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# > 28\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 7, 2, 0, bias=False),# > 14\n",
        "            nn.BatchNorm2d(self.dim_h * 8), # 40 X 8 = 320\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "#            nn.Conv2d(self.dim_h * 8, self.dim_h * 16, 7, 2, 0, bias=False),# > 7\n",
        "#            nn.BatchNorm2d(self.dim_h * 16), # 40 X 8 = 320\n",
        "#            nn.LeakyReLU(0.2, inplace=True))\n",
        "#            nn.Conv2d(self.dim_h * 16, self.dim_h * 32, 7, 2, 0, bias=False),# > 1\n",
        "#            nn.BatchNorm2d(self.dim_h * 32), # 40 X 8 = 320\n",
        "#            nn.LeakyReLU(0.2, inplace=True))\n",
        "        # final layer is fully connected\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('enc')\n",
        "        #print('input ',x.size()) #torch.Size([100, 3,32,32])\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        #print('aft squeeze ',x.size()) #torch.Size([128, 320])\n",
        "        #aft squeeze  torch.Size([100, 320])\n",
        "        x = self.fc(x)\n",
        "        #print('out ',x.size()) #torch.Size([128, 20])\n",
        "        #out  torch.Size([100, 300])\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        #H_out ​= (H_in​−1)*stride[0] − 2×padding[0] + dilation[0]×(kernel_size[0]−1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "#            nn.ConvTranspose2d(self.dim_h * 32, self.dim_h * 16, 4, 2, 1), # > 14 > 28 > 56 > 112 > 224\n",
        "#            nn.BatchNorm2d(self.dim_h * 16),\n",
        "#            nn.ReLU(True),\n",
        "#            nn.ConvTranspose2d(self.dim_h * 16, self.dim_h * 8, 4, 2, 1), # > 28\n",
        "#            nn.BatchNorm2d(self.dim_h * 8),\n",
        "#            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4, 2, 1),# > 56\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4, 2, 1),# > 112\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, 3, 4, 2, 1),# > 224\n",
        "            #nn.Sigmoid())\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('dec')\n",
        "        #print('input ',x.size())\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"functions to create SMOTE images\"\"\"\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "\n",
        "    # determining the number of samples to generate\n",
        "    #n_to_sample = 10 \n",
        "\n",
        "    # fitting the model\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "#xsamp, ysamp = SM(xclass,yclass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHtLISURIMTg",
        "outputId": "30e08ee1-499a-407d-9928-8137b9fe1304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch: 0 \tTrain Loss: 7.299708 \tmse loss: 3.948752 \tmse2 loss: 3.350956\n",
            "Saving..\n",
            "Epoch: 1 \tTrain Loss: 5.475280 \tmse loss: 3.023897 \tmse2 loss: 2.451383\n",
            "Saving..\n",
            "Epoch: 2 \tTrain Loss: 4.937226 \tmse loss: 2.787710 \tmse2 loss: 2.149516\n",
            "Saving..\n",
            "Epoch: 3 \tTrain Loss: 4.739900 \tmse loss: 2.696243 \tmse2 loss: 2.043657\n",
            "Saving..\n",
            "Epoch: 4 \tTrain Loss: 4.545835 \tmse loss: 2.640414 \tmse2 loss: 1.905420\n",
            "Saving..\n",
            "Epoch: 5 \tTrain Loss: 4.546779 \tmse loss: 2.591076 \tmse2 loss: 1.955702\n",
            "Epoch: 6 \tTrain Loss: 4.416031 \tmse loss: 2.550796 \tmse2 loss: 1.865234\n",
            "Saving..\n",
            "Epoch: 7 \tTrain Loss: 4.367793 \tmse loss: 2.514564 \tmse2 loss: 1.853230\n",
            "Saving..\n",
            "Epoch: 8 \tTrain Loss: 4.426613 \tmse loss: 2.502036 \tmse2 loss: 1.924577\n",
            "Epoch: 9 \tTrain Loss: 4.300451 \tmse loss: 2.479648 \tmse2 loss: 1.820803\n",
            "Saving..\n",
            "Epoch: 10 \tTrain Loss: 4.274477 \tmse loss: 2.465263 \tmse2 loss: 1.809215\n",
            "Saving..\n",
            "Epoch: 11 \tTrain Loss: 4.314148 \tmse loss: 2.447080 \tmse2 loss: 1.867068\n",
            "Epoch: 12 \tTrain Loss: 4.204870 \tmse loss: 2.432808 \tmse2 loss: 1.772062\n",
            "Saving..\n",
            "Epoch: 13 \tTrain Loss: 4.237937 \tmse loss: 2.423360 \tmse2 loss: 1.814576\n",
            "Epoch: 14 \tTrain Loss: 4.161936 \tmse loss: 2.402747 \tmse2 loss: 1.759189\n",
            "Saving..\n",
            "Epoch: 15 \tTrain Loss: 4.181968 \tmse loss: 2.394821 \tmse2 loss: 1.787146\n",
            "Epoch: 16 \tTrain Loss: 4.198235 \tmse loss: 2.384576 \tmse2 loss: 1.813658\n",
            "Epoch: 17 \tTrain Loss: 4.131717 \tmse loss: 2.372162 \tmse2 loss: 1.759555\n",
            "Saving..\n",
            "Epoch: 18 \tTrain Loss: 4.097673 \tmse loss: 2.366959 \tmse2 loss: 1.730714\n",
            "Saving..\n",
            "Epoch: 19 \tTrain Loss: 4.132636 \tmse loss: 2.361576 \tmse2 loss: 1.771060\n",
            "Epoch: 20 \tTrain Loss: 4.049162 \tmse loss: 2.356473 \tmse2 loss: 1.692689\n",
            "Saving..\n",
            "Epoch: 21 \tTrain Loss: 4.081295 \tmse loss: 2.343556 \tmse2 loss: 1.737739\n",
            "Epoch: 22 \tTrain Loss: 4.039450 \tmse loss: 2.336637 \tmse2 loss: 1.702813\n",
            "Saving..\n",
            "Epoch: 23 \tTrain Loss: 4.002055 \tmse loss: 2.328772 \tmse2 loss: 1.673283\n",
            "Saving..\n",
            "Epoch: 24 \tTrain Loss: 4.127426 \tmse loss: 2.326160 \tmse2 loss: 1.801266\n",
            "Epoch: 25 \tTrain Loss: 3.989767 \tmse loss: 2.320340 \tmse2 loss: 1.669427\n",
            "Saving..\n",
            "Epoch: 26 \tTrain Loss: 3.984869 \tmse loss: 2.311248 \tmse2 loss: 1.673621\n",
            "Saving..\n",
            "Epoch: 27 \tTrain Loss: 4.042776 \tmse loss: 2.310111 \tmse2 loss: 1.732666\n",
            "Epoch: 28 \tTrain Loss: 3.970898 \tmse loss: 2.303734 \tmse2 loss: 1.667164\n",
            "Saving..\n",
            "Epoch: 29 \tTrain Loss: 3.973630 \tmse loss: 2.302214 \tmse2 loss: 1.671415\n",
            "Epoch: 30 \tTrain Loss: 4.010978 \tmse loss: 2.297909 \tmse2 loss: 1.713070\n",
            "Epoch: 31 \tTrain Loss: 3.987254 \tmse loss: 2.310320 \tmse2 loss: 1.676935\n",
            "Epoch: 32 \tTrain Loss: 3.984069 \tmse loss: 2.289921 \tmse2 loss: 1.694147\n",
            "Epoch: 33 \tTrain Loss: 3.906743 \tmse loss: 2.286736 \tmse2 loss: 1.620008\n",
            "Saving..\n",
            "Epoch: 34 \tTrain Loss: 3.969659 \tmse loss: 2.282190 \tmse2 loss: 1.687469\n",
            "Epoch: 35 \tTrain Loss: 3.925114 \tmse loss: 2.276585 \tmse2 loss: 1.648529\n",
            "Epoch: 36 \tTrain Loss: 3.981120 \tmse loss: 2.276685 \tmse2 loss: 1.704435\n",
            "Epoch: 37 \tTrain Loss: 3.935492 \tmse loss: 2.275990 \tmse2 loss: 1.659502\n",
            "Epoch: 38 \tTrain Loss: 3.942413 \tmse loss: 2.274116 \tmse2 loss: 1.668298\n",
            "Epoch: 39 \tTrain Loss: 3.957719 \tmse loss: 2.270314 \tmse2 loss: 1.687405\n",
            "Epoch: 40 \tTrain Loss: 3.878466 \tmse loss: 2.265898 \tmse2 loss: 1.612568\n",
            "Saving..\n",
            "Epoch: 41 \tTrain Loss: 3.962000 \tmse loss: 2.262411 \tmse2 loss: 1.699588\n",
            "Epoch: 42 \tTrain Loss: 3.914730 \tmse loss: 2.263000 \tmse2 loss: 1.651730\n",
            "Epoch: 43 \tTrain Loss: 3.977499 \tmse loss: 2.258286 \tmse2 loss: 1.719213\n",
            "Epoch: 44 \tTrain Loss: 3.910816 \tmse loss: 2.258013 \tmse2 loss: 1.652802\n",
            "Epoch: 45 \tTrain Loss: 3.905534 \tmse loss: 2.252712 \tmse2 loss: 1.652822\n",
            "Epoch: 46 \tTrain Loss: 3.934447 \tmse loss: 2.256121 \tmse2 loss: 1.678325\n",
            "Epoch: 47 \tTrain Loss: 3.868122 \tmse loss: 2.251596 \tmse2 loss: 1.616527\n",
            "Saving..\n",
            "Epoch: 48 \tTrain Loss: 3.912687 \tmse loss: 2.248324 \tmse2 loss: 1.664364\n",
            "Epoch: 49 \tTrain Loss: 3.884493 \tmse loss: 2.248140 \tmse2 loss: 1.636353\n",
            "Epoch: 50 \tTrain Loss: 3.945750 \tmse loss: 2.242608 \tmse2 loss: 1.703143\n",
            "Epoch: 51 \tTrain Loss: 3.908133 \tmse loss: 2.243763 \tmse2 loss: 1.664370\n",
            "Epoch: 52 \tTrain Loss: 3.920016 \tmse loss: 2.241278 \tmse2 loss: 1.678738\n",
            "Epoch: 53 \tTrain Loss: 3.858428 \tmse loss: 2.241963 \tmse2 loss: 1.616464\n",
            "Saving..\n",
            "Epoch: 54 \tTrain Loss: 3.854264 \tmse loss: 2.237839 \tmse2 loss: 1.616426\n",
            "Saving..\n",
            "Epoch: 55 \tTrain Loss: 3.826072 \tmse loss: 2.237239 \tmse2 loss: 1.588834\n",
            "Saving..\n",
            "Epoch: 56 \tTrain Loss: 3.833050 \tmse loss: 2.234172 \tmse2 loss: 1.598877\n",
            "Epoch: 57 \tTrain Loss: 3.790773 \tmse loss: 2.232259 \tmse2 loss: 1.558514\n",
            "Saving..\n",
            "Epoch: 58 \tTrain Loss: 3.875974 \tmse loss: 2.232554 \tmse2 loss: 1.643420\n",
            "Epoch: 59 \tTrain Loss: 3.886937 \tmse loss: 2.229300 \tmse2 loss: 1.657636\n",
            "Epoch: 60 \tTrain Loss: 3.841357 \tmse loss: 2.227947 \tmse2 loss: 1.613410\n",
            "Epoch: 61 \tTrain Loss: 3.853950 \tmse loss: 2.226477 \tmse2 loss: 1.627473\n",
            "Epoch: 62 \tTrain Loss: 3.776017 \tmse loss: 2.227669 \tmse2 loss: 1.548348\n",
            "Saving..\n",
            "Epoch: 63 \tTrain Loss: 3.856483 \tmse loss: 2.225468 \tmse2 loss: 1.631014\n",
            "Epoch: 64 \tTrain Loss: 3.785700 \tmse loss: 2.226008 \tmse2 loss: 1.559692\n",
            "Epoch: 65 \tTrain Loss: 3.849824 \tmse loss: 2.221591 \tmse2 loss: 1.628232\n",
            "Epoch: 66 \tTrain Loss: 3.828144 \tmse loss: 2.219339 \tmse2 loss: 1.608805\n",
            "Epoch: 67 \tTrain Loss: 3.809619 \tmse loss: 2.222637 \tmse2 loss: 1.586982\n",
            "Epoch: 68 \tTrain Loss: 3.849566 \tmse loss: 2.218470 \tmse2 loss: 1.631096\n",
            "Epoch: 69 \tTrain Loss: 3.799551 \tmse loss: 2.220548 \tmse2 loss: 1.579003\n",
            "Epoch: 70 \tTrain Loss: 3.838902 \tmse loss: 2.217067 \tmse2 loss: 1.621835\n",
            "Epoch: 71 \tTrain Loss: 3.790363 \tmse loss: 2.214844 \tmse2 loss: 1.575520\n",
            "Epoch: 72 \tTrain Loss: 3.790450 \tmse loss: 2.214968 \tmse2 loss: 1.575481\n",
            "Epoch: 73 \tTrain Loss: 3.759430 \tmse loss: 2.213534 \tmse2 loss: 1.545897\n",
            "Saving..\n",
            "Epoch: 74 \tTrain Loss: 3.832480 \tmse loss: 2.214151 \tmse2 loss: 1.618328\n",
            "Epoch: 75 \tTrain Loss: 3.845364 \tmse loss: 2.214371 \tmse2 loss: 1.630993\n",
            "Epoch: 76 \tTrain Loss: 3.803837 \tmse loss: 2.211776 \tmse2 loss: 1.592061\n",
            "Epoch: 77 \tTrain Loss: 3.814230 \tmse loss: 2.213275 \tmse2 loss: 1.600954\n",
            "Epoch: 78 \tTrain Loss: 3.791293 \tmse loss: 2.209081 \tmse2 loss: 1.582212\n",
            "Epoch: 79 \tTrain Loss: 3.868975 \tmse loss: 2.207222 \tmse2 loss: 1.661754\n",
            "Epoch: 80 \tTrain Loss: 3.792081 \tmse loss: 2.208979 \tmse2 loss: 1.583102\n",
            "Epoch: 81 \tTrain Loss: 3.822955 \tmse loss: 2.206245 \tmse2 loss: 1.616710\n",
            "Epoch: 82 \tTrain Loss: 3.845671 \tmse loss: 2.207343 \tmse2 loss: 1.638328\n",
            "Epoch: 83 \tTrain Loss: 3.834843 \tmse loss: 2.205240 \tmse2 loss: 1.629603\n",
            "Epoch: 84 \tTrain Loss: 3.805325 \tmse loss: 2.205623 \tmse2 loss: 1.599702\n",
            "Epoch: 85 \tTrain Loss: 3.808799 \tmse loss: 2.202371 \tmse2 loss: 1.606428\n",
            "Epoch: 86 \tTrain Loss: 3.767261 \tmse loss: 2.202429 \tmse2 loss: 1.564833\n",
            "Epoch: 87 \tTrain Loss: 3.863575 \tmse loss: 2.204288 \tmse2 loss: 1.659286\n",
            "Epoch: 88 \tTrain Loss: 3.752351 \tmse loss: 2.200975 \tmse2 loss: 1.551376\n",
            "Saving..\n",
            "Epoch: 89 \tTrain Loss: 3.845682 \tmse loss: 2.199071 \tmse2 loss: 1.646611\n",
            "Epoch: 90 \tTrain Loss: 3.754134 \tmse loss: 2.199297 \tmse2 loss: 1.554837\n",
            "Epoch: 91 \tTrain Loss: 3.830484 \tmse loss: 2.200141 \tmse2 loss: 1.630343\n",
            "Epoch: 92 \tTrain Loss: 3.777850 \tmse loss: 2.197678 \tmse2 loss: 1.580172\n",
            "Epoch: 93 \tTrain Loss: 3.789671 \tmse loss: 2.197279 \tmse2 loss: 1.592392\n",
            "Epoch: 94 \tTrain Loss: 3.784913 \tmse loss: 2.197601 \tmse2 loss: 1.587312\n",
            "Epoch: 95 \tTrain Loss: 3.819384 \tmse loss: 2.196122 \tmse2 loss: 1.623262\n",
            "Epoch: 96 \tTrain Loss: 3.820010 \tmse loss: 2.195397 \tmse2 loss: 1.624612\n",
            "Epoch: 97 \tTrain Loss: 3.818604 \tmse loss: 2.195291 \tmse2 loss: 1.623313\n",
            "Epoch: 98 \tTrain Loss: 3.799754 \tmse loss: 2.193857 \tmse2 loss: 1.605897\n",
            "Epoch: 99 \tTrain Loss: 3.810735 \tmse loss: 2.193996 \tmse2 loss: 1.616739\n",
            "Epoch: 100 \tTrain Loss: 3.804020 \tmse loss: 2.192475 \tmse2 loss: 1.611545\n",
            "Epoch: 101 \tTrain Loss: 3.775496 \tmse loss: 2.192804 \tmse2 loss: 1.582691\n",
            "Epoch: 102 \tTrain Loss: 3.785882 \tmse loss: 2.201557 \tmse2 loss: 1.584325\n",
            "Epoch: 103 \tTrain Loss: 3.738115 \tmse loss: 2.189989 \tmse2 loss: 1.548126\n",
            "Saving..\n",
            "Epoch: 104 \tTrain Loss: 3.811003 \tmse loss: 2.188959 \tmse2 loss: 1.622044\n",
            "Epoch: 105 \tTrain Loss: 3.758102 \tmse loss: 2.190767 \tmse2 loss: 1.567335\n",
            "Epoch: 106 \tTrain Loss: 3.826762 \tmse loss: 2.189714 \tmse2 loss: 1.637048\n",
            "Epoch: 107 \tTrain Loss: 3.831866 \tmse loss: 2.186958 \tmse2 loss: 1.644908\n",
            "Epoch: 108 \tTrain Loss: 3.747474 \tmse loss: 2.187812 \tmse2 loss: 1.559661\n",
            "Epoch: 109 \tTrain Loss: 3.769609 \tmse loss: 2.187766 \tmse2 loss: 1.581843\n",
            "Epoch: 110 \tTrain Loss: 3.696827 \tmse loss: 2.187991 \tmse2 loss: 1.508836\n",
            "Saving..\n",
            "Epoch: 111 \tTrain Loss: 3.709236 \tmse loss: 2.190424 \tmse2 loss: 1.518813\n",
            "Epoch: 112 \tTrain Loss: 3.799122 \tmse loss: 2.187799 \tmse2 loss: 1.611324\n",
            "Epoch: 113 \tTrain Loss: 3.738086 \tmse loss: 2.185507 \tmse2 loss: 1.552579\n",
            "Epoch: 114 \tTrain Loss: 3.764746 \tmse loss: 2.185039 \tmse2 loss: 1.579708\n",
            "Epoch: 115 \tTrain Loss: 3.803086 \tmse loss: 2.185683 \tmse2 loss: 1.617402\n",
            "Epoch: 116 \tTrain Loss: 3.742945 \tmse loss: 2.185350 \tmse2 loss: 1.557595\n",
            "Epoch: 117 \tTrain Loss: 3.736553 \tmse loss: 2.184938 \tmse2 loss: 1.551615\n",
            "Epoch: 118 \tTrain Loss: 3.799377 \tmse loss: 2.182594 \tmse2 loss: 1.616784\n",
            "Epoch: 119 \tTrain Loss: 3.872715 \tmse loss: 2.184131 \tmse2 loss: 1.688584\n",
            "Epoch: 120 \tTrain Loss: 3.779465 \tmse loss: 2.182131 \tmse2 loss: 1.597334\n",
            "Epoch: 121 \tTrain Loss: 3.818857 \tmse loss: 2.181519 \tmse2 loss: 1.637339\n",
            "Epoch: 122 \tTrain Loss: 3.757769 \tmse loss: 2.181140 \tmse2 loss: 1.576629\n",
            "Epoch: 123 \tTrain Loss: 3.760349 \tmse loss: 2.181542 \tmse2 loss: 1.578807\n",
            "Epoch: 124 \tTrain Loss: 3.813594 \tmse loss: 2.182409 \tmse2 loss: 1.631185\n",
            "Epoch: 125 \tTrain Loss: 3.766724 \tmse loss: 2.179236 \tmse2 loss: 1.587488\n",
            "Epoch: 126 \tTrain Loss: 3.799965 \tmse loss: 2.182197 \tmse2 loss: 1.617768\n",
            "Epoch: 127 \tTrain Loss: 3.803834 \tmse loss: 2.179823 \tmse2 loss: 1.624011\n",
            "Epoch: 128 \tTrain Loss: 3.720542 \tmse loss: 2.178688 \tmse2 loss: 1.541854\n",
            "Epoch: 129 \tTrain Loss: 3.825796 \tmse loss: 2.179582 \tmse2 loss: 1.646214\n",
            "Epoch: 130 \tTrain Loss: 3.751146 \tmse loss: 2.178781 \tmse2 loss: 1.572366\n",
            "Out of patience. \n",
            "\n",
            "/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_enc.pth\n",
            "/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_dec.pth\n"
          ]
        }
      ],
      "source": [
        "#Begin the training\n",
        "batch_size = args['batch_size']\n",
        "patience = args['patience']\n",
        "encoder = Encoder(args)\n",
        "decoder = Decoder(args)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "decoder = decoder.to(device)\n",
        "encoder = encoder.to(device)\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "#decoder loss function\n",
        "criterion = nn.MSELoss()\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "num_workers = 0\n",
        "\n",
        "#torch.Tensor returns float so if want long then use torch.tensor\n",
        "tensor_x = torch.Tensor(X_train)\n",
        "tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "    batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "t0 = time.time()\n",
        "if args['train']:\n",
        "    enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "    dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "    for epoch in range(args['epochs']):\n",
        "        train_loss = 0.0\n",
        "        tmse_loss = 0.0\n",
        "        tdiscr_loss = 0.0\n",
        "        # train for one epoch -- set nets to train mode\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "    \n",
        "        for images,labs in train_loader:\n",
        "        \n",
        "            # zero gradients for each batch\n",
        "            encoder.zero_grad()\n",
        "            decoder.zero_grad()\n",
        "            images, labs = images.to(device), labs.to(device)\n",
        "            labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "            # run images\n",
        "            z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "        \n",
        "            x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "            mse = criterion(x_hat,images)\n",
        "                    \n",
        "            resx = []\n",
        "            resy = []\n",
        "        \n",
        "            tc = np.random.choice(num_classes,1)\n",
        "            #tc = 9\n",
        "            xbeg = X_train[y_train == tc]\n",
        "            ybeg = y_train[y_train == tc] \n",
        "            xlen = len(xbeg)\n",
        "            nsamp = min(xlen, 100)\n",
        "            ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "            xclass = xbeg[ind]\n",
        "            yclass = ybeg[ind]\n",
        "        \n",
        "            xclen = len(xclass)\n",
        "            xcminus = np.arange(1,xclen)\n",
        "            \n",
        "            xcplus = np.append(xcminus,0)\n",
        "            xcnew = (xclass[[xcplus],:])\n",
        "            xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "        \n",
        "            xcnew = torch.Tensor(xcnew)\n",
        "            xcnew = xcnew.to(device)\n",
        "        \n",
        "            #encode xclass to feature space\n",
        "            xclass = torch.Tensor(xclass)\n",
        "            xclass = xclass.to(device)\n",
        "            xclass = encoder(xclass)\n",
        "        \n",
        "            xclass = xclass.detach().cpu().numpy()\n",
        "        \n",
        "            xc_enc = (xclass[[xcplus],:])\n",
        "            xc_enc = np.squeeze(xc_enc)\n",
        "        \n",
        "            xc_enc = torch.Tensor(xc_enc)\n",
        "            xc_enc = xc_enc.to(device)\n",
        "            \n",
        "            ximg = decoder(xc_enc)\n",
        "            \n",
        "            mse2 = criterion(ximg,xcnew)\n",
        "        \n",
        "            comb_loss = mse2 + mse\n",
        "            comb_loss.backward()\n",
        "        \n",
        "            enc_optim.step()\n",
        "            dec_optim.step()\n",
        "        \n",
        "            train_loss += comb_loss.item()*images.size(0)\n",
        "            tmse_loss += mse.item()*images.size(0)\n",
        "            tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "        train_loss = train_loss/len(train_loader)\n",
        "        tmse_loss = tmse_loss/len(train_loader)\n",
        "        tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "        print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "                train_loss,tmse_loss,tdiscr_loss))\n",
        "        \n",
        "    \n",
        "    \n",
        "        #store the best encoder and decoder models\n",
        "        #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "        #necessary for illustration purposes\n",
        "        if train_loss < best_loss:\n",
        "            print('Saving..')\n",
        "            patience = args['patience']\n",
        "            path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/bst_enc.pth'\n",
        "            path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/bst_dec.pth'\n",
        "          \n",
        "            torch.save(encoder.state_dict(), path_enc)\n",
        "            torch.save(decoder.state_dict(), path_dec)\n",
        "    \n",
        "            best_loss = train_loss\n",
        "        else:\n",
        "            patience = patience - 1\n",
        "\n",
        "        if patience == 0:\n",
        "            print('Out of patience. \\n')\n",
        "            break\n",
        "    \n",
        "    \n",
        "    #in addition, store the final model (may not be the best) for\n",
        "    #informational purposes\n",
        "    path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_enc.pth'\n",
        "    path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_dec.pth'\n",
        "    print(path_enc)\n",
        "    print(path_dec)\n",
        "    torch.save(encoder.state_dict(), path_enc)\n",
        "    torch.save(decoder.state_dict(), path_dec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoqPIVKqF5Ug",
        "outputId": "a2a38ff8-2737-4363-ece2-dee672661b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train imgs shape  (5992, 3, 56, 56)\n",
            "decy  (5992,)\n",
            "(18774, 9408)\n",
            "(18774,)\n"
          ]
        }
      ],
      "source": [
        "#Generate artificial images\n",
        "import torch\n",
        "np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "#path on the computer where the models are stored\n",
        "modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/'\n",
        "\n",
        "encf = []\n",
        "decf = []\n",
        "for p in range(1):\n",
        "    enc = modpth + '/bst_enc.pth'\n",
        "    dec = modpth + '/bst_dec.pth'\n",
        "    encf.append(enc)\n",
        "    decf.append(dec)\n",
        "\n",
        "for m in range(1):\n",
        "    print('train imgs shape ',X_train.shape) #(45000,3,32,32)\n",
        "    print('decy ',y_train.shape)\n",
        "    \n",
        "    #generate some images \n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    path_enc = encf[m]\n",
        "    path_dec = decf[m]\n",
        "\n",
        "    encoder = Encoder(args)\n",
        "    encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "    encoder = encoder.to(device)\n",
        "\n",
        "    decoder = Decoder(args)\n",
        "    decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "    decoder = decoder.to(device)\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    resx = []\n",
        "    resy = []\n",
        "\n",
        "    for i in [0,1,2,3,4,6]: #skip class 5 since it's max class\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "#        print(xclass.shape) #(500, 3, 32, 32)\n",
        "#        print(yclass[0]) #(500,)\n",
        "            \n",
        "        #encode xclass to feature space\n",
        "        xclass = torch.Tensor(xclass)\n",
        "        xclass = xclass.to(device)\n",
        "        xclass = encoder(xclass)\n",
        "            \n",
        "        xclass = xclass.detach().cpu().numpy()\n",
        "        n = np.max(counter) - counter[i]\n",
        "        xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "#        print(xsamp.shape) #(4500, 600)\n",
        "#        print(len(ysamp)) #4500\n",
        "        ysamp = np.array(ysamp)\n",
        "    \n",
        "        \"\"\"to generate samples for resnet\"\"\"   \n",
        "        xsamp = torch.Tensor(xsamp)\n",
        "        xsamp = xsamp.to(device)\n",
        "        ximg = decoder(xsamp)\n",
        "\n",
        "        ximn = ximg.detach().cpu().numpy()\n",
        "#        print(ximn.shape) \n",
        "        resx.append(ximn)\n",
        "        resy.append(ysamp)\n",
        "    \n",
        "    resx1 = np.vstack(resx)\n",
        "    resy1 = np.hstack(resy)\n",
        "#    print(resx1.shape) #(34720, 3, 32, 32)\n",
        "\n",
        "    resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "#    print(resx1.shape) #(34720, 3072)\n",
        "    \n",
        "    dec_x1 = X_train.reshape(X_train.shape[0],-1)\n",
        "#    print('decx1 ',dec_x1.shape)\n",
        "    combx = np.vstack((resx1,dec_x1))\n",
        "    comby = np.hstack((resy1,y_train))\n",
        "\n",
        "    print(combx.shape) #(45000, 3, 32, 32)\n",
        "    print(comby.shape) #(45000,)\n",
        "#    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76bpFBQcHLIY",
        "outputId": "3485974c-0165-4599-d30d-df3ac0871103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (18774, 56, 56, 3)\n",
            "Counter({0: 2682, 1: 2682, 2: 2682, 3: 2682, 4: 2682, 6: 2682, 5: 2682})\n"
          ]
        }
      ],
      "source": [
        "X_train = combx.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "X_train = moveaxis(X_train, 1, 3)\n",
        "print('X_train shape: ',X_train.shape)\n",
        "y_train = comby\n",
        "print(Counter(comby))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8SqyvSgX8sLO"
      },
      "outputs": [],
      "source": [
        "#X_train = X_train * 255\n",
        "#X_train = X_train.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "we4D35jnEOqs"
      },
      "outputs": [],
      "source": [
        "#de-standardization\n",
        "X_train = (X_train * X_train_std + X_train_mean).astype(int)\n",
        "X_val = (X_val * X_train_std + X_train_mean).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US0KkIaVlTdU"
      },
      "source": [
        "#Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_a_lPCqbibaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2a32cf-c6cd-406c-b8e9-6c9136fb8716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape:  (18774, 1)\n"
          ]
        }
      ],
      "source": [
        "y_train = y_train.reshape(-1, 1)\n",
        "y_val = y_val.reshape(-1, 1)\n",
        "print('y_train shape: ',y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ja5ZmgbCvDw5"
      },
      "outputs": [],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "y_val = to_categorical(y_val, num_classes = num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ioaoIkk4G2pf"
      },
      "outputs": [],
      "source": [
        "#X_val = X_val.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9QM00erNGU32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07cf6447-dbbe-48c6-de88-77a9704cbf91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18774, 56, 56, 3)\n",
            "(18774, 7)\n",
            "(193, 56, 56, 3)\n",
            "(193, 7)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6qneWL_Bs2U",
        "outputId": "22c2c4ff-5544-4dd8-b69a-af96b4b97616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data:  (9814, 32, 32, 3)\n",
            "Remaining Data:  (201, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.02, stratify=y, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vai7M7WSXVY4",
        "outputId": "b9bc1199-a518-4a8b-9d6e-4d6038efbafe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Data:  (416, 32, 32, 3)\n",
            "Val Data:  (416, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# stratified val and test (50%) \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_rem, y_rem, test_size=0.5, stratify=y_rem, random_state=1)\n",
        "\n",
        "print('Test Data: ', X_test.shape)\n",
        "print('Val Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I15HgVuhjFlm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVVOQPNiHXHw",
        "outputId": "a1e60310-4f3b-4063-8465-4d7120d225c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data:  (2015, 32, 32, 3)\n",
            "Test Data:  (224, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "#optional\n",
        "# stratified train and test (10%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Test Data: ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_oaUYYgJNV7",
        "outputId": "ca2f393a-0599-4cfc-b330-45d723f2bb06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data:  (3369, 32, 32, 3)\n",
            "Val Data:  (375, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "#optional\n",
        "# stratified train and val (10%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify=y, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Val Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZklPzWxCCtTW"
      },
      "source": [
        "Create and compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jFShRvTHnqi"
      },
      "outputs": [],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Classification\n",
        "Model from https://github.com/AnasBrital98/CNN-From-Scratch/tree/master/Inception-V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "A8eRZiucdYnP"
      },
      "outputs": [],
      "source": [
        "#USe TF.data\n",
        "import tensorflow as tf\n",
        "training_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "validation_data = tf.data.Dataset.from_tensor_slices((X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7xalxBh-3LNC"
      },
      "outputs": [],
      "source": [
        "autotune = tf.data.AUTOTUNE\n",
        "train_data_batches = training_data.shuffle(buffer_size=40000).batch(32).prefetch(buffer_size=autotune)\n",
        "valid_data_batches = validation_data.shuffle(buffer_size=10000).batch(32).prefetch(buffer_size=autotune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ge4UmF5R0a7V"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "rescale_layer = tf.keras.Sequential([layers.experimental.preprocessing.Rescaling(1./255)])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2), \n",
        "  layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3)),\n",
        "  layers.experimental.preprocessing.RandomTranslation(0.3, 0.3, fill_mode='reflect', interpolation='bilinear',)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mu6rr5apdJtf"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_DeepSMOTE.h5'\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_prc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=10, verbose=0, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=30,monitor='val_prc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rwwLiXUSG0IZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d7e3ef-0302-4266-8bca-55f8cbe3de70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n",
            "Epoch 1/1000\n",
            "587/587 [==============================] - ETA: 0s - loss: 1.2731 - accuracy: 0.5204 - prc: 0.5734\n",
            "Epoch 1: val_prc improved from -inf to 0.83135, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 22s 27ms/step - loss: 1.2731 - accuracy: 0.5204 - prc: 0.5734 - val_loss: 0.7218 - val_accuracy: 0.6891 - val_prc: 0.8314 - lr: 5.0000e-04\n",
            "Epoch 2/1000\n",
            "587/587 [==============================] - ETA: 0s - loss: 1.0813 - accuracy: 0.5871 - prc: 0.6620\n",
            "Epoch 2: val_prc did not improve from 0.83135\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 1.0813 - accuracy: 0.5871 - prc: 0.6620 - val_loss: 0.7416 - val_accuracy: 0.7306 - val_prc: 0.8164 - lr: 5.0000e-04\n",
            "Epoch 3/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 1.0219 - accuracy: 0.6094 - prc: 0.6906\n",
            "Epoch 3: val_prc did not improve from 0.83135\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 1.0220 - accuracy: 0.6095 - prc: 0.6908 - val_loss: 0.7744 - val_accuracy: 0.6995 - val_prc: 0.8180 - lr: 5.0000e-04\n",
            "Epoch 4/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.9771 - accuracy: 0.6269 - prc: 0.7114\n",
            "Epoch 4: val_prc did not improve from 0.83135\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.9771 - accuracy: 0.6268 - prc: 0.7114 - val_loss: 0.6913 - val_accuracy: 0.6995 - val_prc: 0.8279 - lr: 5.0000e-04\n",
            "Epoch 5/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.9542 - accuracy: 0.6349 - prc: 0.7238\n",
            "Epoch 5: val_prc improved from 0.83135 to 0.83197, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 13s 22ms/step - loss: 0.9539 - accuracy: 0.6352 - prc: 0.7239 - val_loss: 0.6795 - val_accuracy: 0.6839 - val_prc: 0.8320 - lr: 5.0000e-04\n",
            "Epoch 6/1000\n",
            "587/587 [==============================] - ETA: 0s - loss: 0.9415 - accuracy: 0.6412 - prc: 0.7275\n",
            "Epoch 6: val_prc did not improve from 0.83197\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.9415 - accuracy: 0.6412 - prc: 0.7275 - val_loss: 0.7446 - val_accuracy: 0.7150 - val_prc: 0.8253 - lr: 5.0000e-04\n",
            "Epoch 7/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.9202 - accuracy: 0.6463 - prc: 0.7396\n",
            "Epoch 7: val_prc did not improve from 0.83197\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.9200 - accuracy: 0.6465 - prc: 0.7397 - val_loss: 0.7432 - val_accuracy: 0.7047 - val_prc: 0.8226 - lr: 5.0000e-04\n",
            "Epoch 8/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.9024 - accuracy: 0.6527 - prc: 0.7447\n",
            "Epoch 8: val_prc did not improve from 0.83197\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.9029 - accuracy: 0.6525 - prc: 0.7445 - val_loss: 0.7572 - val_accuracy: 0.6891 - val_prc: 0.8139 - lr: 5.0000e-04\n",
            "Epoch 9/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8936 - accuracy: 0.6578 - prc: 0.7505\n",
            "Epoch 9: val_prc did not improve from 0.83197\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8940 - accuracy: 0.6578 - prc: 0.7504 - val_loss: 0.6967 - val_accuracy: 0.7358 - val_prc: 0.8259 - lr: 5.0000e-04\n",
            "Epoch 10/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8811 - accuracy: 0.6597 - prc: 0.7552\n",
            "Epoch 10: val_prc did not improve from 0.83197\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8814 - accuracy: 0.6595 - prc: 0.7550 - val_loss: 0.7370 - val_accuracy: 0.6891 - val_prc: 0.8231 - lr: 5.0000e-04\n",
            "Epoch 11/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8628 - accuracy: 0.6705 - prc: 0.7627\n",
            "Epoch 11: val_prc improved from 0.83197 to 0.83873, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 13s 22ms/step - loss: 0.8630 - accuracy: 0.6705 - prc: 0.7626 - val_loss: 0.6827 - val_accuracy: 0.7150 - val_prc: 0.8387 - lr: 5.0000e-04\n",
            "Epoch 12/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.8549 - accuracy: 0.6715 - prc: 0.7663\n",
            "Epoch 12: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.8554 - accuracy: 0.6712 - prc: 0.7660 - val_loss: 0.7397 - val_accuracy: 0.6891 - val_prc: 0.8229 - lr: 5.0000e-04\n",
            "Epoch 13/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8491 - accuracy: 0.6702 - prc: 0.7687\n",
            "Epoch 13: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8493 - accuracy: 0.6700 - prc: 0.7686 - val_loss: 0.7651 - val_accuracy: 0.6788 - val_prc: 0.8052 - lr: 5.0000e-04\n",
            "Epoch 14/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8452 - accuracy: 0.6756 - prc: 0.7708\n",
            "Epoch 14: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8455 - accuracy: 0.6757 - prc: 0.7707 - val_loss: 0.7231 - val_accuracy: 0.7150 - val_prc: 0.8265 - lr: 5.0000e-04\n",
            "Epoch 15/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8314 - accuracy: 0.6808 - prc: 0.7776\n",
            "Epoch 15: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8310 - accuracy: 0.6810 - prc: 0.7777 - val_loss: 0.7487 - val_accuracy: 0.6995 - val_prc: 0.8088 - lr: 5.0000e-04\n",
            "Epoch 16/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8027 - accuracy: 0.6934 - prc: 0.7910\n",
            "Epoch 16: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8027 - accuracy: 0.6935 - prc: 0.7910 - val_loss: 0.7457 - val_accuracy: 0.7098 - val_prc: 0.8242 - lr: 2.5000e-04\n",
            "Epoch 17/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7907 - accuracy: 0.6945 - prc: 0.7933\n",
            "Epoch 17: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7904 - accuracy: 0.6947 - prc: 0.7934 - val_loss: 0.7116 - val_accuracy: 0.7202 - val_prc: 0.8316 - lr: 2.5000e-04\n",
            "Epoch 18/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7901 - accuracy: 0.6990 - prc: 0.7969\n",
            "Epoch 18: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7904 - accuracy: 0.6989 - prc: 0.7968 - val_loss: 0.7190 - val_accuracy: 0.7461 - val_prc: 0.8287 - lr: 2.5000e-04\n",
            "Epoch 19/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7777 - accuracy: 0.7020 - prc: 0.8016\n",
            "Epoch 19: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7776 - accuracy: 0.7020 - prc: 0.8017 - val_loss: 0.7634 - val_accuracy: 0.7461 - val_prc: 0.8163 - lr: 2.5000e-04\n",
            "Epoch 20/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7646 - accuracy: 0.7068 - prc: 0.8065\n",
            "Epoch 20: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7646 - accuracy: 0.7067 - prc: 0.8064 - val_loss: 0.7292 - val_accuracy: 0.7306 - val_prc: 0.8283 - lr: 2.5000e-04\n",
            "Epoch 21/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7682 - accuracy: 0.7061 - prc: 0.8054\n",
            "Epoch 21: val_prc improved from 0.83873 to 0.84058, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 13s 22ms/step - loss: 0.7684 - accuracy: 0.7059 - prc: 0.8054 - val_loss: 0.6883 - val_accuracy: 0.7306 - val_prc: 0.8406 - lr: 2.5000e-04\n",
            "Epoch 22/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7680 - accuracy: 0.7088 - prc: 0.8050\n",
            "Epoch 22: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7684 - accuracy: 0.7087 - prc: 0.8048 - val_loss: 0.7329 - val_accuracy: 0.7150 - val_prc: 0.8226 - lr: 2.5000e-04\n",
            "Epoch 23/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7619 - accuracy: 0.7094 - prc: 0.8069\n",
            "Epoch 23: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7618 - accuracy: 0.7094 - prc: 0.8070 - val_loss: 0.7181 - val_accuracy: 0.7047 - val_prc: 0.8208 - lr: 2.5000e-04\n",
            "Epoch 24/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7546 - accuracy: 0.7101 - prc: 0.8100\n",
            "Epoch 24: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7546 - accuracy: 0.7102 - prc: 0.8100 - val_loss: 0.7130 - val_accuracy: 0.7098 - val_prc: 0.8259 - lr: 2.5000e-04\n",
            "Epoch 25/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7551 - accuracy: 0.7135 - prc: 0.8113\n",
            "Epoch 25: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7552 - accuracy: 0.7134 - prc: 0.8113 - val_loss: 0.6936 - val_accuracy: 0.7461 - val_prc: 0.8403 - lr: 2.5000e-04\n",
            "Epoch 26/1000\n",
            "587/587 [==============================] - ETA: 0s - loss: 0.7335 - accuracy: 0.7197 - prc: 0.8195\n",
            "Epoch 26: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7335 - accuracy: 0.7197 - prc: 0.8195 - val_loss: 0.6809 - val_accuracy: 0.7358 - val_prc: 0.8391 - lr: 1.2500e-04\n",
            "Epoch 27/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7314 - accuracy: 0.7165 - prc: 0.8194\n",
            "Epoch 27: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7313 - accuracy: 0.7164 - prc: 0.8194 - val_loss: 0.7132 - val_accuracy: 0.7409 - val_prc: 0.8308 - lr: 1.2500e-04\n",
            "Epoch 28/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7276 - accuracy: 0.7237 - prc: 0.8226\n",
            "Epoch 28: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7278 - accuracy: 0.7236 - prc: 0.8225 - val_loss: 0.7177 - val_accuracy: 0.7358 - val_prc: 0.8327 - lr: 1.2500e-04\n",
            "Epoch 29/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7339 - accuracy: 0.7181 - prc: 0.8195\n",
            "Epoch 29: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7338 - accuracy: 0.7182 - prc: 0.8195 - val_loss: 0.7326 - val_accuracy: 0.7306 - val_prc: 0.8244 - lr: 1.2500e-04\n",
            "Epoch 30/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7256 - accuracy: 0.7203 - prc: 0.8224\n",
            "Epoch 30: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7254 - accuracy: 0.7204 - prc: 0.8225 - val_loss: 0.6942 - val_accuracy: 0.7461 - val_prc: 0.8370 - lr: 1.2500e-04\n",
            "Epoch 31/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7243 - accuracy: 0.7232 - prc: 0.8218\n",
            "Epoch 31: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7244 - accuracy: 0.7232 - prc: 0.8218 - val_loss: 0.7041 - val_accuracy: 0.7358 - val_prc: 0.8354 - lr: 1.2500e-04\n",
            "Epoch 32/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7139 - accuracy: 0.7259 - prc: 0.8273\n",
            "Epoch 32: val_prc improved from 0.84058 to 0.84312, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 13s 23ms/step - loss: 0.7141 - accuracy: 0.7258 - prc: 0.8273 - val_loss: 0.6859 - val_accuracy: 0.7720 - val_prc: 0.8431 - lr: 1.2500e-04\n",
            "Epoch 33/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.7197 - accuracy: 0.7232 - prc: 0.8238\n",
            "Epoch 33: val_prc improved from 0.84312 to 0.84590, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 12s 21ms/step - loss: 0.7190 - accuracy: 0.7235 - prc: 0.8241 - val_loss: 0.6685 - val_accuracy: 0.7306 - val_prc: 0.8459 - lr: 1.2500e-04\n",
            "Epoch 34/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7217 - accuracy: 0.7255 - prc: 0.8226\n",
            "Epoch 34: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7216 - accuracy: 0.7256 - prc: 0.8227 - val_loss: 0.6916 - val_accuracy: 0.7150 - val_prc: 0.8357 - lr: 1.2500e-04\n",
            "Epoch 35/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7128 - accuracy: 0.7302 - prc: 0.8274\n",
            "Epoch 35: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7128 - accuracy: 0.7302 - prc: 0.8274 - val_loss: 0.7399 - val_accuracy: 0.6995 - val_prc: 0.8210 - lr: 1.2500e-04\n",
            "Epoch 36/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7076 - accuracy: 0.7333 - prc: 0.8307\n",
            "Epoch 36: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7072 - accuracy: 0.7335 - prc: 0.8308 - val_loss: 0.7099 - val_accuracy: 0.7150 - val_prc: 0.8271 - lr: 1.2500e-04\n",
            "Epoch 37/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7055 - accuracy: 0.7341 - prc: 0.8321\n",
            "Epoch 37: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7052 - accuracy: 0.7343 - prc: 0.8322 - val_loss: 0.7393 - val_accuracy: 0.7098 - val_prc: 0.8170 - lr: 1.2500e-04\n",
            "Epoch 38/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7142 - accuracy: 0.7266 - prc: 0.8263\n",
            "Epoch 38: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7144 - accuracy: 0.7266 - prc: 0.8263 - val_loss: 0.8047 - val_accuracy: 0.6943 - val_prc: 0.8000 - lr: 1.2500e-04\n",
            "Epoch 39/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7218 - accuracy: 0.7241 - prc: 0.8242\n",
            "Epoch 39: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7216 - accuracy: 0.7242 - prc: 0.8242 - val_loss: 0.7356 - val_accuracy: 0.7513 - val_prc: 0.8243 - lr: 1.2500e-04\n",
            "Epoch 40/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7044 - accuracy: 0.7299 - prc: 0.8297\n",
            "Epoch 40: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7048 - accuracy: 0.7298 - prc: 0.8295 - val_loss: 0.7664 - val_accuracy: 0.7047 - val_prc: 0.8124 - lr: 1.2500e-04\n",
            "Epoch 41/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7033 - accuracy: 0.7330 - prc: 0.8325\n",
            "Epoch 41: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7034 - accuracy: 0.7329 - prc: 0.8324 - val_loss: 0.7352 - val_accuracy: 0.7461 - val_prc: 0.8189 - lr: 1.2500e-04\n",
            "Epoch 42/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7071 - accuracy: 0.7283 - prc: 0.8301\n",
            "Epoch 42: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7070 - accuracy: 0.7283 - prc: 0.8301 - val_loss: 0.7604 - val_accuracy: 0.7202 - val_prc: 0.8146 - lr: 1.2500e-04\n",
            "Epoch 43/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7006 - accuracy: 0.7328 - prc: 0.8328\n",
            "Epoch 43: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7004 - accuracy: 0.7329 - prc: 0.8329 - val_loss: 0.7399 - val_accuracy: 0.7150 - val_prc: 0.8282 - lr: 1.2500e-04\n",
            "Epoch 44/1000\n",
            "587/587 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.7351 - prc: 0.8349\n",
            "Epoch 44: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6956 - accuracy: 0.7351 - prc: 0.8349 - val_loss: 0.7641 - val_accuracy: 0.6839 - val_prc: 0.8094 - lr: 6.2500e-05\n",
            "Epoch 45/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6837 - accuracy: 0.7400 - prc: 0.8392\n",
            "Epoch 45: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6837 - accuracy: 0.7400 - prc: 0.8392 - val_loss: 0.7361 - val_accuracy: 0.7254 - val_prc: 0.8218 - lr: 6.2500e-05\n",
            "Epoch 46/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6879 - accuracy: 0.7364 - prc: 0.8368\n",
            "Epoch 46: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6879 - accuracy: 0.7364 - prc: 0.8368 - val_loss: 0.7576 - val_accuracy: 0.7202 - val_prc: 0.8160 - lr: 6.2500e-05\n",
            "Epoch 47/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6860 - accuracy: 0.7378 - prc: 0.8385\n",
            "Epoch 47: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6862 - accuracy: 0.7378 - prc: 0.8384 - val_loss: 0.7268 - val_accuracy: 0.7098 - val_prc: 0.8227 - lr: 6.2500e-05\n",
            "Epoch 48/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6910 - accuracy: 0.7368 - prc: 0.8363\n",
            "Epoch 48: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6911 - accuracy: 0.7367 - prc: 0.8363 - val_loss: 0.7554 - val_accuracy: 0.7202 - val_prc: 0.8114 - lr: 6.2500e-05\n",
            "Epoch 49/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6845 - accuracy: 0.7368 - prc: 0.8392\n",
            "Epoch 49: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6847 - accuracy: 0.7367 - prc: 0.8391 - val_loss: 0.7579 - val_accuracy: 0.7098 - val_prc: 0.8145 - lr: 6.2500e-05\n",
            "Epoch 50/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6780 - accuracy: 0.7393 - prc: 0.8412\n",
            "Epoch 50: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6784 - accuracy: 0.7393 - prc: 0.8412 - val_loss: 0.7606 - val_accuracy: 0.7202 - val_prc: 0.8120 - lr: 6.2500e-05\n",
            "Epoch 51/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6844 - accuracy: 0.7401 - prc: 0.8394\n",
            "Epoch 51: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6845 - accuracy: 0.7400 - prc: 0.8394 - val_loss: 0.7536 - val_accuracy: 0.7150 - val_prc: 0.8157 - lr: 6.2500e-05\n",
            "Epoch 52/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.7375 - prc: 0.8403\n",
            "Epoch 52: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6825 - accuracy: 0.7375 - prc: 0.8403 - val_loss: 0.7414 - val_accuracy: 0.7358 - val_prc: 0.8190 - lr: 6.2500e-05\n",
            "Epoch 53/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6787 - accuracy: 0.7443 - prc: 0.8426\n",
            "Epoch 53: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6784 - accuracy: 0.7444 - prc: 0.8427 - val_loss: 0.7151 - val_accuracy: 0.6995 - val_prc: 0.8313 - lr: 6.2500e-05\n",
            "Epoch 54/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6809 - accuracy: 0.7418 - prc: 0.8404\n",
            "Epoch 54: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.6808 - accuracy: 0.7417 - prc: 0.8404 - val_loss: 0.7543 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 3.1250e-05\n",
            "Epoch 55/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6745 - accuracy: 0.7429 - prc: 0.8420\n",
            "Epoch 55: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6746 - accuracy: 0.7427 - prc: 0.8419 - val_loss: 0.7430 - val_accuracy: 0.7202 - val_prc: 0.8212 - lr: 3.1250e-05\n",
            "Epoch 56/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6858 - accuracy: 0.7380 - prc: 0.8390\n",
            "Epoch 56: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6858 - accuracy: 0.7379 - prc: 0.8390 - val_loss: 0.7498 - val_accuracy: 0.7254 - val_prc: 0.8179 - lr: 3.1250e-05\n",
            "Epoch 57/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6813 - accuracy: 0.7357 - prc: 0.8401\n",
            "Epoch 57: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6816 - accuracy: 0.7354 - prc: 0.8400 - val_loss: 0.7782 - val_accuracy: 0.7306 - val_prc: 0.8076 - lr: 3.1250e-05\n",
            "Epoch 58/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.7436 - prc: 0.8438\n",
            "Epoch 58: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6732 - accuracy: 0.7435 - prc: 0.8438 - val_loss: 0.7529 - val_accuracy: 0.7409 - val_prc: 0.8163 - lr: 3.1250e-05\n",
            "Epoch 59/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6694 - accuracy: 0.7415 - prc: 0.8439\n",
            "Epoch 59: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6694 - accuracy: 0.7415 - prc: 0.8439 - val_loss: 0.7706 - val_accuracy: 0.7461 - val_prc: 0.8103 - lr: 3.1250e-05\n",
            "Epoch 60/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6729 - accuracy: 0.7405 - prc: 0.8436\n",
            "Epoch 60: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6733 - accuracy: 0.7403 - prc: 0.8435 - val_loss: 0.7544 - val_accuracy: 0.7461 - val_prc: 0.8177 - lr: 3.1250e-05\n",
            "Epoch 61/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.7396 - prc: 0.8432\n",
            "Epoch 61: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6746 - accuracy: 0.7398 - prc: 0.8433 - val_loss: 0.7558 - val_accuracy: 0.7513 - val_prc: 0.8183 - lr: 3.1250e-05\n",
            "Epoch 62/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.6671 - accuracy: 0.7434 - prc: 0.8456\n",
            "Epoch 62: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6671 - accuracy: 0.7435 - prc: 0.8456 - val_loss: 0.7617 - val_accuracy: 0.7306 - val_prc: 0.8177 - lr: 3.1250e-05\n",
            "Epoch 63/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6765 - accuracy: 0.7408 - prc: 0.8419\n",
            "Epoch 63: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6770 - accuracy: 0.7406 - prc: 0.8417 - val_loss: 0.7741 - val_accuracy: 0.7254 - val_prc: 0.8087 - lr: 3.1250e-05\n",
            "Epoch 64/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.7442 - prc: 0.8451\n",
            "Epoch 64: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6709 - accuracy: 0.7443 - prc: 0.8452 - val_loss: 0.7707 - val_accuracy: 0.7202 - val_prc: 0.8110 - lr: 1.5625e-05\n",
            "Epoch 65/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6688 - accuracy: 0.7431 - prc: 0.8457\n",
            "Epoch 65: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6684 - accuracy: 0.7433 - prc: 0.8458 - val_loss: 0.7705 - val_accuracy: 0.7150 - val_prc: 0.8115 - lr: 1.5625e-05\n",
            "Epoch 66/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.6601 - accuracy: 0.7471 - prc: 0.8490\n",
            "Epoch 66: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6606 - accuracy: 0.7470 - prc: 0.8489 - val_loss: 0.7598 - val_accuracy: 0.7254 - val_prc: 0.8144 - lr: 1.5625e-05\n",
            "Epoch 67/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6602 - accuracy: 0.7520 - prc: 0.8489\n",
            "Epoch 67: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6602 - accuracy: 0.7521 - prc: 0.8489 - val_loss: 0.7683 - val_accuracy: 0.7098 - val_prc: 0.8124 - lr: 1.5625e-05\n",
            "Epoch 68/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6684 - accuracy: 0.7447 - prc: 0.8445\n",
            "Epoch 68: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6682 - accuracy: 0.7448 - prc: 0.8446 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "# this could also be the output a different Keras model or layer\n",
        "input_shape = X_train.shape[1:]\n",
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "x = data_augmentation(input_tensor)\n",
        "#x = rescale_layer(x)\n",
        "\n",
        "base_model = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)\n",
        "x = base_model(x)\n",
        "\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "#x = base_model.output\n",
        "#x = GlobalAveragePooling2D()(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "x = Flatten()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(128, activation='relu')(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "#predictions = Dense(9)(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=input_tensor, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "#model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# train the model on the new data for a few epochs\n",
        "#hst = model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val, y_val))\n",
        "\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=['accuracy', keras.metrics.AUC(name='prc', curve='PR')])\n",
        "#hst = model.fit(dataaugment.flow(X_train,y_train, batch_size=BATCH_SIZE),\n",
        "hst = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,      \n",
        "                    #steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WA3NkiOqePA"
      },
      "outputs": [],
      "source": [
        "# load the saved model\n",
        "#best_model = load_model(best_model_fpath)\n",
        "# evaluate the model\n",
        "#_, train_acc = best_model.evaluate(X_train, y_train, verbose=0)\n",
        "#_, test_acc = best_model.evaluate(X_val, y_val, verbose=0)\n",
        "#print('Train: %.3f, Val: %.3f' % (train_acc, test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vXnW3lmCgln3",
        "outputId": "63e65cd6-b6af-4e7e-8842-8569913d3794"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l8bZo4LoEiQf"
      },
      "outputs": [],
      "source": [
        "#finetune_model_fpath = '/content/drive/MyDrive/PHD/Model/finetune_model.h5'\n",
        "#mc_finetune = ModelCheckpoint(finetune_model_fpath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr1jnSM7yzJc",
        "outputId": "07060090-d74f-4b33-bae8-42d37b46678d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.6657 - accuracy: 0.7467 - prc: 0.8471\n",
            "Epoch 1: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 15s 20ms/step - loss: 0.6658 - accuracy: 0.7466 - prc: 0.8470 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 2/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6687 - accuracy: 0.7428 - prc: 0.8460\n",
            "Epoch 2: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6687 - accuracy: 0.7428 - prc: 0.8460 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 3/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6607 - accuracy: 0.7481 - prc: 0.8471\n",
            "Epoch 3: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6606 - accuracy: 0.7482 - prc: 0.8472 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 4/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6634 - accuracy: 0.7478 - prc: 0.8474\n",
            "Epoch 4: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6636 - accuracy: 0.7477 - prc: 0.8473 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 5/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6642 - accuracy: 0.7425 - prc: 0.8474\n",
            "Epoch 5: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6646 - accuracy: 0.7423 - prc: 0.8472 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 6/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.7414 - prc: 0.8429\n",
            "Epoch 6: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6715 - accuracy: 0.7414 - prc: 0.8429 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 7/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6684 - accuracy: 0.7431 - prc: 0.8448\n",
            "Epoch 7: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6682 - accuracy: 0.7431 - prc: 0.8449 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 8/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6615 - accuracy: 0.7485 - prc: 0.8486\n",
            "Epoch 8: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6617 - accuracy: 0.7484 - prc: 0.8486 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 9/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6598 - accuracy: 0.7454 - prc: 0.8473\n",
            "Epoch 9: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6596 - accuracy: 0.7454 - prc: 0.8474 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 10/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6663 - accuracy: 0.7468 - prc: 0.8468\n",
            "Epoch 10: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.6665 - accuracy: 0.7467 - prc: 0.8468 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 11/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.7413 - prc: 0.8441\n",
            "Epoch 11: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6717 - accuracy: 0.7415 - prc: 0.8443 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 12/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6676 - accuracy: 0.7427 - prc: 0.8442\n",
            "Epoch 12: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6674 - accuracy: 0.7428 - prc: 0.8444 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 13/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6625 - accuracy: 0.7462 - prc: 0.8476\n",
            "Epoch 13: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6625 - accuracy: 0.7461 - prc: 0.8476 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 14/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.7468 - prc: 0.8446\n",
            "Epoch 14: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6721 - accuracy: 0.7468 - prc: 0.8446 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 15/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6738 - accuracy: 0.7447 - prc: 0.8430\n",
            "Epoch 15: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6735 - accuracy: 0.7448 - prc: 0.8431 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 16/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6679 - accuracy: 0.7467 - prc: 0.8460\n",
            "Epoch 16: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6678 - accuracy: 0.7468 - prc: 0.8461 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 17/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6672 - accuracy: 0.7461 - prc: 0.8460\n",
            "Epoch 17: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6669 - accuracy: 0.7462 - prc: 0.8460 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 18/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6640 - accuracy: 0.7463 - prc: 0.8477\n",
            "Epoch 18: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6638 - accuracy: 0.7462 - prc: 0.8477 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 19/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.7464 - prc: 0.8443\n",
            "Epoch 19: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6701 - accuracy: 0.7466 - prc: 0.8443 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 20/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6652 - accuracy: 0.7439 - prc: 0.8467\n",
            "Epoch 20: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6654 - accuracy: 0.7438 - prc: 0.8466 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 21/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.7431 - prc: 0.8443\n",
            "Epoch 21: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6706 - accuracy: 0.7432 - prc: 0.8445 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 22/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6586 - accuracy: 0.7481 - prc: 0.8497\n",
            "Epoch 22: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6585 - accuracy: 0.7481 - prc: 0.8498 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 23/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6757 - accuracy: 0.7426 - prc: 0.8427\n",
            "Epoch 23: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6759 - accuracy: 0.7426 - prc: 0.8426 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 24/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6647 - accuracy: 0.7506 - prc: 0.8473\n",
            "Epoch 24: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6646 - accuracy: 0.7505 - prc: 0.8473 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 25/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6626 - accuracy: 0.7434 - prc: 0.8462\n",
            "Epoch 25: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6627 - accuracy: 0.7433 - prc: 0.8461 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 26/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.7414 - prc: 0.8421\n",
            "Epoch 26: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.6747 - accuracy: 0.7416 - prc: 0.8422 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 27/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6650 - accuracy: 0.7448 - prc: 0.8459\n",
            "Epoch 27: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.6650 - accuracy: 0.7448 - prc: 0.8458 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 28/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6639 - accuracy: 0.7472 - prc: 0.8462\n",
            "Epoch 28: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.6640 - accuracy: 0.7472 - prc: 0.8461 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 29/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.7419 - prc: 0.8437\n",
            "Epoch 29: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6717 - accuracy: 0.7418 - prc: 0.8437 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 30/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6636 - accuracy: 0.7448 - prc: 0.8472\n",
            "Epoch 30: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6633 - accuracy: 0.7450 - prc: 0.8472 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 31/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6624 - accuracy: 0.7456 - prc: 0.8467\n",
            "Epoch 31: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6622 - accuracy: 0.7456 - prc: 0.8468 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# we chose to train the top 2 resnet blocks, i.e. we will freeze\n",
        "# the first 49 layers and unfreeze the rest:\n",
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "#model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "#hst2 = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val, y_val))\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=['accuracy', keras.metrics.AUC(name='prc', curve='PR')])\n",
        "#hst2 = model.fit(dataaugment.flow(X_train,y_train, batch_size=BATCH_SIZE),\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        " #                   steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SPz8NH1Oylv9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "\n",
        "model.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS3ewyxO_anU",
        "outputId": "8f098913-5987-48b4-adcb-3c5a7f7a593b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balanced accuracy on training 0.6735378715244487\n",
            "balanced accuracy on validation 0.4477302894550282\n",
            "Score on val data:  (0.5095860566448802, 0.4477302894550282, 0.44639760895918534, None)\n"
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath)\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3IyWjdGG4Xq"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(best_model_fpath)\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['accuracy'])\n",
        "plt.plot(hst2.history['val_accuracy'])\n",
        "plt.title('model accuracy after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing\n",
        "Result from ISIC Live\n",
        "last_model: 0.506\n",
        "best_model: 0.478"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']\n",
        "#df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60LYAT7VsNOZ",
        "outputId": "e16b1d98-be3b-4a38-972b-4c13bea70bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 56, 56, 3)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.asarray(df_test['image'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "dIX0AmEFNv3Y",
        "outputId": "4d039e7b-75b5-4203-a56e-cdbec370eea2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-d449c10de396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mY_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Y_pred2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# rounded labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
          ]
        }
      ],
      "source": [
        "# predicted labels\n",
        "Y_pred2 = last_model.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)\n",
        "# rounded labels\n",
        "y_pred2 = np.argmax(Y_pred2, axis=1)\n",
        "print(\"y_pred2\", y_pred2.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.set_index(\"image\", inplace = True)\n",
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_DeepSMOTEOversampling_last.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4nEpmkZaTZC"
      },
      "outputs": [],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1))\n",
        "\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtvW3YeaLlC"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RcRGeofw-8tK",
        "uZv-B-ygCD57",
        "cNBXx28B9yGu",
        "US0KkIaVlTdU",
        "0jrJ33lUDkCM",
        "3K908bbiYwbS"
      ],
      "machine_shape": "hm",
      "name": "Skin Cancer Diagnosis using ISIC 2018 Dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}