{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Skin-Cancer-Diagnosis/blob/main/Skin_Cancer_Diagnosis_using_ISIC_2018_Dataset_DeepSMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUusDE1Z9TNb"
      },
      "source": [
        "Prepare the dataset. \n",
        "Currently, we use skin cancer ISIC dataset from Kaggle https://www.kaggle.com/datasets/nodoubttome/skin-cancer9-classesisic\n",
        "\n",
        "Tutorial for how to load Kaggle dataset can be found in https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "e92bbdf6-086d-48dd-bda4-e565dad8b2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR2MJBYq-oiB",
        "outputId": "ef42254f-65ff-4b06-93b9-776176f92c0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "!pip install imbalanced-learn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3mnEebdJH6Ex"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "num_classes = 7\n",
        "#df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aFSe3uekK67v"
      },
      "outputs": [],
      "source": [
        "#decode one hot label\n",
        "df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "#drop one-hot column\n",
        "df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "#make filepaths of the image\n",
        "dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38f3dgvyBqFM"
      },
      "source": [
        "Label Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2IncA-_o_n5w",
        "outputId": "750c982a-5ad3-416b-d449-31e55ae120a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'DF'),\n",
              " Text(0, 0, 'VASC'),\n",
              " Text(0, 0, 'AKIEC'),\n",
              " Text(0, 0, 'BCC'),\n",
              " Text(0, 0, 'BKL'),\n",
              " Text(0, 0, 'MEL'),\n",
              " Text(0, 0, 'NV')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = df_train['Labels'].value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(row['Labels'] == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df_train['Labels'].unique())\n",
        "#for label in labels:\n",
        "#    plot_images_per_label(df_train, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h35T8vKRVV1Y"
      },
      "source": [
        "Manual undersampling majority class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BeldhlTdVQlT"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=.6).index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKjC59JOB_6d"
      },
      "source": [
        "Prepare X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 56\n",
        "IMAGE_H = 56\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3jyCpXnlFoQK"
      },
      "outputs": [],
      "source": [
        "#TIME CONSUMING OPERATION\n",
        "#from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "#X = []\n",
        "#for img in df['FilePaths']:\n",
        "    #img_arr = load_img(img, target_size=IMG_SIZE)\n",
        "#    with load_img(img, target_size=IMG_SIZE) as img_arr:\n",
        "#      X.append(img_to_array(img_arr))\n",
        "\n",
        "#X = np.array(X)\n",
        "df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UZyZMydSgvZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868f8be9-6022-467b-ac0c-b23e575730f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5992, 56, 56, 3)\n",
            "(193, 56, 56, 3)\n"
          ]
        }
      ],
      "source": [
        "X_train = np.asarray(df_train['image_px'].tolist())\n",
        "X_val = np.asarray(df_val['image_px'].tolist())\n",
        "print(np.array(X_train).shape)\n",
        "print(np.array(X_val).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uqYLmicGAjZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69d48f8-d08a-4c9b-965a-603bc334b38c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'NV': 2682, 'MEL': 1113, 'BKL': 1099, 'BCC': 514, 'AKIEC': 327, 'VASC': 142, 'DF': 115})\n",
            "(5992,)\n"
          ]
        }
      ],
      "source": [
        "y_train = np.array(df_train['Labels'].values)\n",
        "\n",
        "# summarize class distribution\n",
        "from collections import Counter\n",
        "counter = Counter(y_train)\n",
        "print(counter)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kEuVIGc3g859",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e99e9f5-d091-44c2-bb1a-0d6e3ec9eeb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'NV': 123, 'BKL': 22, 'MEL': 21, 'BCC': 15, 'AKIEC': 8, 'VASC': 3, 'DF': 1})\n",
            "(193,)\n"
          ]
        }
      ],
      "source": [
        "y_val = np.array(df_val['Labels'].values)\n",
        "print(Counter(y_val))\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QfvEVGIQhIr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38c2c59-905f-4d45-ce3f-82160f7e4822"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 2, 4, ..., 2, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#label encoding\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_val = label_encoder.fit_transform(y_val)\n",
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZv-B-ygCD57"
      },
      "source": [
        "#SMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDskF1wjGffh"
      },
      "outputs": [],
      "source": [
        "def SMOTE_Data(X, y):\n",
        "  sm = SMOTE(random_state=42, k_neighbors=5)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, IMAGE_W * IMAGE_H * 3)), y)\n",
        "  X_resampled.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brshqGvOCDJL",
        "outputId": "69cd1efa-ecf2-4066-fcb2-6e76150c29a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32851, 150528)\n",
            "(32851,)\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train) #beware of the actual parameter\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GfOtcbV5vVZ",
        "outputId": "835b01d9-1627-4c85-fde0-c4a58a2ace7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({5: 4693, 4: 4693, 2: 4693, 3: 4693, 0: 4693, 1: 4693, 6: 4693})\n"
          ]
        }
      ],
      "source": [
        "counter = Counter(y_train)\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl-nmACZOZpg",
        "outputId": "b35b1691-9cd5-4b83-ccf6-2b4cfdfd8fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape:  (32851, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "print('X_train shape: ',X_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RAxUkXy8ueYG"
      },
      "outputs": [],
      "source": [
        "#Normalization\n",
        "X_train_mean = np.mean(X_train)\n",
        "X_train_std = np.std(X_train)\n",
        "\n",
        "X_train = (X_train - X_train_mean)/X_train_std\n",
        "X_val = (X_val - X_train_mean)/X_train_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h-Xqj-WQ90L_"
      },
      "outputs": [],
      "source": [
        "#optional\n",
        "#X=X_train\n",
        "#y=y_train\n",
        "\n",
        "from numpy import moveaxis\n",
        "X_train = moveaxis(X_train, 3, 1)\n",
        "#X_train = X_train.astype('float32') / 255.\n",
        "#dec_x = X_train \n",
        "#dec_y = y\n",
        "\n",
        "#create counter for encoder\n",
        "counter = sorted(counter.items())\n",
        "counter = [value for _, value in counter]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0kMMmX7r-fV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e96ce4-5342-4eda-e0a7-e5e9e7ba399b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(torch.version.cuda) #10.1\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "\n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "\n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 12   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "\n",
        "args['patience'] = 20\n",
        "\n",
        "## create encoder model and decoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        #[(W−K+2P)/S]+1.\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 224 > 112\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),# > 56\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# > 28\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 7, 2, 0, bias=False),# > 14\n",
        "            nn.BatchNorm2d(self.dim_h * 8), # 40 X 8 = 320\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "#            nn.Conv2d(self.dim_h * 8, self.dim_h * 16, 7, 2, 0, bias=False),# > 7\n",
        "#            nn.BatchNorm2d(self.dim_h * 16), # 40 X 8 = 320\n",
        "#            nn.LeakyReLU(0.2, inplace=True))\n",
        "#            nn.Conv2d(self.dim_h * 16, self.dim_h * 32, 7, 2, 0, bias=False),# > 1\n",
        "#            nn.BatchNorm2d(self.dim_h * 32), # 40 X 8 = 320\n",
        "#            nn.LeakyReLU(0.2, inplace=True))\n",
        "        # final layer is fully connected\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('enc')\n",
        "        #print('input ',x.size()) #torch.Size([100, 3,32,32])\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        #print('aft squeeze ',x.size()) #torch.Size([128, 320])\n",
        "        #aft squeeze  torch.Size([100, 320])\n",
        "        x = self.fc(x)\n",
        "        #print('out ',x.size()) #torch.Size([128, 20])\n",
        "        #out  torch.Size([100, 300])\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        #H_out ​= (H_in​−1)*stride[0] − 2×padding[0] + dilation[0]×(kernel_size[0]−1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "#            nn.ConvTranspose2d(self.dim_h * 32, self.dim_h * 16, 4, 2, 1), # > 14 > 28 > 56 > 112 > 224\n",
        "#            nn.BatchNorm2d(self.dim_h * 16),\n",
        "#            nn.ReLU(True),\n",
        "#            nn.ConvTranspose2d(self.dim_h * 16, self.dim_h * 8, 4, 2, 1), # > 28\n",
        "#            nn.BatchNorm2d(self.dim_h * 8),\n",
        "#            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4, 2, 1),# > 56\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4, 2, 1),# > 112\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, 3, 4, 2, 1),# > 224\n",
        "            #nn.Sigmoid())\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('dec')\n",
        "        #print('input ',x.size())\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"functions to create SMOTE images\"\"\"\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "\n",
        "    # determining the number of samples to generate\n",
        "    #n_to_sample = 10 \n",
        "\n",
        "    # fitting the model\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "#xsamp, ysamp = SM(xclass,yclass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHtLISURIMTg",
        "outputId": "30e08ee1-499a-407d-9928-8137b9fe1304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch: 0 \tTrain Loss: 7.299708 \tmse loss: 3.948752 \tmse2 loss: 3.350956\n",
            "Saving..\n",
            "Epoch: 1 \tTrain Loss: 5.475280 \tmse loss: 3.023897 \tmse2 loss: 2.451383\n",
            "Saving..\n",
            "Epoch: 2 \tTrain Loss: 4.937226 \tmse loss: 2.787710 \tmse2 loss: 2.149516\n",
            "Saving..\n",
            "Epoch: 3 \tTrain Loss: 4.739900 \tmse loss: 2.696243 \tmse2 loss: 2.043657\n",
            "Saving..\n",
            "Epoch: 4 \tTrain Loss: 4.545835 \tmse loss: 2.640414 \tmse2 loss: 1.905420\n",
            "Saving..\n",
            "Epoch: 5 \tTrain Loss: 4.546779 \tmse loss: 2.591076 \tmse2 loss: 1.955702\n",
            "Epoch: 6 \tTrain Loss: 4.416031 \tmse loss: 2.550796 \tmse2 loss: 1.865234\n",
            "Saving..\n",
            "Epoch: 7 \tTrain Loss: 4.367793 \tmse loss: 2.514564 \tmse2 loss: 1.853230\n",
            "Saving..\n",
            "Epoch: 8 \tTrain Loss: 4.426613 \tmse loss: 2.502036 \tmse2 loss: 1.924577\n",
            "Epoch: 9 \tTrain Loss: 4.300451 \tmse loss: 2.479648 \tmse2 loss: 1.820803\n",
            "Saving..\n",
            "Epoch: 10 \tTrain Loss: 4.274477 \tmse loss: 2.465263 \tmse2 loss: 1.809215\n",
            "Saving..\n",
            "Epoch: 11 \tTrain Loss: 4.314148 \tmse loss: 2.447080 \tmse2 loss: 1.867068\n",
            "Epoch: 12 \tTrain Loss: 4.204870 \tmse loss: 2.432808 \tmse2 loss: 1.772062\n",
            "Saving..\n",
            "Epoch: 13 \tTrain Loss: 4.237937 \tmse loss: 2.423360 \tmse2 loss: 1.814576\n",
            "Epoch: 14 \tTrain Loss: 4.161936 \tmse loss: 2.402747 \tmse2 loss: 1.759189\n",
            "Saving..\n",
            "Epoch: 15 \tTrain Loss: 4.181968 \tmse loss: 2.394821 \tmse2 loss: 1.787146\n",
            "Epoch: 16 \tTrain Loss: 4.198235 \tmse loss: 2.384576 \tmse2 loss: 1.813658\n",
            "Epoch: 17 \tTrain Loss: 4.131717 \tmse loss: 2.372162 \tmse2 loss: 1.759555\n",
            "Saving..\n",
            "Epoch: 18 \tTrain Loss: 4.097673 \tmse loss: 2.366959 \tmse2 loss: 1.730714\n",
            "Saving..\n",
            "Epoch: 19 \tTrain Loss: 4.132636 \tmse loss: 2.361576 \tmse2 loss: 1.771060\n",
            "Epoch: 20 \tTrain Loss: 4.049162 \tmse loss: 2.356473 \tmse2 loss: 1.692689\n",
            "Saving..\n",
            "Epoch: 21 \tTrain Loss: 4.081295 \tmse loss: 2.343556 \tmse2 loss: 1.737739\n",
            "Epoch: 22 \tTrain Loss: 4.039450 \tmse loss: 2.336637 \tmse2 loss: 1.702813\n",
            "Saving..\n",
            "Epoch: 23 \tTrain Loss: 4.002055 \tmse loss: 2.328772 \tmse2 loss: 1.673283\n",
            "Saving..\n",
            "Epoch: 24 \tTrain Loss: 4.127426 \tmse loss: 2.326160 \tmse2 loss: 1.801266\n",
            "Epoch: 25 \tTrain Loss: 3.989767 \tmse loss: 2.320340 \tmse2 loss: 1.669427\n",
            "Saving..\n",
            "Epoch: 26 \tTrain Loss: 3.984869 \tmse loss: 2.311248 \tmse2 loss: 1.673621\n",
            "Saving..\n",
            "Epoch: 27 \tTrain Loss: 4.042776 \tmse loss: 2.310111 \tmse2 loss: 1.732666\n",
            "Epoch: 28 \tTrain Loss: 3.970898 \tmse loss: 2.303734 \tmse2 loss: 1.667164\n",
            "Saving..\n",
            "Epoch: 29 \tTrain Loss: 3.973630 \tmse loss: 2.302214 \tmse2 loss: 1.671415\n",
            "Epoch: 30 \tTrain Loss: 4.010978 \tmse loss: 2.297909 \tmse2 loss: 1.713070\n",
            "Epoch: 31 \tTrain Loss: 3.987254 \tmse loss: 2.310320 \tmse2 loss: 1.676935\n",
            "Epoch: 32 \tTrain Loss: 3.984069 \tmse loss: 2.289921 \tmse2 loss: 1.694147\n",
            "Epoch: 33 \tTrain Loss: 3.906743 \tmse loss: 2.286736 \tmse2 loss: 1.620008\n",
            "Saving..\n",
            "Epoch: 34 \tTrain Loss: 3.969659 \tmse loss: 2.282190 \tmse2 loss: 1.687469\n",
            "Epoch: 35 \tTrain Loss: 3.925114 \tmse loss: 2.276585 \tmse2 loss: 1.648529\n",
            "Epoch: 36 \tTrain Loss: 3.981120 \tmse loss: 2.276685 \tmse2 loss: 1.704435\n",
            "Epoch: 37 \tTrain Loss: 3.935492 \tmse loss: 2.275990 \tmse2 loss: 1.659502\n",
            "Epoch: 38 \tTrain Loss: 3.942413 \tmse loss: 2.274116 \tmse2 loss: 1.668298\n",
            "Epoch: 39 \tTrain Loss: 3.957719 \tmse loss: 2.270314 \tmse2 loss: 1.687405\n",
            "Epoch: 40 \tTrain Loss: 3.878466 \tmse loss: 2.265898 \tmse2 loss: 1.612568\n",
            "Saving..\n",
            "Epoch: 41 \tTrain Loss: 3.962000 \tmse loss: 2.262411 \tmse2 loss: 1.699588\n",
            "Epoch: 42 \tTrain Loss: 3.914730 \tmse loss: 2.263000 \tmse2 loss: 1.651730\n",
            "Epoch: 43 \tTrain Loss: 3.977499 \tmse loss: 2.258286 \tmse2 loss: 1.719213\n",
            "Epoch: 44 \tTrain Loss: 3.910816 \tmse loss: 2.258013 \tmse2 loss: 1.652802\n",
            "Epoch: 45 \tTrain Loss: 3.905534 \tmse loss: 2.252712 \tmse2 loss: 1.652822\n",
            "Epoch: 46 \tTrain Loss: 3.934447 \tmse loss: 2.256121 \tmse2 loss: 1.678325\n",
            "Epoch: 47 \tTrain Loss: 3.868122 \tmse loss: 2.251596 \tmse2 loss: 1.616527\n",
            "Saving..\n",
            "Epoch: 48 \tTrain Loss: 3.912687 \tmse loss: 2.248324 \tmse2 loss: 1.664364\n",
            "Epoch: 49 \tTrain Loss: 3.884493 \tmse loss: 2.248140 \tmse2 loss: 1.636353\n",
            "Epoch: 50 \tTrain Loss: 3.945750 \tmse loss: 2.242608 \tmse2 loss: 1.703143\n",
            "Epoch: 51 \tTrain Loss: 3.908133 \tmse loss: 2.243763 \tmse2 loss: 1.664370\n",
            "Epoch: 52 \tTrain Loss: 3.920016 \tmse loss: 2.241278 \tmse2 loss: 1.678738\n",
            "Epoch: 53 \tTrain Loss: 3.858428 \tmse loss: 2.241963 \tmse2 loss: 1.616464\n",
            "Saving..\n",
            "Epoch: 54 \tTrain Loss: 3.854264 \tmse loss: 2.237839 \tmse2 loss: 1.616426\n",
            "Saving..\n",
            "Epoch: 55 \tTrain Loss: 3.826072 \tmse loss: 2.237239 \tmse2 loss: 1.588834\n",
            "Saving..\n",
            "Epoch: 56 \tTrain Loss: 3.833050 \tmse loss: 2.234172 \tmse2 loss: 1.598877\n",
            "Epoch: 57 \tTrain Loss: 3.790773 \tmse loss: 2.232259 \tmse2 loss: 1.558514\n",
            "Saving..\n",
            "Epoch: 58 \tTrain Loss: 3.875974 \tmse loss: 2.232554 \tmse2 loss: 1.643420\n",
            "Epoch: 59 \tTrain Loss: 3.886937 \tmse loss: 2.229300 \tmse2 loss: 1.657636\n",
            "Epoch: 60 \tTrain Loss: 3.841357 \tmse loss: 2.227947 \tmse2 loss: 1.613410\n",
            "Epoch: 61 \tTrain Loss: 3.853950 \tmse loss: 2.226477 \tmse2 loss: 1.627473\n",
            "Epoch: 62 \tTrain Loss: 3.776017 \tmse loss: 2.227669 \tmse2 loss: 1.548348\n",
            "Saving..\n",
            "Epoch: 63 \tTrain Loss: 3.856483 \tmse loss: 2.225468 \tmse2 loss: 1.631014\n",
            "Epoch: 64 \tTrain Loss: 3.785700 \tmse loss: 2.226008 \tmse2 loss: 1.559692\n",
            "Epoch: 65 \tTrain Loss: 3.849824 \tmse loss: 2.221591 \tmse2 loss: 1.628232\n",
            "Epoch: 66 \tTrain Loss: 3.828144 \tmse loss: 2.219339 \tmse2 loss: 1.608805\n",
            "Epoch: 67 \tTrain Loss: 3.809619 \tmse loss: 2.222637 \tmse2 loss: 1.586982\n",
            "Epoch: 68 \tTrain Loss: 3.849566 \tmse loss: 2.218470 \tmse2 loss: 1.631096\n",
            "Epoch: 69 \tTrain Loss: 3.799551 \tmse loss: 2.220548 \tmse2 loss: 1.579003\n",
            "Epoch: 70 \tTrain Loss: 3.838902 \tmse loss: 2.217067 \tmse2 loss: 1.621835\n",
            "Epoch: 71 \tTrain Loss: 3.790363 \tmse loss: 2.214844 \tmse2 loss: 1.575520\n",
            "Epoch: 72 \tTrain Loss: 3.790450 \tmse loss: 2.214968 \tmse2 loss: 1.575481\n",
            "Epoch: 73 \tTrain Loss: 3.759430 \tmse loss: 2.213534 \tmse2 loss: 1.545897\n",
            "Saving..\n",
            "Epoch: 74 \tTrain Loss: 3.832480 \tmse loss: 2.214151 \tmse2 loss: 1.618328\n",
            "Epoch: 75 \tTrain Loss: 3.845364 \tmse loss: 2.214371 \tmse2 loss: 1.630993\n",
            "Epoch: 76 \tTrain Loss: 3.803837 \tmse loss: 2.211776 \tmse2 loss: 1.592061\n",
            "Epoch: 77 \tTrain Loss: 3.814230 \tmse loss: 2.213275 \tmse2 loss: 1.600954\n",
            "Epoch: 78 \tTrain Loss: 3.791293 \tmse loss: 2.209081 \tmse2 loss: 1.582212\n",
            "Epoch: 79 \tTrain Loss: 3.868975 \tmse loss: 2.207222 \tmse2 loss: 1.661754\n",
            "Epoch: 80 \tTrain Loss: 3.792081 \tmse loss: 2.208979 \tmse2 loss: 1.583102\n",
            "Epoch: 81 \tTrain Loss: 3.822955 \tmse loss: 2.206245 \tmse2 loss: 1.616710\n",
            "Epoch: 82 \tTrain Loss: 3.845671 \tmse loss: 2.207343 \tmse2 loss: 1.638328\n",
            "Epoch: 83 \tTrain Loss: 3.834843 \tmse loss: 2.205240 \tmse2 loss: 1.629603\n",
            "Epoch: 84 \tTrain Loss: 3.805325 \tmse loss: 2.205623 \tmse2 loss: 1.599702\n",
            "Epoch: 85 \tTrain Loss: 3.808799 \tmse loss: 2.202371 \tmse2 loss: 1.606428\n",
            "Epoch: 86 \tTrain Loss: 3.767261 \tmse loss: 2.202429 \tmse2 loss: 1.564833\n",
            "Epoch: 87 \tTrain Loss: 3.863575 \tmse loss: 2.204288 \tmse2 loss: 1.659286\n",
            "Epoch: 88 \tTrain Loss: 3.752351 \tmse loss: 2.200975 \tmse2 loss: 1.551376\n",
            "Saving..\n",
            "Epoch: 89 \tTrain Loss: 3.845682 \tmse loss: 2.199071 \tmse2 loss: 1.646611\n",
            "Epoch: 90 \tTrain Loss: 3.754134 \tmse loss: 2.199297 \tmse2 loss: 1.554837\n",
            "Epoch: 91 \tTrain Loss: 3.830484 \tmse loss: 2.200141 \tmse2 loss: 1.630343\n",
            "Epoch: 92 \tTrain Loss: 3.777850 \tmse loss: 2.197678 \tmse2 loss: 1.580172\n",
            "Epoch: 93 \tTrain Loss: 3.789671 \tmse loss: 2.197279 \tmse2 loss: 1.592392\n",
            "Epoch: 94 \tTrain Loss: 3.784913 \tmse loss: 2.197601 \tmse2 loss: 1.587312\n",
            "Epoch: 95 \tTrain Loss: 3.819384 \tmse loss: 2.196122 \tmse2 loss: 1.623262\n",
            "Epoch: 96 \tTrain Loss: 3.820010 \tmse loss: 2.195397 \tmse2 loss: 1.624612\n",
            "Epoch: 97 \tTrain Loss: 3.818604 \tmse loss: 2.195291 \tmse2 loss: 1.623313\n",
            "Epoch: 98 \tTrain Loss: 3.799754 \tmse loss: 2.193857 \tmse2 loss: 1.605897\n",
            "Epoch: 99 \tTrain Loss: 3.810735 \tmse loss: 2.193996 \tmse2 loss: 1.616739\n",
            "Epoch: 100 \tTrain Loss: 3.804020 \tmse loss: 2.192475 \tmse2 loss: 1.611545\n",
            "Epoch: 101 \tTrain Loss: 3.775496 \tmse loss: 2.192804 \tmse2 loss: 1.582691\n",
            "Epoch: 102 \tTrain Loss: 3.785882 \tmse loss: 2.201557 \tmse2 loss: 1.584325\n",
            "Epoch: 103 \tTrain Loss: 3.738115 \tmse loss: 2.189989 \tmse2 loss: 1.548126\n",
            "Saving..\n",
            "Epoch: 104 \tTrain Loss: 3.811003 \tmse loss: 2.188959 \tmse2 loss: 1.622044\n",
            "Epoch: 105 \tTrain Loss: 3.758102 \tmse loss: 2.190767 \tmse2 loss: 1.567335\n",
            "Epoch: 106 \tTrain Loss: 3.826762 \tmse loss: 2.189714 \tmse2 loss: 1.637048\n",
            "Epoch: 107 \tTrain Loss: 3.831866 \tmse loss: 2.186958 \tmse2 loss: 1.644908\n",
            "Epoch: 108 \tTrain Loss: 3.747474 \tmse loss: 2.187812 \tmse2 loss: 1.559661\n",
            "Epoch: 109 \tTrain Loss: 3.769609 \tmse loss: 2.187766 \tmse2 loss: 1.581843\n",
            "Epoch: 110 \tTrain Loss: 3.696827 \tmse loss: 2.187991 \tmse2 loss: 1.508836\n",
            "Saving..\n",
            "Epoch: 111 \tTrain Loss: 3.709236 \tmse loss: 2.190424 \tmse2 loss: 1.518813\n",
            "Epoch: 112 \tTrain Loss: 3.799122 \tmse loss: 2.187799 \tmse2 loss: 1.611324\n",
            "Epoch: 113 \tTrain Loss: 3.738086 \tmse loss: 2.185507 \tmse2 loss: 1.552579\n",
            "Epoch: 114 \tTrain Loss: 3.764746 \tmse loss: 2.185039 \tmse2 loss: 1.579708\n",
            "Epoch: 115 \tTrain Loss: 3.803086 \tmse loss: 2.185683 \tmse2 loss: 1.617402\n",
            "Epoch: 116 \tTrain Loss: 3.742945 \tmse loss: 2.185350 \tmse2 loss: 1.557595\n",
            "Epoch: 117 \tTrain Loss: 3.736553 \tmse loss: 2.184938 \tmse2 loss: 1.551615\n",
            "Epoch: 118 \tTrain Loss: 3.799377 \tmse loss: 2.182594 \tmse2 loss: 1.616784\n",
            "Epoch: 119 \tTrain Loss: 3.872715 \tmse loss: 2.184131 \tmse2 loss: 1.688584\n",
            "Epoch: 120 \tTrain Loss: 3.779465 \tmse loss: 2.182131 \tmse2 loss: 1.597334\n",
            "Epoch: 121 \tTrain Loss: 3.818857 \tmse loss: 2.181519 \tmse2 loss: 1.637339\n",
            "Epoch: 122 \tTrain Loss: 3.757769 \tmse loss: 2.181140 \tmse2 loss: 1.576629\n",
            "Epoch: 123 \tTrain Loss: 3.760349 \tmse loss: 2.181542 \tmse2 loss: 1.578807\n",
            "Epoch: 124 \tTrain Loss: 3.813594 \tmse loss: 2.182409 \tmse2 loss: 1.631185\n",
            "Epoch: 125 \tTrain Loss: 3.766724 \tmse loss: 2.179236 \tmse2 loss: 1.587488\n",
            "Epoch: 126 \tTrain Loss: 3.799965 \tmse loss: 2.182197 \tmse2 loss: 1.617768\n",
            "Epoch: 127 \tTrain Loss: 3.803834 \tmse loss: 2.179823 \tmse2 loss: 1.624011\n",
            "Epoch: 128 \tTrain Loss: 3.720542 \tmse loss: 2.178688 \tmse2 loss: 1.541854\n",
            "Epoch: 129 \tTrain Loss: 3.825796 \tmse loss: 2.179582 \tmse2 loss: 1.646214\n",
            "Epoch: 130 \tTrain Loss: 3.751146 \tmse loss: 2.178781 \tmse2 loss: 1.572366\n",
            "Out of patience. \n",
            "\n",
            "/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_enc.pth\n",
            "/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_dec.pth\n"
          ]
        }
      ],
      "source": [
        "#Begin the training\n",
        "batch_size = args['batch_size']\n",
        "patience = args['patience']\n",
        "encoder = Encoder(args)\n",
        "decoder = Decoder(args)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "decoder = decoder.to(device)\n",
        "encoder = encoder.to(device)\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "#decoder loss function\n",
        "criterion = nn.MSELoss()\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "num_workers = 0\n",
        "\n",
        "#torch.Tensor returns float so if want long then use torch.tensor\n",
        "tensor_x = torch.Tensor(X_train)\n",
        "tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "    batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "t0 = time.time()\n",
        "if args['train']:\n",
        "    enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "    dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "    for epoch in range(args['epochs']):\n",
        "        train_loss = 0.0\n",
        "        tmse_loss = 0.0\n",
        "        tdiscr_loss = 0.0\n",
        "        # train for one epoch -- set nets to train mode\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "    \n",
        "        for images,labs in train_loader:\n",
        "        \n",
        "            # zero gradients for each batch\n",
        "            encoder.zero_grad()\n",
        "            decoder.zero_grad()\n",
        "            images, labs = images.to(device), labs.to(device)\n",
        "            labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "            # run images\n",
        "            z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "        \n",
        "            x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "            mse = criterion(x_hat,images)\n",
        "                    \n",
        "            resx = []\n",
        "            resy = []\n",
        "        \n",
        "            tc = np.random.choice(num_classes,1)\n",
        "            #tc = 9\n",
        "            xbeg = X_train[y_train == tc]\n",
        "            ybeg = y_train[y_train == tc] \n",
        "            xlen = len(xbeg)\n",
        "            nsamp = min(xlen, 100)\n",
        "            ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "            xclass = xbeg[ind]\n",
        "            yclass = ybeg[ind]\n",
        "        \n",
        "            xclen = len(xclass)\n",
        "            xcminus = np.arange(1,xclen)\n",
        "            \n",
        "            xcplus = np.append(xcminus,0)\n",
        "            xcnew = (xclass[[xcplus],:])\n",
        "            xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "        \n",
        "            xcnew = torch.Tensor(xcnew)\n",
        "            xcnew = xcnew.to(device)\n",
        "        \n",
        "            #encode xclass to feature space\n",
        "            xclass = torch.Tensor(xclass)\n",
        "            xclass = xclass.to(device)\n",
        "            xclass = encoder(xclass)\n",
        "        \n",
        "            xclass = xclass.detach().cpu().numpy()\n",
        "        \n",
        "            xc_enc = (xclass[[xcplus],:])\n",
        "            xc_enc = np.squeeze(xc_enc)\n",
        "        \n",
        "            xc_enc = torch.Tensor(xc_enc)\n",
        "            xc_enc = xc_enc.to(device)\n",
        "            \n",
        "            ximg = decoder(xc_enc)\n",
        "            \n",
        "            mse2 = criterion(ximg,xcnew)\n",
        "        \n",
        "            comb_loss = mse2 + mse\n",
        "            comb_loss.backward()\n",
        "        \n",
        "            enc_optim.step()\n",
        "            dec_optim.step()\n",
        "        \n",
        "            train_loss += comb_loss.item()*images.size(0)\n",
        "            tmse_loss += mse.item()*images.size(0)\n",
        "            tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "        train_loss = train_loss/len(train_loader)\n",
        "        tmse_loss = tmse_loss/len(train_loader)\n",
        "        tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "        print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "                train_loss,tmse_loss,tdiscr_loss))\n",
        "        \n",
        "    \n",
        "    \n",
        "        #store the best encoder and decoder models\n",
        "        #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "        #necessary for illustration purposes\n",
        "        if train_loss < best_loss:\n",
        "            print('Saving..')\n",
        "            patience = args['patience']\n",
        "            path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/bst_enc.pth'\n",
        "            path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/bst_dec.pth'\n",
        "          \n",
        "            torch.save(encoder.state_dict(), path_enc)\n",
        "            torch.save(decoder.state_dict(), path_dec)\n",
        "    \n",
        "            best_loss = train_loss\n",
        "        else:\n",
        "            patience = patience - 1\n",
        "\n",
        "        if patience == 0:\n",
        "            print('Out of patience. \\n')\n",
        "            break\n",
        "    \n",
        "    \n",
        "    #in addition, store the final model (may not be the best) for\n",
        "    #informational purposes\n",
        "    path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_enc.pth'\n",
        "    path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/f_dec.pth'\n",
        "    print(path_enc)\n",
        "    print(path_dec)\n",
        "    torch.save(encoder.state_dict(), path_enc)\n",
        "    torch.save(decoder.state_dict(), path_dec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoqPIVKqF5Ug",
        "outputId": "c8019c1b-071e-44d2-b40c-86a229410f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train imgs shape  (5992, 3, 56, 56)\n",
            "decy  (5992,)\n",
            "(18774, 9408)\n",
            "(18774,)\n"
          ]
        }
      ],
      "source": [
        "#Generate artificial images\n",
        "import torch\n",
        "np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "#path on the computer where the models are stored\n",
        "modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/'\n",
        "\n",
        "encf = []\n",
        "decf = []\n",
        "for p in range(1):\n",
        "    enc = modpth + '/bst_enc.pth'\n",
        "    dec = modpth + '/bst_dec.pth'\n",
        "    encf.append(enc)\n",
        "    decf.append(dec)\n",
        "\n",
        "for m in range(1):\n",
        "    print('train imgs shape ',X_train.shape) #(45000,3,32,32)\n",
        "    print('decy ',y_train.shape)\n",
        "    \n",
        "    #generate some images \n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    path_enc = encf[m]\n",
        "    path_dec = decf[m]\n",
        "\n",
        "    encoder = Encoder(args)\n",
        "    encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "    encoder = encoder.to(device)\n",
        "\n",
        "    decoder = Decoder(args)\n",
        "    decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "    decoder = decoder.to(device)\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    resx = []\n",
        "    resy = []\n",
        "\n",
        "    for i in [0,1,2,3,4,6]: #skip class 5 since it's max class\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "#        print(xclass.shape) #(500, 3, 32, 32)\n",
        "#        print(yclass[0]) #(500,)\n",
        "            \n",
        "        #encode xclass to feature space\n",
        "        xclass = torch.Tensor(xclass)\n",
        "        xclass = xclass.to(device)\n",
        "        xclass = encoder(xclass)\n",
        "            \n",
        "        xclass = xclass.detach().cpu().numpy()\n",
        "        n = np.max(counter) - counter[i]\n",
        "        xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "#        print(xsamp.shape) #(4500, 600)\n",
        "#        print(len(ysamp)) #4500\n",
        "        ysamp = np.array(ysamp)\n",
        "    \n",
        "        \"\"\"to generate samples for resnet\"\"\"   \n",
        "        xsamp = torch.Tensor(xsamp)\n",
        "        xsamp = xsamp.to(device)\n",
        "        ximg = decoder(xsamp)\n",
        "\n",
        "        ximn = ximg.detach().cpu().numpy()\n",
        "#        print(ximn.shape) \n",
        "        resx.append(ximn)\n",
        "        resy.append(ysamp)\n",
        "    \n",
        "    resx1 = np.vstack(resx)\n",
        "    resy1 = np.hstack(resy)\n",
        "#    print(resx1.shape) #(34720, 3, 32, 32)\n",
        "\n",
        "    resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "#    print(resx1.shape) #(34720, 3072)\n",
        "    \n",
        "    dec_x1 = X_train.reshape(X_train.shape[0],-1)\n",
        "#    print('decx1 ',dec_x1.shape)\n",
        "    combx = np.vstack((resx1,dec_x1))\n",
        "    comby = np.hstack((resy1,y_train))\n",
        "\n",
        "    print(combx.shape) #(45000, 3, 32, 32)\n",
        "    print(comby.shape) #(45000,)\n",
        "#    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76bpFBQcHLIY",
        "outputId": "71038423-26c9-4335-a628-b726496bf4a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (18774, 56, 56, 3)\n",
            "Counter({0: 2682, 1: 2682, 2: 2682, 3: 2682, 4: 2682, 6: 2682, 5: 2682})\n"
          ]
        }
      ],
      "source": [
        "X_train = combx.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "X_train = moveaxis(X_train, 1, 3)\n",
        "print('X_train shape: ',X_train.shape)\n",
        "y_train = comby\n",
        "print(Counter(comby))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8SqyvSgX8sLO"
      },
      "outputs": [],
      "source": [
        "#X_train = X_train * 255\n",
        "#X_train = X_train.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "we4D35jnEOqs"
      },
      "outputs": [],
      "source": [
        "#de-standardization\n",
        "X_train = (X_train * X_train_std + X_train_mean).astype(int)\n",
        "X_val = (X_val * X_train_std + X_train_mean).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US0KkIaVlTdU"
      },
      "source": [
        "#Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_a_lPCqbibaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eedc070-6f63-4081-b17f-027ee1068dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape:  (18774, 1)\n"
          ]
        }
      ],
      "source": [
        "y_train = y_train.reshape(-1, 1)\n",
        "y_val = y_val.reshape(-1, 1)\n",
        "print('y_train shape: ',y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ja5ZmgbCvDw5"
      },
      "outputs": [],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "y_val = to_categorical(y_val, num_classes = num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ioaoIkk4G2pf"
      },
      "outputs": [],
      "source": [
        "#X_val = X_val.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9QM00erNGU32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17a3fa6-746b-430f-ad69-3b70761d0582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18774, 56, 56, 3)\n",
            "(18774, 7)\n",
            "(193, 56, 56, 3)\n",
            "(193, 7)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6qneWL_Bs2U",
        "outputId": "22c2c4ff-5544-4dd8-b69a-af96b4b97616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data:  (9814, 32, 32, 3)\n",
            "Remaining Data:  (201, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.02, stratify=y, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vai7M7WSXVY4",
        "outputId": "b9bc1199-a518-4a8b-9d6e-4d6038efbafe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Data:  (416, 32, 32, 3)\n",
            "Val Data:  (416, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# stratified val and test (50%) \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_rem, y_rem, test_size=0.5, stratify=y_rem, random_state=1)\n",
        "\n",
        "print('Test Data: ', X_test.shape)\n",
        "print('Val Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I15HgVuhjFlm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVVOQPNiHXHw",
        "outputId": "a1e60310-4f3b-4063-8465-4d7120d225c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data:  (2015, 32, 32, 3)\n",
            "Test Data:  (224, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "#optional\n",
        "# stratified train and test (10%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Test Data: ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_oaUYYgJNV7",
        "outputId": "ca2f393a-0599-4cfc-b330-45d723f2bb06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data:  (3369, 32, 32, 3)\n",
            "Val Data:  (375, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "#optional\n",
        "# stratified train and val (10%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify=y, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Val Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZklPzWxCCtTW"
      },
      "source": [
        "Create and compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jFShRvTHnqi"
      },
      "outputs": [],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Classification\n",
        "Model from https://github.com/AnasBrital98/CNN-From-Scratch/tree/master/Inception-V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "A8eRZiucdYnP"
      },
      "outputs": [],
      "source": [
        "#USe TF.data\n",
        "import tensorflow as tf\n",
        "training_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "validation_data = tf.data.Dataset.from_tensor_slices((X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7xalxBh-3LNC"
      },
      "outputs": [],
      "source": [
        "autotune = tf.data.AUTOTUNE\n",
        "train_data_batches = training_data.shuffle(buffer_size=40000).batch(32).prefetch(buffer_size=autotune)\n",
        "valid_data_batches = validation_data.shuffle(buffer_size=10000).batch(32).prefetch(buffer_size=autotune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ge4UmF5R0a7V"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "rescale_layer = tf.keras.Sequential([layers.experimental.preprocessing.Rescaling(1./255)])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2), \n",
        "  layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3)),\n",
        "  layers.experimental.preprocessing.RandomTranslation(0.3, 0.3, fill_mode='reflect', interpolation='bilinear',)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mu6rr5apdJtf"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_DeepSMOTE.h5'\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_prc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=10, verbose=0, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=30,monitor='val_prc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rwwLiXUSG0IZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d7e3ef-0302-4266-8bca-55f8cbe3de70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n",
            "Epoch 1/1000\n",
            "587/587 [==============================] - ETA: 0s - loss: 1.2731 - accuracy: 0.5204 - prc: 0.5734\n",
            "Epoch 1: val_prc improved from -inf to 0.83135, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 22s 27ms/step - loss: 1.2731 - accuracy: 0.5204 - prc: 0.5734 - val_loss: 0.7218 - val_accuracy: 0.6891 - val_prc: 0.8314 - lr: 5.0000e-04\n",
            "Epoch 2/1000\n",
            "587/587 [==============================] - ETA: 0s - loss: 1.0813 - accuracy: 0.5871 - prc: 0.6620\n",
            "Epoch 2: val_prc did not improve from 0.83135\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 1.0813 - accuracy: 0.5871 - prc: 0.6620 - val_loss: 0.7416 - val_accuracy: 0.7306 - val_prc: 0.8164 - lr: 5.0000e-04\n",
            "Epoch 3/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 1.0219 - accuracy: 0.6094 - prc: 0.6906\n",
            "Epoch 3: val_prc did not improve from 0.83135\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 1.0220 - accuracy: 0.6095 - prc: 0.6908 - val_loss: 0.7744 - val_accuracy: 0.6995 - val_prc: 0.8180 - lr: 5.0000e-04\n",
            "Epoch 4/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.9771 - accuracy: 0.6269 - prc: 0.7114\n",
            "Epoch 4: val_prc did not improve from 0.83135\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.9771 - accuracy: 0.6268 - prc: 0.7114 - val_loss: 0.6913 - val_accuracy: 0.6995 - val_prc: 0.8279 - lr: 5.0000e-04\n",
            "Epoch 5/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.9542 - accuracy: 0.6349 - prc: 0.7238\n",
            "Epoch 5: val_prc improved from 0.83135 to 0.83197, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 13s 22ms/step - loss: 0.9539 - accuracy: 0.6352 - prc: 0.7239 - val_loss: 0.6795 - val_accuracy: 0.6839 - val_prc: 0.8320 - lr: 5.0000e-04\n",
            "Epoch 6/1000\n",
            "587/587 [==============================] - ETA: 0s - loss: 0.9415 - accuracy: 0.6412 - prc: 0.7275\n",
            "Epoch 6: val_prc did not improve from 0.83197\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.9415 - accuracy: 0.6412 - prc: 0.7275 - val_loss: 0.7446 - val_accuracy: 0.7150 - val_prc: 0.8253 - lr: 5.0000e-04\n",
            "Epoch 7/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.9202 - accuracy: 0.6463 - prc: 0.7396\n",
            "Epoch 7: val_prc did not improve from 0.83197\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.9200 - accuracy: 0.6465 - prc: 0.7397 - val_loss: 0.7432 - val_accuracy: 0.7047 - val_prc: 0.8226 - lr: 5.0000e-04\n",
            "Epoch 8/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.9024 - accuracy: 0.6527 - prc: 0.7447\n",
            "Epoch 8: val_prc did not improve from 0.83197\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.9029 - accuracy: 0.6525 - prc: 0.7445 - val_loss: 0.7572 - val_accuracy: 0.6891 - val_prc: 0.8139 - lr: 5.0000e-04\n",
            "Epoch 9/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8936 - accuracy: 0.6578 - prc: 0.7505\n",
            "Epoch 9: val_prc did not improve from 0.83197\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8940 - accuracy: 0.6578 - prc: 0.7504 - val_loss: 0.6967 - val_accuracy: 0.7358 - val_prc: 0.8259 - lr: 5.0000e-04\n",
            "Epoch 10/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8811 - accuracy: 0.6597 - prc: 0.7552\n",
            "Epoch 10: val_prc did not improve from 0.83197\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8814 - accuracy: 0.6595 - prc: 0.7550 - val_loss: 0.7370 - val_accuracy: 0.6891 - val_prc: 0.8231 - lr: 5.0000e-04\n",
            "Epoch 11/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8628 - accuracy: 0.6705 - prc: 0.7627\n",
            "Epoch 11: val_prc improved from 0.83197 to 0.83873, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 13s 22ms/step - loss: 0.8630 - accuracy: 0.6705 - prc: 0.7626 - val_loss: 0.6827 - val_accuracy: 0.7150 - val_prc: 0.8387 - lr: 5.0000e-04\n",
            "Epoch 12/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.8549 - accuracy: 0.6715 - prc: 0.7663\n",
            "Epoch 12: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.8554 - accuracy: 0.6712 - prc: 0.7660 - val_loss: 0.7397 - val_accuracy: 0.6891 - val_prc: 0.8229 - lr: 5.0000e-04\n",
            "Epoch 13/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8491 - accuracy: 0.6702 - prc: 0.7687\n",
            "Epoch 13: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8493 - accuracy: 0.6700 - prc: 0.7686 - val_loss: 0.7651 - val_accuracy: 0.6788 - val_prc: 0.8052 - lr: 5.0000e-04\n",
            "Epoch 14/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8452 - accuracy: 0.6756 - prc: 0.7708\n",
            "Epoch 14: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8455 - accuracy: 0.6757 - prc: 0.7707 - val_loss: 0.7231 - val_accuracy: 0.7150 - val_prc: 0.8265 - lr: 5.0000e-04\n",
            "Epoch 15/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8314 - accuracy: 0.6808 - prc: 0.7776\n",
            "Epoch 15: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8310 - accuracy: 0.6810 - prc: 0.7777 - val_loss: 0.7487 - val_accuracy: 0.6995 - val_prc: 0.8088 - lr: 5.0000e-04\n",
            "Epoch 16/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.8027 - accuracy: 0.6934 - prc: 0.7910\n",
            "Epoch 16: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.8027 - accuracy: 0.6935 - prc: 0.7910 - val_loss: 0.7457 - val_accuracy: 0.7098 - val_prc: 0.8242 - lr: 2.5000e-04\n",
            "Epoch 17/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7907 - accuracy: 0.6945 - prc: 0.7933\n",
            "Epoch 17: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7904 - accuracy: 0.6947 - prc: 0.7934 - val_loss: 0.7116 - val_accuracy: 0.7202 - val_prc: 0.8316 - lr: 2.5000e-04\n",
            "Epoch 18/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7901 - accuracy: 0.6990 - prc: 0.7969\n",
            "Epoch 18: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7904 - accuracy: 0.6989 - prc: 0.7968 - val_loss: 0.7190 - val_accuracy: 0.7461 - val_prc: 0.8287 - lr: 2.5000e-04\n",
            "Epoch 19/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7777 - accuracy: 0.7020 - prc: 0.8016\n",
            "Epoch 19: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7776 - accuracy: 0.7020 - prc: 0.8017 - val_loss: 0.7634 - val_accuracy: 0.7461 - val_prc: 0.8163 - lr: 2.5000e-04\n",
            "Epoch 20/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7646 - accuracy: 0.7068 - prc: 0.8065\n",
            "Epoch 20: val_prc did not improve from 0.83873\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7646 - accuracy: 0.7067 - prc: 0.8064 - val_loss: 0.7292 - val_accuracy: 0.7306 - val_prc: 0.8283 - lr: 2.5000e-04\n",
            "Epoch 21/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7682 - accuracy: 0.7061 - prc: 0.8054\n",
            "Epoch 21: val_prc improved from 0.83873 to 0.84058, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 13s 22ms/step - loss: 0.7684 - accuracy: 0.7059 - prc: 0.8054 - val_loss: 0.6883 - val_accuracy: 0.7306 - val_prc: 0.8406 - lr: 2.5000e-04\n",
            "Epoch 22/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7680 - accuracy: 0.7088 - prc: 0.8050\n",
            "Epoch 22: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7684 - accuracy: 0.7087 - prc: 0.8048 - val_loss: 0.7329 - val_accuracy: 0.7150 - val_prc: 0.8226 - lr: 2.5000e-04\n",
            "Epoch 23/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7619 - accuracy: 0.7094 - prc: 0.8069\n",
            "Epoch 23: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7618 - accuracy: 0.7094 - prc: 0.8070 - val_loss: 0.7181 - val_accuracy: 0.7047 - val_prc: 0.8208 - lr: 2.5000e-04\n",
            "Epoch 24/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7546 - accuracy: 0.7101 - prc: 0.8100\n",
            "Epoch 24: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7546 - accuracy: 0.7102 - prc: 0.8100 - val_loss: 0.7130 - val_accuracy: 0.7098 - val_prc: 0.8259 - lr: 2.5000e-04\n",
            "Epoch 25/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7551 - accuracy: 0.7135 - prc: 0.8113\n",
            "Epoch 25: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7552 - accuracy: 0.7134 - prc: 0.8113 - val_loss: 0.6936 - val_accuracy: 0.7461 - val_prc: 0.8403 - lr: 2.5000e-04\n",
            "Epoch 26/1000\n",
            "587/587 [==============================] - ETA: 0s - loss: 0.7335 - accuracy: 0.7197 - prc: 0.8195\n",
            "Epoch 26: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7335 - accuracy: 0.7197 - prc: 0.8195 - val_loss: 0.6809 - val_accuracy: 0.7358 - val_prc: 0.8391 - lr: 1.2500e-04\n",
            "Epoch 27/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7314 - accuracy: 0.7165 - prc: 0.8194\n",
            "Epoch 27: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7313 - accuracy: 0.7164 - prc: 0.8194 - val_loss: 0.7132 - val_accuracy: 0.7409 - val_prc: 0.8308 - lr: 1.2500e-04\n",
            "Epoch 28/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7276 - accuracy: 0.7237 - prc: 0.8226\n",
            "Epoch 28: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7278 - accuracy: 0.7236 - prc: 0.8225 - val_loss: 0.7177 - val_accuracy: 0.7358 - val_prc: 0.8327 - lr: 1.2500e-04\n",
            "Epoch 29/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7339 - accuracy: 0.7181 - prc: 0.8195\n",
            "Epoch 29: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7338 - accuracy: 0.7182 - prc: 0.8195 - val_loss: 0.7326 - val_accuracy: 0.7306 - val_prc: 0.8244 - lr: 1.2500e-04\n",
            "Epoch 30/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7256 - accuracy: 0.7203 - prc: 0.8224\n",
            "Epoch 30: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7254 - accuracy: 0.7204 - prc: 0.8225 - val_loss: 0.6942 - val_accuracy: 0.7461 - val_prc: 0.8370 - lr: 1.2500e-04\n",
            "Epoch 31/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7243 - accuracy: 0.7232 - prc: 0.8218\n",
            "Epoch 31: val_prc did not improve from 0.84058\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7244 - accuracy: 0.7232 - prc: 0.8218 - val_loss: 0.7041 - val_accuracy: 0.7358 - val_prc: 0.8354 - lr: 1.2500e-04\n",
            "Epoch 32/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7139 - accuracy: 0.7259 - prc: 0.8273\n",
            "Epoch 32: val_prc improved from 0.84058 to 0.84312, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 13s 23ms/step - loss: 0.7141 - accuracy: 0.7258 - prc: 0.8273 - val_loss: 0.6859 - val_accuracy: 0.7720 - val_prc: 0.8431 - lr: 1.2500e-04\n",
            "Epoch 33/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.7197 - accuracy: 0.7232 - prc: 0.8238\n",
            "Epoch 33: val_prc improved from 0.84312 to 0.84590, saving model to /content/drive/MyDrive/PHD/Model/best_model_DeepSMOTE.h5\n",
            "587/587 [==============================] - 12s 21ms/step - loss: 0.7190 - accuracy: 0.7235 - prc: 0.8241 - val_loss: 0.6685 - val_accuracy: 0.7306 - val_prc: 0.8459 - lr: 1.2500e-04\n",
            "Epoch 34/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7217 - accuracy: 0.7255 - prc: 0.8226\n",
            "Epoch 34: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7216 - accuracy: 0.7256 - prc: 0.8227 - val_loss: 0.6916 - val_accuracy: 0.7150 - val_prc: 0.8357 - lr: 1.2500e-04\n",
            "Epoch 35/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7128 - accuracy: 0.7302 - prc: 0.8274\n",
            "Epoch 35: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7128 - accuracy: 0.7302 - prc: 0.8274 - val_loss: 0.7399 - val_accuracy: 0.6995 - val_prc: 0.8210 - lr: 1.2500e-04\n",
            "Epoch 36/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7076 - accuracy: 0.7333 - prc: 0.8307\n",
            "Epoch 36: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7072 - accuracy: 0.7335 - prc: 0.8308 - val_loss: 0.7099 - val_accuracy: 0.7150 - val_prc: 0.8271 - lr: 1.2500e-04\n",
            "Epoch 37/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7055 - accuracy: 0.7341 - prc: 0.8321\n",
            "Epoch 37: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.7052 - accuracy: 0.7343 - prc: 0.8322 - val_loss: 0.7393 - val_accuracy: 0.7098 - val_prc: 0.8170 - lr: 1.2500e-04\n",
            "Epoch 38/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7142 - accuracy: 0.7266 - prc: 0.8263\n",
            "Epoch 38: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7144 - accuracy: 0.7266 - prc: 0.8263 - val_loss: 0.8047 - val_accuracy: 0.6943 - val_prc: 0.8000 - lr: 1.2500e-04\n",
            "Epoch 39/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7218 - accuracy: 0.7241 - prc: 0.8242\n",
            "Epoch 39: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7216 - accuracy: 0.7242 - prc: 0.8242 - val_loss: 0.7356 - val_accuracy: 0.7513 - val_prc: 0.8243 - lr: 1.2500e-04\n",
            "Epoch 40/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7044 - accuracy: 0.7299 - prc: 0.8297\n",
            "Epoch 40: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7048 - accuracy: 0.7298 - prc: 0.8295 - val_loss: 0.7664 - val_accuracy: 0.7047 - val_prc: 0.8124 - lr: 1.2500e-04\n",
            "Epoch 41/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7033 - accuracy: 0.7330 - prc: 0.8325\n",
            "Epoch 41: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7034 - accuracy: 0.7329 - prc: 0.8324 - val_loss: 0.7352 - val_accuracy: 0.7461 - val_prc: 0.8189 - lr: 1.2500e-04\n",
            "Epoch 42/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7071 - accuracy: 0.7283 - prc: 0.8301\n",
            "Epoch 42: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7070 - accuracy: 0.7283 - prc: 0.8301 - val_loss: 0.7604 - val_accuracy: 0.7202 - val_prc: 0.8146 - lr: 1.2500e-04\n",
            "Epoch 43/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.7006 - accuracy: 0.7328 - prc: 0.8328\n",
            "Epoch 43: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.7004 - accuracy: 0.7329 - prc: 0.8329 - val_loss: 0.7399 - val_accuracy: 0.7150 - val_prc: 0.8282 - lr: 1.2500e-04\n",
            "Epoch 44/1000\n",
            "587/587 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.7351 - prc: 0.8349\n",
            "Epoch 44: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6956 - accuracy: 0.7351 - prc: 0.8349 - val_loss: 0.7641 - val_accuracy: 0.6839 - val_prc: 0.8094 - lr: 6.2500e-05\n",
            "Epoch 45/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6837 - accuracy: 0.7400 - prc: 0.8392\n",
            "Epoch 45: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6837 - accuracy: 0.7400 - prc: 0.8392 - val_loss: 0.7361 - val_accuracy: 0.7254 - val_prc: 0.8218 - lr: 6.2500e-05\n",
            "Epoch 46/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6879 - accuracy: 0.7364 - prc: 0.8368\n",
            "Epoch 46: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6879 - accuracy: 0.7364 - prc: 0.8368 - val_loss: 0.7576 - val_accuracy: 0.7202 - val_prc: 0.8160 - lr: 6.2500e-05\n",
            "Epoch 47/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6860 - accuracy: 0.7378 - prc: 0.8385\n",
            "Epoch 47: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6862 - accuracy: 0.7378 - prc: 0.8384 - val_loss: 0.7268 - val_accuracy: 0.7098 - val_prc: 0.8227 - lr: 6.2500e-05\n",
            "Epoch 48/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6910 - accuracy: 0.7368 - prc: 0.8363\n",
            "Epoch 48: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6911 - accuracy: 0.7367 - prc: 0.8363 - val_loss: 0.7554 - val_accuracy: 0.7202 - val_prc: 0.8114 - lr: 6.2500e-05\n",
            "Epoch 49/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6845 - accuracy: 0.7368 - prc: 0.8392\n",
            "Epoch 49: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6847 - accuracy: 0.7367 - prc: 0.8391 - val_loss: 0.7579 - val_accuracy: 0.7098 - val_prc: 0.8145 - lr: 6.2500e-05\n",
            "Epoch 50/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6780 - accuracy: 0.7393 - prc: 0.8412\n",
            "Epoch 50: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6784 - accuracy: 0.7393 - prc: 0.8412 - val_loss: 0.7606 - val_accuracy: 0.7202 - val_prc: 0.8120 - lr: 6.2500e-05\n",
            "Epoch 51/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6844 - accuracy: 0.7401 - prc: 0.8394\n",
            "Epoch 51: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6845 - accuracy: 0.7400 - prc: 0.8394 - val_loss: 0.7536 - val_accuracy: 0.7150 - val_prc: 0.8157 - lr: 6.2500e-05\n",
            "Epoch 52/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.7375 - prc: 0.8403\n",
            "Epoch 52: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6825 - accuracy: 0.7375 - prc: 0.8403 - val_loss: 0.7414 - val_accuracy: 0.7358 - val_prc: 0.8190 - lr: 6.2500e-05\n",
            "Epoch 53/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6787 - accuracy: 0.7443 - prc: 0.8426\n",
            "Epoch 53: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6784 - accuracy: 0.7444 - prc: 0.8427 - val_loss: 0.7151 - val_accuracy: 0.6995 - val_prc: 0.8313 - lr: 6.2500e-05\n",
            "Epoch 54/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6809 - accuracy: 0.7418 - prc: 0.8404\n",
            "Epoch 54: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.6808 - accuracy: 0.7417 - prc: 0.8404 - val_loss: 0.7543 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 3.1250e-05\n",
            "Epoch 55/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6745 - accuracy: 0.7429 - prc: 0.8420\n",
            "Epoch 55: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6746 - accuracy: 0.7427 - prc: 0.8419 - val_loss: 0.7430 - val_accuracy: 0.7202 - val_prc: 0.8212 - lr: 3.1250e-05\n",
            "Epoch 56/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6858 - accuracy: 0.7380 - prc: 0.8390\n",
            "Epoch 56: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6858 - accuracy: 0.7379 - prc: 0.8390 - val_loss: 0.7498 - val_accuracy: 0.7254 - val_prc: 0.8179 - lr: 3.1250e-05\n",
            "Epoch 57/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6813 - accuracy: 0.7357 - prc: 0.8401\n",
            "Epoch 57: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6816 - accuracy: 0.7354 - prc: 0.8400 - val_loss: 0.7782 - val_accuracy: 0.7306 - val_prc: 0.8076 - lr: 3.1250e-05\n",
            "Epoch 58/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.7436 - prc: 0.8438\n",
            "Epoch 58: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6732 - accuracy: 0.7435 - prc: 0.8438 - val_loss: 0.7529 - val_accuracy: 0.7409 - val_prc: 0.8163 - lr: 3.1250e-05\n",
            "Epoch 59/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6694 - accuracy: 0.7415 - prc: 0.8439\n",
            "Epoch 59: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6694 - accuracy: 0.7415 - prc: 0.8439 - val_loss: 0.7706 - val_accuracy: 0.7461 - val_prc: 0.8103 - lr: 3.1250e-05\n",
            "Epoch 60/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6729 - accuracy: 0.7405 - prc: 0.8436\n",
            "Epoch 60: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6733 - accuracy: 0.7403 - prc: 0.8435 - val_loss: 0.7544 - val_accuracy: 0.7461 - val_prc: 0.8177 - lr: 3.1250e-05\n",
            "Epoch 61/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.7396 - prc: 0.8432\n",
            "Epoch 61: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6746 - accuracy: 0.7398 - prc: 0.8433 - val_loss: 0.7558 - val_accuracy: 0.7513 - val_prc: 0.8183 - lr: 3.1250e-05\n",
            "Epoch 62/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.6671 - accuracy: 0.7434 - prc: 0.8456\n",
            "Epoch 62: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6671 - accuracy: 0.7435 - prc: 0.8456 - val_loss: 0.7617 - val_accuracy: 0.7306 - val_prc: 0.8177 - lr: 3.1250e-05\n",
            "Epoch 63/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6765 - accuracy: 0.7408 - prc: 0.8419\n",
            "Epoch 63: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6770 - accuracy: 0.7406 - prc: 0.8417 - val_loss: 0.7741 - val_accuracy: 0.7254 - val_prc: 0.8087 - lr: 3.1250e-05\n",
            "Epoch 64/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.7442 - prc: 0.8451\n",
            "Epoch 64: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6709 - accuracy: 0.7443 - prc: 0.8452 - val_loss: 0.7707 - val_accuracy: 0.7202 - val_prc: 0.8110 - lr: 1.5625e-05\n",
            "Epoch 65/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6688 - accuracy: 0.7431 - prc: 0.8457\n",
            "Epoch 65: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6684 - accuracy: 0.7433 - prc: 0.8458 - val_loss: 0.7705 - val_accuracy: 0.7150 - val_prc: 0.8115 - lr: 1.5625e-05\n",
            "Epoch 66/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.6601 - accuracy: 0.7471 - prc: 0.8490\n",
            "Epoch 66: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6606 - accuracy: 0.7470 - prc: 0.8489 - val_loss: 0.7598 - val_accuracy: 0.7254 - val_prc: 0.8144 - lr: 1.5625e-05\n",
            "Epoch 67/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6602 - accuracy: 0.7520 - prc: 0.8489\n",
            "Epoch 67: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6602 - accuracy: 0.7521 - prc: 0.8489 - val_loss: 0.7683 - val_accuracy: 0.7098 - val_prc: 0.8124 - lr: 1.5625e-05\n",
            "Epoch 68/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6684 - accuracy: 0.7447 - prc: 0.8445\n",
            "Epoch 68: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6682 - accuracy: 0.7448 - prc: 0.8446 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "# this could also be the output a different Keras model or layer\n",
        "input_shape = X_train.shape[1:]\n",
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "x = data_augmentation(input_tensor)\n",
        "#x = rescale_layer(x)\n",
        "\n",
        "base_model = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)\n",
        "x = base_model(x)\n",
        "\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "#x = base_model.output\n",
        "#x = GlobalAveragePooling2D()(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "x = Flatten()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(128, activation='relu')(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "#predictions = Dense(9)(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=input_tensor, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "#model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# train the model on the new data for a few epochs\n",
        "#hst = model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val, y_val))\n",
        "\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=['accuracy', keras.metrics.AUC(name='prc', curve='PR')])\n",
        "#hst = model.fit(dataaugment.flow(X_train,y_train, batch_size=BATCH_SIZE),\n",
        "hst = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,      \n",
        "                    #steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WA3NkiOqePA"
      },
      "outputs": [],
      "source": [
        "# load the saved model\n",
        "#best_model = load_model(best_model_fpath)\n",
        "# evaluate the model\n",
        "#_, train_acc = best_model.evaluate(X_train, y_train, verbose=0)\n",
        "#_, test_acc = best_model.evaluate(X_val, y_val, verbose=0)\n",
        "#print('Train: %.3f, Val: %.3f' % (train_acc, test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vXnW3lmCgln3",
        "outputId": "63e65cd6-b6af-4e7e-8842-8569913d3794"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l8bZo4LoEiQf"
      },
      "outputs": [],
      "source": [
        "#finetune_model_fpath = '/content/drive/MyDrive/PHD/Model/finetune_model.h5'\n",
        "#mc_finetune = ModelCheckpoint(finetune_model_fpath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr1jnSM7yzJc",
        "outputId": "07060090-d74f-4b33-bae8-42d37b46678d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "585/587 [============================>.] - ETA: 0s - loss: 0.6657 - accuracy: 0.7467 - prc: 0.8471\n",
            "Epoch 1: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 15s 20ms/step - loss: 0.6658 - accuracy: 0.7466 - prc: 0.8470 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 2/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6687 - accuracy: 0.7428 - prc: 0.8460\n",
            "Epoch 2: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6687 - accuracy: 0.7428 - prc: 0.8460 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 3/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6607 - accuracy: 0.7481 - prc: 0.8471\n",
            "Epoch 3: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6606 - accuracy: 0.7482 - prc: 0.8472 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 4/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6634 - accuracy: 0.7478 - prc: 0.8474\n",
            "Epoch 4: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6636 - accuracy: 0.7477 - prc: 0.8473 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 5/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6642 - accuracy: 0.7425 - prc: 0.8474\n",
            "Epoch 5: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6646 - accuracy: 0.7423 - prc: 0.8472 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 6/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.7414 - prc: 0.8429\n",
            "Epoch 6: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6715 - accuracy: 0.7414 - prc: 0.8429 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 7/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6684 - accuracy: 0.7431 - prc: 0.8448\n",
            "Epoch 7: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6682 - accuracy: 0.7431 - prc: 0.8449 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 8/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6615 - accuracy: 0.7485 - prc: 0.8486\n",
            "Epoch 8: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6617 - accuracy: 0.7484 - prc: 0.8486 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 9/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6598 - accuracy: 0.7454 - prc: 0.8473\n",
            "Epoch 9: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6596 - accuracy: 0.7454 - prc: 0.8474 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 10/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6663 - accuracy: 0.7468 - prc: 0.8468\n",
            "Epoch 10: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.6665 - accuracy: 0.7467 - prc: 0.8468 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 11/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.7413 - prc: 0.8441\n",
            "Epoch 11: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6717 - accuracy: 0.7415 - prc: 0.8443 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.5625e-05\n",
            "Epoch 12/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6676 - accuracy: 0.7427 - prc: 0.8442\n",
            "Epoch 12: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6674 - accuracy: 0.7428 - prc: 0.8444 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 13/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6625 - accuracy: 0.7462 - prc: 0.8476\n",
            "Epoch 13: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6625 - accuracy: 0.7461 - prc: 0.8476 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 14/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.7468 - prc: 0.8446\n",
            "Epoch 14: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6721 - accuracy: 0.7468 - prc: 0.8446 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 15/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6738 - accuracy: 0.7447 - prc: 0.8430\n",
            "Epoch 15: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6735 - accuracy: 0.7448 - prc: 0.8431 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 16/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6679 - accuracy: 0.7467 - prc: 0.8460\n",
            "Epoch 16: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6678 - accuracy: 0.7468 - prc: 0.8461 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 17/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6672 - accuracy: 0.7461 - prc: 0.8460\n",
            "Epoch 17: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 19ms/step - loss: 0.6669 - accuracy: 0.7462 - prc: 0.8460 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 18/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6640 - accuracy: 0.7463 - prc: 0.8477\n",
            "Epoch 18: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6638 - accuracy: 0.7462 - prc: 0.8477 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 19/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.7464 - prc: 0.8443\n",
            "Epoch 19: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6701 - accuracy: 0.7466 - prc: 0.8443 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 20/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6652 - accuracy: 0.7439 - prc: 0.8467\n",
            "Epoch 20: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6654 - accuracy: 0.7438 - prc: 0.8466 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 21/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.7431 - prc: 0.8443\n",
            "Epoch 21: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6706 - accuracy: 0.7432 - prc: 0.8445 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 22/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6586 - accuracy: 0.7481 - prc: 0.8497\n",
            "Epoch 22: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6585 - accuracy: 0.7481 - prc: 0.8498 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 23/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6757 - accuracy: 0.7426 - prc: 0.8427\n",
            "Epoch 23: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6759 - accuracy: 0.7426 - prc: 0.8426 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 24/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6647 - accuracy: 0.7506 - prc: 0.8473\n",
            "Epoch 24: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6646 - accuracy: 0.7505 - prc: 0.8473 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 25/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6626 - accuracy: 0.7434 - prc: 0.8462\n",
            "Epoch 25: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6627 - accuracy: 0.7433 - prc: 0.8461 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 26/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.7414 - prc: 0.8421\n",
            "Epoch 26: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.6747 - accuracy: 0.7416 - prc: 0.8422 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 27/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6650 - accuracy: 0.7448 - prc: 0.8459\n",
            "Epoch 27: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.6650 - accuracy: 0.7448 - prc: 0.8458 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 28/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6639 - accuracy: 0.7472 - prc: 0.8462\n",
            "Epoch 28: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 11s 20ms/step - loss: 0.6640 - accuracy: 0.7472 - prc: 0.8461 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 29/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.7419 - prc: 0.8437\n",
            "Epoch 29: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6717 - accuracy: 0.7418 - prc: 0.8437 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 30/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6636 - accuracy: 0.7448 - prc: 0.8472\n",
            "Epoch 30: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6633 - accuracy: 0.7450 - prc: 0.8472 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n",
            "Epoch 31/1000\n",
            "586/587 [============================>.] - ETA: 0s - loss: 0.6624 - accuracy: 0.7456 - prc: 0.8467\n",
            "Epoch 31: val_prc did not improve from 0.84590\n",
            "587/587 [==============================] - 12s 20ms/step - loss: 0.6622 - accuracy: 0.7456 - prc: 0.8468 - val_loss: 0.7658 - val_accuracy: 0.7202 - val_prc: 0.8142 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# we chose to train the top 2 resnet blocks, i.e. we will freeze\n",
        "# the first 49 layers and unfreeze the rest:\n",
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "#model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "#hst2 = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val, y_val))\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=['accuracy', keras.metrics.AUC(name='prc', curve='PR')])\n",
        "#hst2 = model.fit(dataaugment.flow(X_train,y_train, batch_size=BATCH_SIZE),\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        " #                   steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SPz8NH1Oylv9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "\n",
        "model.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS3ewyxO_anU",
        "outputId": "32472d44-8246-4675-9d1c-cdb39200a33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balanced accuracy on training 0.669276659209545\n",
            "balanced accuracy on validation 0.4477302894550282\n",
            "Score on val data:  (0.5095860566448802, 0.4477302894550282, 0.44639760895918534, None)\n"
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath)\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3IyWjdGG4Xq",
        "outputId": "670c3dd1-aeab-4e2d-a0b4-030622f42441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balanced accuracy on training 0.6690103334398636\n",
            "balanced accuracy on validation 0.44019865152269333\n",
            "Score on val data:  (0.5207671957671958, 0.44019865152269333, 0.4551700927284494, None)\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath)\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['accuracy'])\n",
        "plt.plot(hst2.history['val_accuracy'])\n",
        "plt.title('model accuracy after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing\n",
        "Result from ISIC Live\n",
        "last_model: 0.506\n",
        "best_model: 0.478"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']\n",
        "#df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60LYAT7VsNOZ",
        "outputId": "c2734b0f-1334-4da5-8e51-cbe46489cc65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 56, 56, 3)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.asarray(df_test['image'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIX0AmEFNv3Y",
        "outputId": "575e8d1d-7b97-424c-ba85-fe55a78f0ec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_pred2 (1512, 7)\n",
            "y_pred2 1512\n"
          ]
        }
      ],
      "source": [
        "# predicted labels\n",
        "Y_pred2 = last_model.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)\n",
        "# rounded labels\n",
        "y_pred2 = np.argmax(Y_pred2, axis=1)\n",
        "print(\"y_pred2\", y_pred2.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.set_index(\"image\", inplace = True)\n",
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_DeepSMOTEOversampling_last.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4nEpmkZaTZC",
        "outputId": "8b9cfe6b-13f8-4acb-98df-01ef13226d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2   1   3   0   1   1   0]\n",
            " [  5   9   1   0   0   0   0]\n",
            " [  2   0   9   0   4   7   0]\n",
            " [  0   0   0   0   0   1   0]\n",
            " [  0   1   3   0  13   4   0]\n",
            " [  0   2   4   1   9 107   0]\n",
            " [  0   2   0   0   0   0   1]]\n"
          ]
        }
      ],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1))\n",
        "\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "gVtvW3YeaLlC",
        "outputId": "dc92dc16-f448-4ce5-e86b-4a317ef753cf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "Ey-1yjWGeKs7",
        "outputId": "046cbd7a-4f48-46e1-bb93-cd2cc5804307"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'AKIEC'),\n",
              " Text(0, 0, 'BCC'),\n",
              " Text(0, 0, 'BKL'),\n",
              " Text(0, 0, 'DF'),\n",
              " Text(0, 0, 'MEL'),\n",
              " Text(0, 0, 'NV'),\n",
              " Text(0, 0, 'VASC')]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RcRGeofw-8tK",
        "uZv-B-ygCD57",
        "cNBXx28B9yGu",
        "US0KkIaVlTdU",
        "0jrJ33lUDkCM",
        "3K908bbiYwbS"
      ],
      "machine_shape": "hm",
      "name": "Skin Cancer Diagnosis using ISIC 2018 Dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}