{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Skin-Cancer-Diagnosis/blob/main/Skin_Cancer_Diagnosis_using_ISIC_2018_Dataset_OversamplingOnFeatureMaps_Resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUusDE1Z9TNb"
      },
      "source": [
        "Prepare the dataset. \n",
        "Currently, we use skin cancer ISIC dataset from Kaggle https://www.kaggle.com/datasets/nodoubttome/skin-cancer9-classesisic\n",
        "\n",
        "Tutorial for how to load Kaggle dataset can be found in https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "3a99ae4c-8619-4b5f-8084-b01ee9ae54c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR2MJBYq-oiB",
        "outputId": "ff75a5ef-7907-4333-ab56-220ab9c7ac94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "!pip install imbalanced-learn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 224\n",
        "IMAGE_H = 224\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 300\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "the_arch = 'resnet50'\n",
        "\n",
        "#Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2), \n",
        "  layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3)),\n",
        "  layers.experimental.preprocessing.RandomTranslation(0.3, 0.3, fill_mode='reflect', interpolation='bilinear',)\n",
        "])\n",
        "\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_no.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_no.h5'\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=50, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=50,monitor='val_balanced_acc')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images, arch = the_arch):\n",
        "  input_images = input_images.astype('float32')\n",
        "  if arch == 'inception_v3':\n",
        "    output_ims = tf.keras.applications.inception_v3.preprocess_input(input_images)\n",
        "  else:\n",
        "    output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "    # load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "    # one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def balanced_acc(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    \n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    return balanced_acc\n",
        "\n",
        "def define_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    # compile model\n",
        "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def define_base_model(arch = the_arch):\n",
        "  if arch == 'dense':\n",
        "    input_tensor = Input(shape=(2048))\n",
        "  else:\n",
        "    input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "  #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  if arch == 'resnet50':\n",
        "    x = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)(input_tensor, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "  elif arch == 'inception_v3':\n",
        "    x = InceptionV3(input_shape=(224,224,3), weights='imagenet', include_top=False)(input_tensor, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "  else:\n",
        "    x = input_tensor\n",
        "  #x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    plt.close()\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "    # convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    # return normalized images\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val, df_train, df_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train, the_arch)\n",
        "  X_val = preprocess_image_input(X_val, the_arch)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, IMAGE_W * IMAGE_H * 3)), y)\n",
        "  X_resampled = X_resampled.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def SMOTE_Data2(X, y, one_hot = False, k = 5):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exp"
      ],
      "metadata": {
        "id": "UswA0co2y1wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "x = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)(input_tensor, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "res50 = Model(inputs=input_tensor, outputs=x)"
      ],
      "metadata": {
        "id": "dnqJYIONy34l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = res50.predict(X_train)\n",
        "X_val = res50.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA7Af2Y73FUv",
        "outputId": "63498393-b40a-4efb-ec36-2427fbe37935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 2048)\n",
            "(5321, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krJiAb1m3QNf",
        "outputId": "fc0dfaf9-da03-4d79-c03d-584362e908f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 2048)\n",
            "(14077, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bw4C7Fwwxad"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_cifar10_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QM00erNGU32",
        "outputId": "9a5b6e0d-eb0f-45de-a6bb-23b588f2f22e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 224, 224, 3)\n",
            "(5321, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "X_train, y_train, X_val, y_val, df_train, df_val = load_isic2018_dataset(train_under_frac = 0.7)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-rGI2h3JN5s"
      },
      "outputs": [],
      "source": [
        "X_train = preprocess_image_input(X_train, the_arch)\n",
        "X_val = preprocess_image_input(X_val, the_arch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xArGWuciBt_-",
        "outputId": "49ce963a-7a3d-43a3-ce99-876400f8601f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 2048)\n",
            "(14077, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8eRZiucdYnP"
      },
      "outputs": [],
      "source": [
        "#USe TF.data\n",
        "#training_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "#validation_data = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "\n",
        "#autotune = tf.data.AUTOTUNE\n",
        "#train_data_batches = training_data.shuffle(buffer_size=40000).batch(BATCH_SIZE).prefetch(buffer_size=autotune)\n",
        "#valid_data_batches = validation_data.shuffle(buffer_size=10000).batch(BATCH_SIZE).prefetch(buffer_size=autotune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Z_nccu6QjB"
      },
      "outputs": [],
      "source": [
        "#path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "#df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "#df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "#df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "#df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "#df1.to_pickle(path+\"isic2018_train.pkl\")\n",
        "#df2.to_pickle(path+\"isic2018_val.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qge6cnxQPnH6"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.read_pickle(path+\"isic2018_train.pkl\")\n",
        "X_train = df1.loc[:, df1.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,224,224,3)\n",
        "y_train = df1.loc[:, df1.columns == 'y_train'].to_numpy()\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "df1 = pd.read_pickle(path+\"isic2018_val.pkl\")\n",
        "X_val = df1.loc[:, df1.columns != 'y_val'].to_numpy()\n",
        "X_val = X_val.reshape(-1,224,224,3)\n",
        "y_val = df1.loc[:, df1.columns == 'y_val'].to_numpy()\n",
        "y_val = to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAMBgWqIsAAB"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIygrW81Ln4z",
        "outputId": "3d0a950a-eb81-4d3c-afba-a7e0c574eb85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 2048)]            0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,626,567\n",
            "Trainable params: 2,626,567\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 1.7853 - accuracy: 0.3160 - balanced_acc: 0.3161\n",
            "Epoch 1: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.7685 - accuracy: 0.3241 - balanced_acc: 0.3250 - val_loss: 1.4837 - val_accuracy: 0.5078 - val_balanced_acc: 0.2106 - lr: 5.0000e-04\n",
            "Epoch 2/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 1.4164 - accuracy: 0.4834 - balanced_acc: 0.4842\n",
            "Epoch 2: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 1.4088 - accuracy: 0.4867 - balanced_acc: 0.4870 - val_loss: 1.3865 - val_accuracy: 0.5233 - val_balanced_acc: 0.2676 - lr: 5.0000e-04\n",
            "Epoch 3/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.2508 - accuracy: 0.5519 - balanced_acc: 0.5510\n",
            "Epoch 3: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 1.2503 - accuracy: 0.5517 - balanced_acc: 0.5509 - val_loss: 1.2510 - val_accuracy: 0.5699 - val_balanced_acc: 0.2831 - lr: 5.0000e-04\n",
            "Epoch 4/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 1.1575 - accuracy: 0.5902 - balanced_acc: 0.5879\n",
            "Epoch 4: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1577 - accuracy: 0.5900 - balanced_acc: 0.5879 - val_loss: 1.1639 - val_accuracy: 0.5855 - val_balanced_acc: 0.2856 - lr: 5.0000e-04\n",
            "Epoch 5/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.0854 - accuracy: 0.6141 - balanced_acc: 0.6127\n",
            "Epoch 5: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0844 - accuracy: 0.6140 - balanced_acc: 0.6123 - val_loss: 1.1613 - val_accuracy: 0.5751 - val_balanced_acc: 0.2935 - lr: 5.0000e-04\n",
            "Epoch 6/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 1.0285 - accuracy: 0.6378 - balanced_acc: 0.6365\n",
            "Epoch 6: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 1.0283 - accuracy: 0.6378 - balanced_acc: 0.6368 - val_loss: 1.1024 - val_accuracy: 0.5959 - val_balanced_acc: 0.3134 - lr: 5.0000e-04\n",
            "Epoch 7/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9812 - accuracy: 0.6492 - balanced_acc: 0.6487\n",
            "Epoch 7: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.9795 - accuracy: 0.6497 - balanced_acc: 0.6491 - val_loss: 1.0886 - val_accuracy: 0.6062 - val_balanced_acc: 0.3310 - lr: 5.0000e-04\n",
            "Epoch 8/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.9496 - accuracy: 0.6638 - balanced_acc: 0.6634\n",
            "Epoch 8: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9457 - accuracy: 0.6652 - balanced_acc: 0.6643 - val_loss: 1.0277 - val_accuracy: 0.6218 - val_balanced_acc: 0.3416 - lr: 5.0000e-04\n",
            "Epoch 9/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.9160 - accuracy: 0.6774 - balanced_acc: 0.6772\n",
            "Epoch 9: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9157 - accuracy: 0.6773 - balanced_acc: 0.6767 - val_loss: 1.0208 - val_accuracy: 0.6218 - val_balanced_acc: 0.3497 - lr: 5.0000e-04\n",
            "Epoch 10/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8954 - accuracy: 0.6852 - balanced_acc: 0.6844\n",
            "Epoch 10: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8962 - accuracy: 0.6849 - balanced_acc: 0.6842 - val_loss: 1.0077 - val_accuracy: 0.6373 - val_balanced_acc: 0.3637 - lr: 5.0000e-04\n",
            "Epoch 11/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8631 - accuracy: 0.6940 - balanced_acc: 0.6934\n",
            "Epoch 11: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.8621 - accuracy: 0.6942 - balanced_acc: 0.6937 - val_loss: 0.9705 - val_accuracy: 0.6373 - val_balanced_acc: 0.3625 - lr: 5.0000e-04\n",
            "Epoch 12/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8467 - accuracy: 0.7014 - balanced_acc: 0.7010\n",
            "Epoch 12: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.8460 - accuracy: 0.7016 - balanced_acc: 0.7014 - val_loss: 0.9710 - val_accuracy: 0.6425 - val_balanced_acc: 0.3654 - lr: 5.0000e-04\n",
            "Epoch 13/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8230 - accuracy: 0.7142 - balanced_acc: 0.7127\n",
            "Epoch 13: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.8239 - accuracy: 0.7137 - balanced_acc: 0.7125 - val_loss: 0.9580 - val_accuracy: 0.6425 - val_balanced_acc: 0.3663 - lr: 5.0000e-04\n",
            "Epoch 14/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8045 - accuracy: 0.7178 - balanced_acc: 0.7165\n",
            "Epoch 14: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.8047 - accuracy: 0.7171 - balanced_acc: 0.7160 - val_loss: 0.9625 - val_accuracy: 0.6321 - val_balanced_acc: 0.3572 - lr: 5.0000e-04\n",
            "Epoch 15/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7888 - accuracy: 0.7260 - balanced_acc: 0.7293\n",
            "Epoch 15: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.7889 - accuracy: 0.7262 - balanced_acc: 0.7295 - val_loss: 0.9267 - val_accuracy: 0.6528 - val_balanced_acc: 0.3403 - lr: 5.0000e-04\n",
            "Epoch 16/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.7780 - accuracy: 0.7294 - balanced_acc: 0.7288\n",
            "Epoch 16: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.7756 - accuracy: 0.7305 - balanced_acc: 0.7305 - val_loss: 0.9459 - val_accuracy: 0.6528 - val_balanced_acc: 0.3698 - lr: 5.0000e-04\n",
            "Epoch 17/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.7647 - accuracy: 0.7316 - balanced_acc: 0.7295\n",
            "Epoch 17: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.7655 - accuracy: 0.7315 - balanced_acc: 0.7295 - val_loss: 0.9502 - val_accuracy: 0.6373 - val_balanced_acc: 0.3652 - lr: 5.0000e-04\n",
            "Epoch 18/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7442 - accuracy: 0.7412 - balanced_acc: 0.7408\n",
            "Epoch 18: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.7445 - accuracy: 0.7412 - balanced_acc: 0.7409 - val_loss: 0.8992 - val_accuracy: 0.6632 - val_balanced_acc: 0.3459 - lr: 5.0000e-04\n",
            "Epoch 19/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.7329 - accuracy: 0.7443 - balanced_acc: 0.7432\n",
            "Epoch 19: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.7346 - accuracy: 0.7435 - balanced_acc: 0.7427 - val_loss: 0.9044 - val_accuracy: 0.6528 - val_balanced_acc: 0.3597 - lr: 5.0000e-04\n",
            "Epoch 20/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.7259 - accuracy: 0.7479 - balanced_acc: 0.7477\n",
            "Epoch 20: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.7248 - accuracy: 0.7482 - balanced_acc: 0.7480 - val_loss: 0.9280 - val_accuracy: 0.6477 - val_balanced_acc: 0.3540 - lr: 5.0000e-04\n",
            "Epoch 21/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.7110 - accuracy: 0.7539 - balanced_acc: 0.7544\n",
            "Epoch 21: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.7110 - accuracy: 0.7539 - balanced_acc: 0.7544 - val_loss: 0.9204 - val_accuracy: 0.6632 - val_balanced_acc: 0.3980 - lr: 5.0000e-04\n",
            "Epoch 22/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.7014 - accuracy: 0.7512 - balanced_acc: 0.7525\n",
            "Epoch 22: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.7017 - accuracy: 0.7508 - balanced_acc: 0.7518 - val_loss: 0.8960 - val_accuracy: 0.6839 - val_balanced_acc: 0.3806 - lr: 5.0000e-04\n",
            "Epoch 23/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.6911 - accuracy: 0.7567 - balanced_acc: 0.7575\n",
            "Epoch 23: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6922 - accuracy: 0.7566 - balanced_acc: 0.7575 - val_loss: 0.8784 - val_accuracy: 0.6788 - val_balanced_acc: 0.3724 - lr: 5.0000e-04\n",
            "Epoch 24/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.6886 - accuracy: 0.7604 - balanced_acc: 0.7593\n",
            "Epoch 24: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6875 - accuracy: 0.7609 - balanced_acc: 0.7598 - val_loss: 0.8818 - val_accuracy: 0.6736 - val_balanced_acc: 0.3657 - lr: 5.0000e-04\n",
            "Epoch 25/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.6704 - accuracy: 0.7644 - balanced_acc: 0.7657\n",
            "Epoch 25: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6704 - accuracy: 0.7644 - balanced_acc: 0.7657 - val_loss: 0.8869 - val_accuracy: 0.6839 - val_balanced_acc: 0.3769 - lr: 5.0000e-04\n",
            "Epoch 26/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.6621 - accuracy: 0.7702 - balanced_acc: 0.7719\n",
            "Epoch 26: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6627 - accuracy: 0.7700 - balanced_acc: 0.7717 - val_loss: 0.8678 - val_accuracy: 0.6788 - val_balanced_acc: 0.3604 - lr: 5.0000e-04\n",
            "Epoch 27/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.6584 - accuracy: 0.7719 - balanced_acc: 0.7723\n",
            "Epoch 27: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6591 - accuracy: 0.7723 - balanced_acc: 0.7727 - val_loss: 0.8809 - val_accuracy: 0.6684 - val_balanced_acc: 0.3630 - lr: 5.0000e-04\n",
            "Epoch 28/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.6486 - accuracy: 0.7729 - balanced_acc: 0.7710\n",
            "Epoch 28: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6486 - accuracy: 0.7729 - balanced_acc: 0.7710 - val_loss: 0.8930 - val_accuracy: 0.6788 - val_balanced_acc: 0.3739 - lr: 5.0000e-04\n",
            "Epoch 29/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.6412 - accuracy: 0.7752 - balanced_acc: 0.7729\n",
            "Epoch 29: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6405 - accuracy: 0.7754 - balanced_acc: 0.7732 - val_loss: 0.8973 - val_accuracy: 0.6788 - val_balanced_acc: 0.3775 - lr: 5.0000e-04\n",
            "Epoch 30/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.6362 - accuracy: 0.7760 - balanced_acc: 0.7766\n",
            "Epoch 30: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6352 - accuracy: 0.7770 - balanced_acc: 0.7777 - val_loss: 0.8794 - val_accuracy: 0.6684 - val_balanced_acc: 0.3602 - lr: 5.0000e-04\n",
            "Epoch 31/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.6319 - accuracy: 0.7804 - balanced_acc: 0.7829\n",
            "Epoch 31: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6315 - accuracy: 0.7806 - balanced_acc: 0.7828 - val_loss: 0.8368 - val_accuracy: 0.6891 - val_balanced_acc: 0.3664 - lr: 5.0000e-04\n",
            "Epoch 32/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.6135 - accuracy: 0.7847 - balanced_acc: 0.7816\n",
            "Epoch 32: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6134 - accuracy: 0.7848 - balanced_acc: 0.7818 - val_loss: 0.8412 - val_accuracy: 0.6839 - val_balanced_acc: 0.3613 - lr: 5.0000e-04\n",
            "Epoch 33/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.6162 - accuracy: 0.7839 - balanced_acc: 0.7859\n",
            "Epoch 33: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6128 - accuracy: 0.7848 - balanced_acc: 0.7865 - val_loss: 0.8753 - val_accuracy: 0.6943 - val_balanced_acc: 0.3880 - lr: 5.0000e-04\n",
            "Epoch 34/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.6023 - accuracy: 0.7928 - balanced_acc: 0.7923\n",
            "Epoch 34: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6021 - accuracy: 0.7934 - balanced_acc: 0.7929 - val_loss: 0.8464 - val_accuracy: 0.6684 - val_balanced_acc: 0.3560 - lr: 5.0000e-04\n",
            "Epoch 35/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.5955 - accuracy: 0.7951 - balanced_acc: 0.7953\n",
            "Epoch 35: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6003 - accuracy: 0.7932 - balanced_acc: 0.7932 - val_loss: 0.8362 - val_accuracy: 0.7047 - val_balanced_acc: 0.3819 - lr: 5.0000e-04\n",
            "Epoch 36/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.5927 - accuracy: 0.7930 - balanced_acc: 0.7929\n",
            "Epoch 36: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.7935 - balanced_acc: 0.7931 - val_loss: 0.8417 - val_accuracy: 0.6943 - val_balanced_acc: 0.3739 - lr: 5.0000e-04\n",
            "Epoch 37/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.7930 - balanced_acc: 0.7942\n",
            "Epoch 37: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5923 - accuracy: 0.7930 - balanced_acc: 0.7942 - val_loss: 0.8797 - val_accuracy: 0.6580 - val_balanced_acc: 0.3570 - lr: 5.0000e-04\n",
            "Epoch 38/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.5809 - accuracy: 0.7994 - balanced_acc: 0.7991\n",
            "Epoch 38: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5789 - accuracy: 0.7998 - balanced_acc: 0.7996 - val_loss: 0.8335 - val_accuracy: 0.6943 - val_balanced_acc: 0.3739 - lr: 5.0000e-04\n",
            "Epoch 39/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.5758 - accuracy: 0.8029 - balanced_acc: 0.8031\n",
            "Epoch 39: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5772 - accuracy: 0.8017 - balanced_acc: 0.8020 - val_loss: 0.8739 - val_accuracy: 0.6788 - val_balanced_acc: 0.3749 - lr: 5.0000e-04\n",
            "Epoch 40/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.5693 - accuracy: 0.8044 - balanced_acc: 0.8042\n",
            "Epoch 40: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5696 - accuracy: 0.8043 - balanced_acc: 0.8041 - val_loss: 0.8361 - val_accuracy: 0.6943 - val_balanced_acc: 0.3739 - lr: 5.0000e-04\n",
            "Epoch 41/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.5645 - accuracy: 0.8070 - balanced_acc: 0.8078\n",
            "Epoch 41: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5628 - accuracy: 0.8077 - balanced_acc: 0.8078 - val_loss: 0.8393 - val_accuracy: 0.6943 - val_balanced_acc: 0.3739 - lr: 5.0000e-04\n",
            "Epoch 42/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.8088 - balanced_acc: 0.8069\n",
            "Epoch 42: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5549 - accuracy: 0.8088 - balanced_acc: 0.8069 - val_loss: 0.8556 - val_accuracy: 0.6736 - val_balanced_acc: 0.3579 - lr: 5.0000e-04\n",
            "Epoch 43/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.5549 - accuracy: 0.8076 - balanced_acc: 0.8077\n",
            "Epoch 43: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5565 - accuracy: 0.8069 - balanced_acc: 0.8063 - val_loss: 0.8155 - val_accuracy: 0.6891 - val_balanced_acc: 0.3658 - lr: 5.0000e-04\n",
            "Epoch 44/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.5377 - accuracy: 0.8165 - balanced_acc: 0.8169\n",
            "Epoch 44: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5391 - accuracy: 0.8164 - balanced_acc: 0.8171 - val_loss: 0.8122 - val_accuracy: 0.6891 - val_balanced_acc: 0.3611 - lr: 5.0000e-04\n",
            "Epoch 45/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.5497 - accuracy: 0.8123 - balanced_acc: 0.8126\n",
            "Epoch 45: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5496 - accuracy: 0.8122 - balanced_acc: 0.8122 - val_loss: 0.8053 - val_accuracy: 0.6943 - val_balanced_acc: 0.3703 - lr: 5.0000e-04\n",
            "Epoch 46/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.5373 - accuracy: 0.8140 - balanced_acc: 0.8151\n",
            "Epoch 46: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5373 - accuracy: 0.8140 - balanced_acc: 0.8151 - val_loss: 0.8170 - val_accuracy: 0.7047 - val_balanced_acc: 0.3783 - lr: 5.0000e-04\n",
            "Epoch 47/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.5319 - accuracy: 0.8193 - balanced_acc: 0.8187\n",
            "Epoch 47: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5314 - accuracy: 0.8190 - balanced_acc: 0.8184 - val_loss: 0.8308 - val_accuracy: 0.6684 - val_balanced_acc: 0.3550 - lr: 5.0000e-04\n",
            "Epoch 48/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.8177 - balanced_acc: 0.8192\n",
            "Epoch 48: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5339 - accuracy: 0.8177 - balanced_acc: 0.8192 - val_loss: 0.7981 - val_accuracy: 0.6839 - val_balanced_acc: 0.3860 - lr: 5.0000e-04\n",
            "Epoch 49/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.5211 - accuracy: 0.8187 - balanced_acc: 0.8170\n",
            "Epoch 49: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5217 - accuracy: 0.8183 - balanced_acc: 0.8169 - val_loss: 0.8055 - val_accuracy: 0.6995 - val_balanced_acc: 0.3738 - lr: 5.0000e-04\n",
            "Epoch 50/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.5186 - accuracy: 0.8191 - balanced_acc: 0.8194\n",
            "Epoch 50: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5186 - accuracy: 0.8191 - balanced_acc: 0.8194 - val_loss: 0.8002 - val_accuracy: 0.6995 - val_balanced_acc: 0.3738 - lr: 5.0000e-04\n",
            "Epoch 51/300\n",
            "202/219 [==========================>...] - ETA: 0s - loss: 0.5125 - accuracy: 0.8246 - balanced_acc: 0.8237\n",
            "Epoch 51: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5149 - accuracy: 0.8244 - balanced_acc: 0.8235 - val_loss: 0.7933 - val_accuracy: 0.6995 - val_balanced_acc: 0.3703 - lr: 5.0000e-04\n",
            "Epoch 52/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.5074 - accuracy: 0.8271 - balanced_acc: 0.8261\n",
            "Epoch 52: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5084 - accuracy: 0.8265 - balanced_acc: 0.8261 - val_loss: 0.7973 - val_accuracy: 0.6943 - val_balanced_acc: 0.3694 - lr: 5.0000e-04\n",
            "Epoch 53/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.5084 - accuracy: 0.8271 - balanced_acc: 0.8275\n",
            "Epoch 53: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5084 - accuracy: 0.8277 - balanced_acc: 0.8280 - val_loss: 0.7940 - val_accuracy: 0.7047 - val_balanced_acc: 0.3783 - lr: 5.0000e-04\n",
            "Epoch 54/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.5085 - accuracy: 0.8262 - balanced_acc: 0.8252\n",
            "Epoch 54: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5086 - accuracy: 0.8259 - balanced_acc: 0.8249 - val_loss: 0.8021 - val_accuracy: 0.6943 - val_balanced_acc: 0.3649 - lr: 5.0000e-04\n",
            "Epoch 55/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.4980 - accuracy: 0.8334 - balanced_acc: 0.8339\n",
            "Epoch 55: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4999 - accuracy: 0.8324 - balanced_acc: 0.8326 - val_loss: 0.8324 - val_accuracy: 0.6788 - val_balanced_acc: 0.3951 - lr: 5.0000e-04\n",
            "Epoch 56/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4973 - accuracy: 0.8287 - balanced_acc: 0.8273\n",
            "Epoch 56: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4973 - accuracy: 0.8287 - balanced_acc: 0.8273 - val_loss: 0.8091 - val_accuracy: 0.6943 - val_balanced_acc: 0.3976 - lr: 5.0000e-04\n",
            "Epoch 57/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.4848 - accuracy: 0.8349 - balanced_acc: 0.8318\n",
            "Epoch 57: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4862 - accuracy: 0.8344 - balanced_acc: 0.8311 - val_loss: 0.7556 - val_accuracy: 0.7047 - val_balanced_acc: 0.3774 - lr: 5.0000e-04\n",
            "Epoch 58/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4876 - accuracy: 0.8363 - balanced_acc: 0.8375\n",
            "Epoch 58: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.8363 - balanced_acc: 0.8375 - val_loss: 0.8000 - val_accuracy: 0.7047 - val_balanced_acc: 0.3810 - lr: 5.0000e-04\n",
            "Epoch 59/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.4891 - accuracy: 0.8325 - balanced_acc: 0.8325\n",
            "Epoch 59: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.8332 - balanced_acc: 0.8330 - val_loss: 0.7973 - val_accuracy: 0.6995 - val_balanced_acc: 0.3738 - lr: 5.0000e-04\n",
            "Epoch 60/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.8398 - balanced_acc: 0.8399\n",
            "Epoch 60: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4798 - accuracy: 0.8398 - balanced_acc: 0.8399 - val_loss: 0.8097 - val_accuracy: 0.6839 - val_balanced_acc: 0.3675 - lr: 5.0000e-04\n",
            "Epoch 61/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.4775 - accuracy: 0.8388 - balanced_acc: 0.8410\n",
            "Epoch 61: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4776 - accuracy: 0.8391 - balanced_acc: 0.8415 - val_loss: 0.7849 - val_accuracy: 0.7047 - val_balanced_acc: 0.3783 - lr: 5.0000e-04\n",
            "Epoch 62/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.4723 - accuracy: 0.8419 - balanced_acc: 0.8412\n",
            "Epoch 62: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4721 - accuracy: 0.8421 - balanced_acc: 0.8420 - val_loss: 0.7980 - val_accuracy: 0.6891 - val_balanced_acc: 0.3620 - lr: 5.0000e-04\n",
            "Epoch 63/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.4566 - accuracy: 0.8469 - balanced_acc: 0.8463\n",
            "Epoch 63: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4580 - accuracy: 0.8468 - balanced_acc: 0.8463 - val_loss: 0.8235 - val_accuracy: 0.6839 - val_balanced_acc: 0.3710 - lr: 5.0000e-04\n",
            "Epoch 64/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.4725 - accuracy: 0.8388 - balanced_acc: 0.8392\n",
            "Epoch 64: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4736 - accuracy: 0.8384 - balanced_acc: 0.8387 - val_loss: 0.7851 - val_accuracy: 0.7098 - val_balanced_acc: 0.4146 - lr: 5.0000e-04\n",
            "Epoch 65/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.4618 - accuracy: 0.8431 - balanced_acc: 0.8438\n",
            "Epoch 65: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4617 - accuracy: 0.8431 - balanced_acc: 0.8440 - val_loss: 0.7601 - val_accuracy: 0.7047 - val_balanced_acc: 0.4057 - lr: 5.0000e-04\n",
            "Epoch 66/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.4511 - accuracy: 0.8474 - balanced_acc: 0.8468\n",
            "Epoch 66: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4534 - accuracy: 0.8470 - balanced_acc: 0.8465 - val_loss: 0.7813 - val_accuracy: 0.6995 - val_balanced_acc: 0.4087 - lr: 5.0000e-04\n",
            "Epoch 67/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.8454 - balanced_acc: 0.8443\n",
            "Epoch 67: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4553 - accuracy: 0.8454 - balanced_acc: 0.8443 - val_loss: 0.7582 - val_accuracy: 0.7202 - val_balanced_acc: 0.4165 - lr: 5.0000e-04\n",
            "Epoch 68/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.4504 - accuracy: 0.8479 - balanced_acc: 0.8477\n",
            "Epoch 68: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4507 - accuracy: 0.8471 - balanced_acc: 0.8467 - val_loss: 0.7808 - val_accuracy: 0.7098 - val_balanced_acc: 0.4183 - lr: 5.0000e-04\n",
            "Epoch 69/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.4514 - accuracy: 0.8500 - balanced_acc: 0.8494\n",
            "Epoch 69: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.8505 - balanced_acc: 0.8504 - val_loss: 0.7811 - val_accuracy: 0.7047 - val_balanced_acc: 0.4138 - lr: 5.0000e-04\n",
            "Epoch 70/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.8452 - balanced_acc: 0.8433\n",
            "Epoch 70: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4531 - accuracy: 0.8452 - balanced_acc: 0.8433 - val_loss: 0.7930 - val_accuracy: 0.6943 - val_balanced_acc: 0.4121 - lr: 5.0000e-04\n",
            "Epoch 71/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.4392 - accuracy: 0.8528 - balanced_acc: 0.8542\n",
            "Epoch 71: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4374 - accuracy: 0.8539 - balanced_acc: 0.8554 - val_loss: 0.7746 - val_accuracy: 0.7098 - val_balanced_acc: 0.4167 - lr: 5.0000e-04\n",
            "Epoch 72/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.8578 - balanced_acc: 0.8587\n",
            "Epoch 72: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4354 - accuracy: 0.8578 - balanced_acc: 0.8587 - val_loss: 0.7708 - val_accuracy: 0.6891 - val_balanced_acc: 0.3995 - lr: 5.0000e-04\n",
            "Epoch 73/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.4426 - accuracy: 0.8521 - balanced_acc: 0.8531\n",
            "Epoch 73: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4414 - accuracy: 0.8520 - balanced_acc: 0.8533 - val_loss: 0.7723 - val_accuracy: 0.6995 - val_balanced_acc: 0.4087 - lr: 5.0000e-04\n",
            "Epoch 74/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.4344 - accuracy: 0.8568 - balanced_acc: 0.8579\n",
            "Epoch 74: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4339 - accuracy: 0.8571 - balanced_acc: 0.8581 - val_loss: 0.7721 - val_accuracy: 0.7150 - val_balanced_acc: 0.4218 - lr: 5.0000e-04\n",
            "Epoch 75/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.4364 - accuracy: 0.8526 - balanced_acc: 0.8536\n",
            "Epoch 75: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.8534 - balanced_acc: 0.8542 - val_loss: 0.7820 - val_accuracy: 0.6943 - val_balanced_acc: 0.4079 - lr: 5.0000e-04\n",
            "Epoch 76/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.4227 - accuracy: 0.8603 - balanced_acc: 0.8604\n",
            "Epoch 76: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4230 - accuracy: 0.8598 - balanced_acc: 0.8599 - val_loss: 0.7609 - val_accuracy: 0.7098 - val_balanced_acc: 0.4203 - lr: 5.0000e-04\n",
            "Epoch 77/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.8561 - balanced_acc: 0.8553\n",
            "Epoch 77: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4250 - accuracy: 0.8561 - balanced_acc: 0.8553 - val_loss: 0.7803 - val_accuracy: 0.6943 - val_balanced_acc: 0.4121 - lr: 5.0000e-04\n",
            "Epoch 78/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.4216 - accuracy: 0.8629 - balanced_acc: 0.8637\n",
            "Epoch 78: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4217 - accuracy: 0.8628 - balanced_acc: 0.8633 - val_loss: 0.7629 - val_accuracy: 0.7150 - val_balanced_acc: 0.4156 - lr: 5.0000e-04\n",
            "Epoch 79/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.4214 - accuracy: 0.8592 - balanced_acc: 0.8613\n",
            "Epoch 79: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4204 - accuracy: 0.8594 - balanced_acc: 0.8609 - val_loss: 0.7599 - val_accuracy: 0.7098 - val_balanced_acc: 0.4146 - lr: 5.0000e-04\n",
            "Epoch 80/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.4145 - accuracy: 0.8630 - balanced_acc: 0.8625\n",
            "Epoch 80: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4136 - accuracy: 0.8632 - balanced_acc: 0.8626 - val_loss: 0.7627 - val_accuracy: 0.7098 - val_balanced_acc: 0.4210 - lr: 5.0000e-04\n",
            "Epoch 81/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.4077 - accuracy: 0.8640 - balanced_acc: 0.8638\n",
            "Epoch 81: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4077 - accuracy: 0.8637 - balanced_acc: 0.8635 - val_loss: 0.7575 - val_accuracy: 0.7047 - val_balanced_acc: 0.4158 - lr: 5.0000e-04\n",
            "Epoch 82/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.4150 - accuracy: 0.8604 - balanced_acc: 0.8600\n",
            "Epoch 82: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4150 - accuracy: 0.8598 - balanced_acc: 0.8593 - val_loss: 0.7860 - val_accuracy: 0.6943 - val_balanced_acc: 0.4121 - lr: 5.0000e-04\n",
            "Epoch 83/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.4061 - accuracy: 0.8635 - balanced_acc: 0.8661\n",
            "Epoch 83: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4075 - accuracy: 0.8633 - balanced_acc: 0.8653 - val_loss: 0.7471 - val_accuracy: 0.7254 - val_balanced_acc: 0.4193 - lr: 5.0000e-04\n",
            "Epoch 84/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.4051 - accuracy: 0.8677 - balanced_acc: 0.8675\n",
            "Epoch 84: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4051 - accuracy: 0.8678 - balanced_acc: 0.8673 - val_loss: 0.7605 - val_accuracy: 0.7202 - val_balanced_acc: 0.4153 - lr: 5.0000e-04\n",
            "Epoch 85/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.3994 - accuracy: 0.8672 - balanced_acc: 0.8654\n",
            "Epoch 85: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4007 - accuracy: 0.8663 - balanced_acc: 0.8642 - val_loss: 0.7652 - val_accuracy: 0.7047 - val_balanced_acc: 0.4158 - lr: 5.0000e-04\n",
            "Epoch 86/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.4025 - accuracy: 0.8660 - balanced_acc: 0.8639\n",
            "Epoch 86: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4016 - accuracy: 0.8660 - balanced_acc: 0.8640 - val_loss: 0.7675 - val_accuracy: 0.7098 - val_balanced_acc: 0.4210 - lr: 5.0000e-04\n",
            "Epoch 87/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.4010 - accuracy: 0.8679 - balanced_acc: 0.8684\n",
            "Epoch 87: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4009 - accuracy: 0.8679 - balanced_acc: 0.8683 - val_loss: 0.7740 - val_accuracy: 0.7047 - val_balanced_acc: 0.4201 - lr: 5.0000e-04\n",
            "Epoch 88/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.3888 - accuracy: 0.8725 - balanced_acc: 0.8721\n",
            "Epoch 88: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3901 - accuracy: 0.8722 - balanced_acc: 0.8716 - val_loss: 0.7791 - val_accuracy: 0.6943 - val_balanced_acc: 0.4121 - lr: 5.0000e-04\n",
            "Epoch 89/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.4009 - accuracy: 0.8653 - balanced_acc: 0.8649\n",
            "Epoch 89: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4011 - accuracy: 0.8645 - balanced_acc: 0.8643 - val_loss: 0.7677 - val_accuracy: 0.7098 - val_balanced_acc: 0.4190 - lr: 5.0000e-04\n",
            "Epoch 90/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.3885 - accuracy: 0.8740 - balanced_acc: 0.8757\n",
            "Epoch 90: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3878 - accuracy: 0.8737 - balanced_acc: 0.8747 - val_loss: 0.7573 - val_accuracy: 0.7254 - val_balanced_acc: 0.4243 - lr: 5.0000e-04\n",
            "Epoch 91/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.3877 - accuracy: 0.8731 - balanced_acc: 0.8752\n",
            "Epoch 91: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3881 - accuracy: 0.8732 - balanced_acc: 0.8751 - val_loss: 0.7670 - val_accuracy: 0.7098 - val_balanced_acc: 0.4279 - lr: 5.0000e-04\n",
            "Epoch 92/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.3825 - accuracy: 0.8751 - balanced_acc: 0.8740\n",
            "Epoch 92: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3825 - accuracy: 0.8751 - balanced_acc: 0.8740 - val_loss: 0.7834 - val_accuracy: 0.7047 - val_balanced_acc: 0.4280 - lr: 5.0000e-04\n",
            "Epoch 93/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.3874 - accuracy: 0.8691 - balanced_acc: 0.8680\n",
            "Epoch 93: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3874 - accuracy: 0.8691 - balanced_acc: 0.8680 - val_loss: 0.7519 - val_accuracy: 0.7202 - val_balanced_acc: 0.4290 - lr: 5.0000e-04\n",
            "Epoch 94/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.3813 - accuracy: 0.8750 - balanced_acc: 0.8750\n",
            "Epoch 94: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3801 - accuracy: 0.8756 - balanced_acc: 0.8756 - val_loss: 0.7439 - val_accuracy: 0.7202 - val_balanced_acc: 0.4174 - lr: 5.0000e-04\n",
            "Epoch 95/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.3795 - accuracy: 0.8754 - balanced_acc: 0.8751\n",
            "Epoch 95: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3781 - accuracy: 0.8755 - balanced_acc: 0.8755 - val_loss: 0.7478 - val_accuracy: 0.7098 - val_balanced_acc: 0.4492 - lr: 5.0000e-04\n",
            "Epoch 96/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.8766 - balanced_acc: 0.8746\n",
            "Epoch 96: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3740 - accuracy: 0.8765 - balanced_acc: 0.8746 - val_loss: 0.7683 - val_accuracy: 0.6943 - val_balanced_acc: 0.4121 - lr: 5.0000e-04\n",
            "Epoch 97/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.3770 - accuracy: 0.8779 - balanced_acc: 0.8798\n",
            "Epoch 97: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3769 - accuracy: 0.8781 - balanced_acc: 0.8797 - val_loss: 0.7473 - val_accuracy: 0.7254 - val_balanced_acc: 0.4225 - lr: 5.0000e-04\n",
            "Epoch 98/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.8749 - balanced_acc: 0.8758\n",
            "Epoch 98: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3768 - accuracy: 0.8749 - balanced_acc: 0.8758 - val_loss: 0.7456 - val_accuracy: 0.7306 - val_balanced_acc: 0.4315 - lr: 5.0000e-04\n",
            "Epoch 99/300\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3689 - accuracy: 0.8767 - balanced_acc: 0.8773\n",
            "Epoch 99: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3678 - accuracy: 0.8773 - balanced_acc: 0.8776 - val_loss: 0.7836 - val_accuracy: 0.6943 - val_balanced_acc: 0.4475 - lr: 5.0000e-04\n",
            "Epoch 100/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3658 - accuracy: 0.8800 - balanced_acc: 0.8816\n",
            "Epoch 100: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3664 - accuracy: 0.8798 - balanced_acc: 0.8813 - val_loss: 0.7667 - val_accuracy: 0.6943 - val_balanced_acc: 0.4184 - lr: 5.0000e-04\n",
            "Epoch 101/300\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3685 - accuracy: 0.8811 - balanced_acc: 0.8821\n",
            "Epoch 101: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3678 - accuracy: 0.8813 - balanced_acc: 0.8822 - val_loss: 0.7428 - val_accuracy: 0.7306 - val_balanced_acc: 0.4287 - lr: 5.0000e-04\n",
            "Epoch 102/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.3615 - accuracy: 0.8832 - balanced_acc: 0.8833\n",
            "Epoch 102: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.8835 - balanced_acc: 0.8839 - val_loss: 0.7359 - val_accuracy: 0.7150 - val_balanced_acc: 0.4470 - lr: 5.0000e-04\n",
            "Epoch 103/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3613 - accuracy: 0.8807 - balanced_acc: 0.8797\n",
            "Epoch 103: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3620 - accuracy: 0.8804 - balanced_acc: 0.8797 - val_loss: 0.7622 - val_accuracy: 0.7098 - val_balanced_acc: 0.4540 - lr: 5.0000e-04\n",
            "Epoch 104/300\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.8832 - balanced_acc: 0.8819\n",
            "Epoch 104: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3562 - accuracy: 0.8840 - balanced_acc: 0.8826 - val_loss: 0.7491 - val_accuracy: 0.7202 - val_balanced_acc: 0.4227 - lr: 5.0000e-04\n",
            "Epoch 105/300\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3637 - accuracy: 0.8768 - balanced_acc: 0.8766\n",
            "Epoch 105: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3629 - accuracy: 0.8775 - balanced_acc: 0.8774 - val_loss: 0.7297 - val_accuracy: 0.7409 - val_balanced_acc: 0.4563 - lr: 5.0000e-04\n",
            "Epoch 106/300\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3518 - accuracy: 0.8851 - balanced_acc: 0.8860\n",
            "Epoch 106: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3536 - accuracy: 0.8839 - balanced_acc: 0.8851 - val_loss: 0.7476 - val_accuracy: 0.7047 - val_balanced_acc: 0.4420 - lr: 5.0000e-04\n",
            "Epoch 107/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8875 - balanced_acc: 0.8856\n",
            "Epoch 107: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3487 - accuracy: 0.8876 - balanced_acc: 0.8856 - val_loss: 0.7608 - val_accuracy: 0.7098 - val_balanced_acc: 0.4210 - lr: 5.0000e-04\n",
            "Epoch 108/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.3409 - accuracy: 0.8918 - balanced_acc: 0.8920\n",
            "Epoch 108: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3414 - accuracy: 0.8915 - balanced_acc: 0.8916 - val_loss: 0.7653 - val_accuracy: 0.6995 - val_balanced_acc: 0.4193 - lr: 5.0000e-04\n",
            "Epoch 109/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.3554 - accuracy: 0.8853 - balanced_acc: 0.8861\n",
            "Epoch 109: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3553 - accuracy: 0.8854 - balanced_acc: 0.8862 - val_loss: 0.7508 - val_accuracy: 0.7202 - val_balanced_acc: 0.4554 - lr: 5.0000e-04\n",
            "Epoch 110/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3392 - accuracy: 0.8867 - balanced_acc: 0.8875\n",
            "Epoch 110: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3393 - accuracy: 0.8869 - balanced_acc: 0.8877 - val_loss: 0.7371 - val_accuracy: 0.7306 - val_balanced_acc: 0.4609 - lr: 5.0000e-04\n",
            "Epoch 111/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.3452 - accuracy: 0.8879 - balanced_acc: 0.8874\n",
            "Epoch 111: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3456 - accuracy: 0.8875 - balanced_acc: 0.8869 - val_loss: 0.7291 - val_accuracy: 0.7306 - val_balanced_acc: 0.4607 - lr: 5.0000e-04\n",
            "Epoch 112/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.3426 - accuracy: 0.8889 - balanced_acc: 0.8889\n",
            "Epoch 112: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.8888 - balanced_acc: 0.8889 - val_loss: 0.7364 - val_accuracy: 0.7306 - val_balanced_acc: 0.4245 - lr: 5.0000e-04\n",
            "Epoch 113/300\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3451 - accuracy: 0.8877 - balanced_acc: 0.8884\n",
            "Epoch 113: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.8878 - balanced_acc: 0.8885 - val_loss: 0.7354 - val_accuracy: 0.7306 - val_balanced_acc: 0.4287 - lr: 5.0000e-04\n",
            "Epoch 114/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.3339 - accuracy: 0.8909 - balanced_acc: 0.8908\n",
            "Epoch 114: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3335 - accuracy: 0.8915 - balanced_acc: 0.8911 - val_loss: 0.7479 - val_accuracy: 0.7254 - val_balanced_acc: 0.4236 - lr: 5.0000e-04\n",
            "Epoch 115/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.3324 - accuracy: 0.8928 - balanced_acc: 0.8922\n",
            "Epoch 115: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.8929 - balanced_acc: 0.8923 - val_loss: 0.7546 - val_accuracy: 0.7150 - val_balanced_acc: 0.4581 - lr: 5.0000e-04\n",
            "Epoch 116/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.8934 - balanced_acc: 0.8925\n",
            "Epoch 116: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8935 - balanced_acc: 0.8926 - val_loss: 0.7457 - val_accuracy: 0.7098 - val_balanced_acc: 0.4461 - lr: 5.0000e-04\n",
            "Epoch 117/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.3326 - accuracy: 0.8929 - balanced_acc: 0.8930\n",
            "Epoch 117: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8927 - balanced_acc: 0.8922 - val_loss: 0.7469 - val_accuracy: 0.7306 - val_balanced_acc: 0.4314 - lr: 5.0000e-04\n",
            "Epoch 118/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.3367 - accuracy: 0.8912 - balanced_acc: 0.8911\n",
            "Epoch 118: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.8909 - balanced_acc: 0.8901 - val_loss: 0.7438 - val_accuracy: 0.7358 - val_balanced_acc: 0.4374 - lr: 5.0000e-04\n",
            "Epoch 119/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.8939 - balanced_acc: 0.8944\n",
            "Epoch 119: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8942 - balanced_acc: 0.8948 - val_loss: 0.7495 - val_accuracy: 0.7150 - val_balanced_acc: 0.4551 - lr: 5.0000e-04\n",
            "Epoch 120/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.3174 - accuracy: 0.8992 - balanced_acc: 0.8996\n",
            "Epoch 120: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3177 - accuracy: 0.8989 - balanced_acc: 0.8992 - val_loss: 0.7410 - val_accuracy: 0.7202 - val_balanced_acc: 0.4270 - lr: 5.0000e-04\n",
            "Epoch 121/300\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3355 - accuracy: 0.8914 - balanced_acc: 0.8913\n",
            "Epoch 121: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8917 - balanced_acc: 0.8916 - val_loss: 0.7351 - val_accuracy: 0.7358 - val_balanced_acc: 0.4618 - lr: 5.0000e-04\n",
            "Epoch 122/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.3171 - accuracy: 0.8999 - balanced_acc: 0.8987\n",
            "Epoch 122: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.9007 - balanced_acc: 0.8994 - val_loss: 0.7560 - val_accuracy: 0.7098 - val_balanced_acc: 0.4540 - lr: 5.0000e-04\n",
            "Epoch 123/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.3227 - accuracy: 0.8954 - balanced_acc: 0.8947\n",
            "Epoch 123: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3220 - accuracy: 0.8957 - balanced_acc: 0.8949 - val_loss: 0.7411 - val_accuracy: 0.7254 - val_balanced_acc: 0.4278 - lr: 5.0000e-04\n",
            "Epoch 124/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.3211 - accuracy: 0.8924 - balanced_acc: 0.8909\n",
            "Epoch 124: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.8925 - balanced_acc: 0.8912 - val_loss: 0.7358 - val_accuracy: 0.7358 - val_balanced_acc: 0.4324 - lr: 5.0000e-04\n",
            "Epoch 125/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.3195 - accuracy: 0.8999 - balanced_acc: 0.9000\n",
            "Epoch 125: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3198 - accuracy: 0.8995 - balanced_acc: 0.8995 - val_loss: 0.7240 - val_accuracy: 0.7358 - val_balanced_acc: 0.4585 - lr: 5.0000e-04\n",
            "Epoch 126/300\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3160 - accuracy: 0.8974 - balanced_acc: 0.8996\n",
            "Epoch 126: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.8978 - balanced_acc: 0.9000 - val_loss: 0.7415 - val_accuracy: 0.7202 - val_balanced_acc: 0.4557 - lr: 5.0000e-04\n",
            "Epoch 127/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.3132 - accuracy: 0.9006 - balanced_acc: 0.8989\n",
            "Epoch 127: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3129 - accuracy: 0.9012 - balanced_acc: 0.8999 - val_loss: 0.7534 - val_accuracy: 0.7306 - val_balanced_acc: 0.4658 - lr: 5.0000e-04\n",
            "Epoch 128/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.3106 - accuracy: 0.9013 - balanced_acc: 0.8995\n",
            "Epoch 128: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3103 - accuracy: 0.9014 - balanced_acc: 0.8995 - val_loss: 0.7294 - val_accuracy: 0.7254 - val_balanced_acc: 0.4278 - lr: 5.0000e-04\n",
            "Epoch 129/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.3175 - accuracy: 0.8983 - balanced_acc: 0.8994\n",
            "Epoch 129: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3185 - accuracy: 0.8975 - balanced_acc: 0.8982 - val_loss: 0.7255 - val_accuracy: 0.7306 - val_balanced_acc: 0.4525 - lr: 5.0000e-04\n",
            "Epoch 130/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.3081 - accuracy: 0.8996 - balanced_acc: 0.8988\n",
            "Epoch 130: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3087 - accuracy: 0.8994 - balanced_acc: 0.8986 - val_loss: 0.7233 - val_accuracy: 0.7461 - val_balanced_acc: 0.4341 - lr: 5.0000e-04\n",
            "Epoch 131/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.3090 - accuracy: 0.9009 - balanced_acc: 0.9001\n",
            "Epoch 131: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.9017 - balanced_acc: 0.9009 - val_loss: 0.7350 - val_accuracy: 0.7409 - val_balanced_acc: 0.4662 - lr: 5.0000e-04\n",
            "Epoch 132/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.3073 - accuracy: 0.9030 - balanced_acc: 0.9026\n",
            "Epoch 132: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3062 - accuracy: 0.9032 - balanced_acc: 0.9028 - val_loss: 0.7290 - val_accuracy: 0.7358 - val_balanced_acc: 0.4280 - lr: 5.0000e-04\n",
            "Epoch 133/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.3046 - accuracy: 0.9001 - balanced_acc: 0.8994\n",
            "Epoch 133: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3040 - accuracy: 0.9004 - balanced_acc: 0.8997 - val_loss: 0.7437 - val_accuracy: 0.7254 - val_balanced_acc: 0.4517 - lr: 5.0000e-04\n",
            "Epoch 134/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.3073 - accuracy: 0.9014 - balanced_acc: 0.9009\n",
            "Epoch 134: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3087 - accuracy: 0.9006 - balanced_acc: 0.9001 - val_loss: 0.7201 - val_accuracy: 0.7409 - val_balanced_acc: 0.4290 - lr: 5.0000e-04\n",
            "Epoch 135/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.3017 - accuracy: 0.9056 - balanced_acc: 0.9071\n",
            "Epoch 135: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3020 - accuracy: 0.9059 - balanced_acc: 0.9072 - val_loss: 0.7315 - val_accuracy: 0.7409 - val_balanced_acc: 0.4624 - lr: 5.0000e-04\n",
            "Epoch 136/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.2930 - accuracy: 0.9101 - balanced_acc: 0.9087\n",
            "Epoch 136: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2927 - accuracy: 0.9100 - balanced_acc: 0.9086 - val_loss: 0.7517 - val_accuracy: 0.7202 - val_balanced_acc: 0.4557 - lr: 5.0000e-04\n",
            "Epoch 137/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2977 - accuracy: 0.9062 - balanced_acc: 0.9070\n",
            "Epoch 137: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2977 - accuracy: 0.9059 - balanced_acc: 0.9066 - val_loss: 0.7330 - val_accuracy: 0.7358 - val_balanced_acc: 0.4280 - lr: 5.0000e-04\n",
            "Epoch 138/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.3033 - accuracy: 0.9036 - balanced_acc: 0.9038\n",
            "Epoch 138: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3022 - accuracy: 0.9042 - balanced_acc: 0.9043 - val_loss: 0.7356 - val_accuracy: 0.7409 - val_balanced_acc: 0.4657 - lr: 5.0000e-04\n",
            "Epoch 139/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2931 - accuracy: 0.9078 - balanced_acc: 0.9092\n",
            "Epoch 139: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2919 - accuracy: 0.9079 - balanced_acc: 0.9090 - val_loss: 0.7299 - val_accuracy: 0.7254 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 140/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.2970 - accuracy: 0.9075 - balanced_acc: 0.9046\n",
            "Epoch 140: val_balanced_acc did not improve from 0.47210\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2973 - accuracy: 0.9075 - balanced_acc: 0.9049 - val_loss: 0.7249 - val_accuracy: 0.7254 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 141/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2958 - accuracy: 0.9057 - balanced_acc: 0.9067\n",
            "Epoch 141: val_balanced_acc improved from 0.47210 to 0.47390, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2966 - accuracy: 0.9057 - balanced_acc: 0.9069 - val_loss: 0.7175 - val_accuracy: 0.7565 - val_balanced_acc: 0.4739 - lr: 5.0000e-04\n",
            "Epoch 142/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2940 - accuracy: 0.9062 - balanced_acc: 0.9086\n",
            "Epoch 142: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2938 - accuracy: 0.9064 - balanced_acc: 0.9091 - val_loss: 0.7250 - val_accuracy: 0.7306 - val_balanced_acc: 0.4525 - lr: 5.0000e-04\n",
            "Epoch 143/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2902 - accuracy: 0.9087 - balanced_acc: 0.9056\n",
            "Epoch 143: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2914 - accuracy: 0.9079 - balanced_acc: 0.9051 - val_loss: 0.7335 - val_accuracy: 0.7306 - val_balanced_acc: 0.4288 - lr: 5.0000e-04\n",
            "Epoch 144/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2846 - accuracy: 0.9067 - balanced_acc: 0.9063\n",
            "Epoch 144: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2839 - accuracy: 0.9064 - balanced_acc: 0.9061 - val_loss: 0.7453 - val_accuracy: 0.7202 - val_balanced_acc: 0.4557 - lr: 5.0000e-04\n",
            "Epoch 145/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2888 - accuracy: 0.9071 - balanced_acc: 0.9077\n",
            "Epoch 145: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2892 - accuracy: 0.9070 - balanced_acc: 0.9080 - val_loss: 0.7161 - val_accuracy: 0.7409 - val_balanced_acc: 0.4332 - lr: 5.0000e-04\n",
            "Epoch 146/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.2848 - accuracy: 0.9089 - balanced_acc: 0.9074\n",
            "Epoch 146: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2848 - accuracy: 0.9089 - balanced_acc: 0.9075 - val_loss: 0.7596 - val_accuracy: 0.7254 - val_balanced_acc: 0.4616 - lr: 5.0000e-04\n",
            "Epoch 147/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.2854 - accuracy: 0.9124 - balanced_acc: 0.9123\n",
            "Epoch 147: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.9114 - balanced_acc: 0.9113 - val_loss: 0.7158 - val_accuracy: 0.7358 - val_balanced_acc: 0.4612 - lr: 5.0000e-04\n",
            "Epoch 148/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2810 - accuracy: 0.9124 - balanced_acc: 0.9110\n",
            "Epoch 148: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2824 - accuracy: 0.9115 - balanced_acc: 0.9104 - val_loss: 0.7327 - val_accuracy: 0.7358 - val_balanced_acc: 0.4646 - lr: 5.0000e-04\n",
            "Epoch 149/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2827 - accuracy: 0.9101 - balanced_acc: 0.9120\n",
            "Epoch 149: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.9106 - balanced_acc: 0.9121 - val_loss: 0.7081 - val_accuracy: 0.7513 - val_balanced_acc: 0.4392 - lr: 5.0000e-04\n",
            "Epoch 150/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2835 - accuracy: 0.9095 - balanced_acc: 0.9099\n",
            "Epoch 150: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2832 - accuracy: 0.9094 - balanced_acc: 0.9097 - val_loss: 0.7179 - val_accuracy: 0.7358 - val_balanced_acc: 0.4633 - lr: 5.0000e-04\n",
            "Epoch 151/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.2756 - accuracy: 0.9142 - balanced_acc: 0.9130\n",
            "Epoch 151: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.9137 - balanced_acc: 0.9131 - val_loss: 0.7265 - val_accuracy: 0.7409 - val_balanced_acc: 0.4375 - lr: 5.0000e-04\n",
            "Epoch 152/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.9117 - balanced_acc: 0.9089\n",
            "Epoch 152: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2763 - accuracy: 0.9119 - balanced_acc: 0.9092 - val_loss: 0.7176 - val_accuracy: 0.7409 - val_balanced_acc: 0.4593 - lr: 5.0000e-04\n",
            "Epoch 153/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2707 - accuracy: 0.9150 - balanced_acc: 0.9161\n",
            "Epoch 153: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.9152 - balanced_acc: 0.9163 - val_loss: 0.7218 - val_accuracy: 0.7513 - val_balanced_acc: 0.4697 - lr: 5.0000e-04\n",
            "Epoch 154/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2793 - accuracy: 0.9106 - balanced_acc: 0.9109\n",
            "Epoch 154: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.9109 - balanced_acc: 0.9108 - val_loss: 0.7424 - val_accuracy: 0.7254 - val_balanced_acc: 0.4571 - lr: 5.0000e-04\n",
            "Epoch 155/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2729 - accuracy: 0.9161 - balanced_acc: 0.9162\n",
            "Epoch 155: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.9160 - balanced_acc: 0.9161 - val_loss: 0.7156 - val_accuracy: 0.7461 - val_balanced_acc: 0.4357 - lr: 5.0000e-04\n",
            "Epoch 156/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.9164 - balanced_acc: 0.9166\n",
            "Epoch 156: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.9164 - balanced_acc: 0.9165 - val_loss: 0.6931 - val_accuracy: 0.7617 - val_balanced_acc: 0.4382 - lr: 5.0000e-04\n",
            "Epoch 157/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.9127 - balanced_acc: 0.9108\n",
            "Epoch 157: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.9133 - balanced_acc: 0.9115 - val_loss: 0.7326 - val_accuracy: 0.7409 - val_balanced_acc: 0.4374 - lr: 5.0000e-04\n",
            "Epoch 158/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.2691 - accuracy: 0.9160 - balanced_acc: 0.9168\n",
            "Epoch 158: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2690 - accuracy: 0.9164 - balanced_acc: 0.9173 - val_loss: 0.7316 - val_accuracy: 0.7358 - val_balanced_acc: 0.4633 - lr: 5.0000e-04\n",
            "Epoch 159/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.2714 - accuracy: 0.9167 - balanced_acc: 0.9168\n",
            "Epoch 159: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.9164 - balanced_acc: 0.9163 - val_loss: 0.7162 - val_accuracy: 0.7513 - val_balanced_acc: 0.4688 - lr: 5.0000e-04\n",
            "Epoch 160/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9163 - balanced_acc: 0.9177\n",
            "Epoch 160: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.9161 - balanced_acc: 0.9175 - val_loss: 0.7260 - val_accuracy: 0.7409 - val_balanced_acc: 0.4347 - lr: 5.0000e-04\n",
            "Epoch 161/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.9173 - balanced_acc: 0.9168\n",
            "Epoch 161: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2653 - accuracy: 0.9179 - balanced_acc: 0.9172 - val_loss: 0.7334 - val_accuracy: 0.7358 - val_balanced_acc: 0.4697 - lr: 5.0000e-04\n",
            "Epoch 162/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2653 - accuracy: 0.9164 - balanced_acc: 0.9148\n",
            "Epoch 162: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.9167 - balanced_acc: 0.9154 - val_loss: 0.7206 - val_accuracy: 0.7358 - val_balanced_acc: 0.4585 - lr: 5.0000e-04\n",
            "Epoch 163/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2625 - accuracy: 0.9161 - balanced_acc: 0.9167\n",
            "Epoch 163: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.9150 - balanced_acc: 0.9151 - val_loss: 0.7192 - val_accuracy: 0.7461 - val_balanced_acc: 0.4680 - lr: 5.0000e-04\n",
            "Epoch 164/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2643 - accuracy: 0.9173 - balanced_acc: 0.9185\n",
            "Epoch 164: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2657 - accuracy: 0.9171 - balanced_acc: 0.9185 - val_loss: 0.7304 - val_accuracy: 0.7409 - val_balanced_acc: 0.4374 - lr: 5.0000e-04\n",
            "Epoch 165/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.2585 - accuracy: 0.9204 - balanced_acc: 0.9207\n",
            "Epoch 165: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2586 - accuracy: 0.9204 - balanced_acc: 0.9205 - val_loss: 0.7449 - val_accuracy: 0.7202 - val_balanced_acc: 0.4512 - lr: 5.0000e-04\n",
            "Epoch 166/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.2576 - accuracy: 0.9213 - balanced_acc: 0.9217\n",
            "Epoch 166: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2589 - accuracy: 0.9204 - balanced_acc: 0.9207 - val_loss: 0.7204 - val_accuracy: 0.7461 - val_balanced_acc: 0.4356 - lr: 5.0000e-04\n",
            "Epoch 167/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.9211 - balanced_acc: 0.9223\n",
            "Epoch 167: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2558 - accuracy: 0.9215 - balanced_acc: 0.9227 - val_loss: 0.7117 - val_accuracy: 0.7461 - val_balanced_acc: 0.4629 - lr: 5.0000e-04\n",
            "Epoch 168/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2567 - accuracy: 0.9203 - balanced_acc: 0.9202\n",
            "Epoch 168: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2572 - accuracy: 0.9201 - balanced_acc: 0.9202 - val_loss: 0.7230 - val_accuracy: 0.7461 - val_balanced_acc: 0.4640 - lr: 5.0000e-04\n",
            "Epoch 169/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.2520 - accuracy: 0.9233 - balanced_acc: 0.9238\n",
            "Epoch 169: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2518 - accuracy: 0.9232 - balanced_acc: 0.9238 - val_loss: 0.7150 - val_accuracy: 0.7461 - val_balanced_acc: 0.4314 - lr: 5.0000e-04\n",
            "Epoch 170/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.2533 - accuracy: 0.9205 - balanced_acc: 0.9220\n",
            "Epoch 170: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2529 - accuracy: 0.9201 - balanced_acc: 0.9217 - val_loss: 0.7299 - val_accuracy: 0.7461 - val_balanced_acc: 0.4665 - lr: 5.0000e-04\n",
            "Epoch 171/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2482 - accuracy: 0.9236 - balanced_acc: 0.9238\n",
            "Epoch 171: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2491 - accuracy: 0.9235 - balanced_acc: 0.9237 - val_loss: 0.7072 - val_accuracy: 0.7409 - val_balanced_acc: 0.4620 - lr: 5.0000e-04\n",
            "Epoch 172/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2520 - accuracy: 0.9218 - balanced_acc: 0.9223\n",
            "Epoch 172: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2524 - accuracy: 0.9220 - balanced_acc: 0.9221 - val_loss: 0.7216 - val_accuracy: 0.7254 - val_balanced_acc: 0.4592 - lr: 5.0000e-04\n",
            "Epoch 173/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2485 - accuracy: 0.9263 - balanced_acc: 0.9258\n",
            "Epoch 173: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2482 - accuracy: 0.9264 - balanced_acc: 0.9260 - val_loss: 0.7144 - val_accuracy: 0.7565 - val_balanced_acc: 0.4736 - lr: 5.0000e-04\n",
            "Epoch 174/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.2500 - accuracy: 0.9228 - balanced_acc: 0.9217\n",
            "Epoch 174: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2511 - accuracy: 0.9229 - balanced_acc: 0.9221 - val_loss: 0.7048 - val_accuracy: 0.7565 - val_balanced_acc: 0.4684 - lr: 5.0000e-04\n",
            "Epoch 175/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.2481 - accuracy: 0.9235 - balanced_acc: 0.9230\n",
            "Epoch 175: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2476 - accuracy: 0.9234 - balanced_acc: 0.9228 - val_loss: 0.7148 - val_accuracy: 0.7513 - val_balanced_acc: 0.4386 - lr: 5.0000e-04\n",
            "Epoch 176/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2426 - accuracy: 0.9251 - balanced_acc: 0.9262\n",
            "Epoch 176: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2410 - accuracy: 0.9260 - balanced_acc: 0.9270 - val_loss: 0.7366 - val_accuracy: 0.7409 - val_balanced_acc: 0.4708 - lr: 5.0000e-04\n",
            "Epoch 177/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2521 - accuracy: 0.9223 - balanced_acc: 0.9221\n",
            "Epoch 177: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2523 - accuracy: 0.9222 - balanced_acc: 0.9220 - val_loss: 0.7250 - val_accuracy: 0.7306 - val_balanced_acc: 0.4254 - lr: 5.0000e-04\n",
            "Epoch 178/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2461 - accuracy: 0.9218 - balanced_acc: 0.9206\n",
            "Epoch 178: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2452 - accuracy: 0.9224 - balanced_acc: 0.9214 - val_loss: 0.7148 - val_accuracy: 0.7461 - val_balanced_acc: 0.4680 - lr: 5.0000e-04\n",
            "Epoch 179/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2411 - accuracy: 0.9247 - balanced_acc: 0.9251\n",
            "Epoch 179: val_balanced_acc did not improve from 0.47390\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2405 - accuracy: 0.9253 - balanced_acc: 0.9254 - val_loss: 0.7059 - val_accuracy: 0.7513 - val_balanced_acc: 0.4316 - lr: 5.0000e-04\n",
            "Epoch 180/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2469 - accuracy: 0.9243 - balanced_acc: 0.9246\n",
            "Epoch 180: val_balanced_acc improved from 0.47390 to 0.47440, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.2464 - accuracy: 0.9244 - balanced_acc: 0.9247 - val_loss: 0.7063 - val_accuracy: 0.7617 - val_balanced_acc: 0.4744 - lr: 5.0000e-04\n",
            "Epoch 181/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2415 - accuracy: 0.9251 - balanced_acc: 0.9260\n",
            "Epoch 181: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.9249 - balanced_acc: 0.9256 - val_loss: 0.7268 - val_accuracy: 0.7461 - val_balanced_acc: 0.4716 - lr: 5.0000e-04\n",
            "Epoch 182/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2368 - accuracy: 0.9284 - balanced_acc: 0.9288\n",
            "Epoch 182: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2374 - accuracy: 0.9281 - balanced_acc: 0.9285 - val_loss: 0.7123 - val_accuracy: 0.7513 - val_balanced_acc: 0.4344 - lr: 5.0000e-04\n",
            "Epoch 183/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2361 - accuracy: 0.9283 - balanced_acc: 0.9273\n",
            "Epoch 183: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2361 - accuracy: 0.9280 - balanced_acc: 0.9271 - val_loss: 0.7161 - val_accuracy: 0.7565 - val_balanced_acc: 0.4736 - lr: 5.0000e-04\n",
            "Epoch 184/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.2358 - accuracy: 0.9266 - balanced_acc: 0.9267\n",
            "Epoch 184: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2364 - accuracy: 0.9266 - balanced_acc: 0.9269 - val_loss: 0.7057 - val_accuracy: 0.7409 - val_balanced_acc: 0.4306 - lr: 5.0000e-04\n",
            "Epoch 185/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2338 - accuracy: 0.9302 - balanced_acc: 0.9305\n",
            "Epoch 185: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2328 - accuracy: 0.9302 - balanced_acc: 0.9306 - val_loss: 0.7023 - val_accuracy: 0.7409 - val_balanced_acc: 0.4593 - lr: 5.0000e-04\n",
            "Epoch 186/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2337 - accuracy: 0.9287 - balanced_acc: 0.9295\n",
            "Epoch 186: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2316 - accuracy: 0.9297 - balanced_acc: 0.9303 - val_loss: 0.7047 - val_accuracy: 0.7513 - val_balanced_acc: 0.4739 - lr: 5.0000e-04\n",
            "Epoch 187/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.2399 - accuracy: 0.9254 - balanced_acc: 0.9248\n",
            "Epoch 187: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2401 - accuracy: 0.9246 - balanced_acc: 0.9243 - val_loss: 0.7187 - val_accuracy: 0.7461 - val_balanced_acc: 0.4589 - lr: 5.0000e-04\n",
            "Epoch 188/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2288 - accuracy: 0.9310 - balanced_acc: 0.9292\n",
            "Epoch 188: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2295 - accuracy: 0.9305 - balanced_acc: 0.9288 - val_loss: 0.7146 - val_accuracy: 0.7461 - val_balanced_acc: 0.4680 - lr: 5.0000e-04\n",
            "Epoch 189/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.2348 - accuracy: 0.9296 - balanced_acc: 0.9309\n",
            "Epoch 189: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2346 - accuracy: 0.9299 - balanced_acc: 0.9312 - val_loss: 0.7118 - val_accuracy: 0.7461 - val_balanced_acc: 0.4616 - lr: 5.0000e-04\n",
            "Epoch 190/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2307 - accuracy: 0.9291 - balanced_acc: 0.9295\n",
            "Epoch 190: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2300 - accuracy: 0.9300 - balanced_acc: 0.9302 - val_loss: 0.7364 - val_accuracy: 0.7461 - val_balanced_acc: 0.4716 - lr: 5.0000e-04\n",
            "Epoch 191/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2294 - accuracy: 0.9314 - balanced_acc: 0.9322\n",
            "Epoch 191: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2299 - accuracy: 0.9312 - balanced_acc: 0.9317 - val_loss: 0.7050 - val_accuracy: 0.7565 - val_balanced_acc: 0.4633 - lr: 5.0000e-04\n",
            "Epoch 192/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2286 - accuracy: 0.9295 - balanced_acc: 0.9292\n",
            "Epoch 192: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2285 - accuracy: 0.9302 - balanced_acc: 0.9299 - val_loss: 0.7191 - val_accuracy: 0.7513 - val_balanced_acc: 0.4676 - lr: 5.0000e-04\n",
            "Epoch 193/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2303 - accuracy: 0.9297 - balanced_acc: 0.9291\n",
            "Epoch 193: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2308 - accuracy: 0.9292 - balanced_acc: 0.9287 - val_loss: 0.7033 - val_accuracy: 0.7565 - val_balanced_acc: 0.4606 - lr: 5.0000e-04\n",
            "Epoch 194/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2242 - accuracy: 0.9314 - balanced_acc: 0.9305\n",
            "Epoch 194: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2238 - accuracy: 0.9318 - balanced_acc: 0.9310 - val_loss: 0.7142 - val_accuracy: 0.7513 - val_balanced_acc: 0.4725 - lr: 5.0000e-04\n",
            "Epoch 195/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.2273 - accuracy: 0.9319 - balanced_acc: 0.9310\n",
            "Epoch 195: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2272 - accuracy: 0.9318 - balanced_acc: 0.9310 - val_loss: 0.7075 - val_accuracy: 0.7668 - val_balanced_acc: 0.4701 - lr: 5.0000e-04\n",
            "Epoch 196/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2261 - accuracy: 0.9305 - balanced_acc: 0.9307\n",
            "Epoch 196: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2262 - accuracy: 0.9302 - balanced_acc: 0.9303 - val_loss: 0.7168 - val_accuracy: 0.7513 - val_balanced_acc: 0.4673 - lr: 5.0000e-04\n",
            "Epoch 197/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2246 - accuracy: 0.9327 - balanced_acc: 0.9330\n",
            "Epoch 197: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2250 - accuracy: 0.9326 - balanced_acc: 0.9331 - val_loss: 0.7146 - val_accuracy: 0.7461 - val_balanced_acc: 0.4614 - lr: 5.0000e-04\n",
            "Epoch 198/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2245 - accuracy: 0.9321 - balanced_acc: 0.9323\n",
            "Epoch 198: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2236 - accuracy: 0.9327 - balanced_acc: 0.9329 - val_loss: 0.7095 - val_accuracy: 0.7565 - val_balanced_acc: 0.4736 - lr: 5.0000e-04\n",
            "Epoch 199/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2220 - accuracy: 0.9302 - balanced_acc: 0.9307\n",
            "Epoch 199: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2221 - accuracy: 0.9304 - balanced_acc: 0.9307 - val_loss: 0.7108 - val_accuracy: 0.7617 - val_balanced_acc: 0.4642 - lr: 5.0000e-04\n",
            "Epoch 200/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.9345 - balanced_acc: 0.9339\n",
            "Epoch 200: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2186 - accuracy: 0.9345 - balanced_acc: 0.9339 - val_loss: 0.6984 - val_accuracy: 0.7668 - val_balanced_acc: 0.4701 - lr: 5.0000e-04\n",
            "Epoch 201/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2205 - accuracy: 0.9339 - balanced_acc: 0.9350\n",
            "Epoch 201: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2203 - accuracy: 0.9336 - balanced_acc: 0.9348 - val_loss: 0.6932 - val_accuracy: 0.7668 - val_balanced_acc: 0.4701 - lr: 5.0000e-04\n",
            "Epoch 202/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9334 - balanced_acc: 0.9348\n",
            "Epoch 202: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2174 - accuracy: 0.9331 - balanced_acc: 0.9343 - val_loss: 0.7093 - val_accuracy: 0.7617 - val_balanced_acc: 0.4744 - lr: 5.0000e-04\n",
            "Epoch 203/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2159 - accuracy: 0.9344 - balanced_acc: 0.9341\n",
            "Epoch 203: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2173 - accuracy: 0.9338 - balanced_acc: 0.9334 - val_loss: 0.7069 - val_accuracy: 0.7513 - val_balanced_acc: 0.4625 - lr: 5.0000e-04\n",
            "Epoch 204/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2164 - accuracy: 0.9358 - balanced_acc: 0.9351\n",
            "Epoch 204: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2165 - accuracy: 0.9355 - balanced_acc: 0.9349 - val_loss: 0.7177 - val_accuracy: 0.7565 - val_balanced_acc: 0.4736 - lr: 5.0000e-04\n",
            "Epoch 205/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2166 - accuracy: 0.9345 - balanced_acc: 0.9347\n",
            "Epoch 205: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2159 - accuracy: 0.9348 - balanced_acc: 0.9346 - val_loss: 0.7291 - val_accuracy: 0.7461 - val_balanced_acc: 0.4716 - lr: 5.0000e-04\n",
            "Epoch 206/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.2148 - accuracy: 0.9361 - balanced_acc: 0.9357\n",
            "Epoch 206: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2144 - accuracy: 0.9365 - balanced_acc: 0.9360 - val_loss: 0.7106 - val_accuracy: 0.7565 - val_balanced_acc: 0.4633 - lr: 5.0000e-04\n",
            "Epoch 207/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2127 - accuracy: 0.9366 - balanced_acc: 0.9357\n",
            "Epoch 207: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2123 - accuracy: 0.9369 - balanced_acc: 0.9362 - val_loss: 0.7044 - val_accuracy: 0.7565 - val_balanced_acc: 0.4633 - lr: 5.0000e-04\n",
            "Epoch 208/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2088 - accuracy: 0.9366 - balanced_acc: 0.9378\n",
            "Epoch 208: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2095 - accuracy: 0.9366 - balanced_acc: 0.9380 - val_loss: 0.7132 - val_accuracy: 0.7617 - val_balanced_acc: 0.4693 - lr: 5.0000e-04\n",
            "Epoch 209/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.2121 - accuracy: 0.9362 - balanced_acc: 0.9367\n",
            "Epoch 209: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2134 - accuracy: 0.9356 - balanced_acc: 0.9362 - val_loss: 0.7077 - val_accuracy: 0.7565 - val_balanced_acc: 0.4606 - lr: 5.0000e-04\n",
            "Epoch 210/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2102 - accuracy: 0.9371 - balanced_acc: 0.9378\n",
            "Epoch 210: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2101 - accuracy: 0.9371 - balanced_acc: 0.9376 - val_loss: 0.7196 - val_accuracy: 0.7617 - val_balanced_acc: 0.4693 - lr: 5.0000e-04\n",
            "Epoch 211/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2138 - accuracy: 0.9351 - balanced_acc: 0.9349\n",
            "Epoch 211: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2126 - accuracy: 0.9353 - balanced_acc: 0.9351 - val_loss: 0.7102 - val_accuracy: 0.7668 - val_balanced_acc: 0.4701 - lr: 5.0000e-04\n",
            "Epoch 212/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.2064 - accuracy: 0.9387 - balanced_acc: 0.9381\n",
            "Epoch 212: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9393 - balanced_acc: 0.9386 - val_loss: 0.7103 - val_accuracy: 0.7513 - val_balanced_acc: 0.4673 - lr: 5.0000e-04\n",
            "Epoch 213/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.2087 - accuracy: 0.9377 - balanced_acc: 0.9376\n",
            "Epoch 213: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2085 - accuracy: 0.9375 - balanced_acc: 0.9374 - val_loss: 0.7311 - val_accuracy: 0.7358 - val_balanced_acc: 0.4189 - lr: 5.0000e-04\n",
            "Epoch 214/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.2076 - accuracy: 0.9357 - balanced_acc: 0.9361\n",
            "Epoch 214: val_balanced_acc did not improve from 0.47440\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9353 - balanced_acc: 0.9357 - val_loss: 0.7196 - val_accuracy: 0.7461 - val_balanced_acc: 0.4665 - lr: 5.0000e-04\n",
            "Epoch 215/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2078 - accuracy: 0.9379 - balanced_acc: 0.9383\n",
            "Epoch 215: val_balanced_acc improved from 0.47440 to 0.47523, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2079 - accuracy: 0.9376 - balanced_acc: 0.9379 - val_loss: 0.7141 - val_accuracy: 0.7668 - val_balanced_acc: 0.4752 - lr: 5.0000e-04\n",
            "Epoch 216/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2045 - accuracy: 0.9376 - balanced_acc: 0.9380\n",
            "Epoch 216: val_balanced_acc improved from 0.47523 to 0.47690, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9378 - balanced_acc: 0.9381 - val_loss: 0.6839 - val_accuracy: 0.7772 - val_balanced_acc: 0.4769 - lr: 5.0000e-04\n",
            "Epoch 217/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2058 - accuracy: 0.9405 - balanced_acc: 0.9398\n",
            "Epoch 217: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2053 - accuracy: 0.9403 - balanced_acc: 0.9397 - val_loss: 0.7276 - val_accuracy: 0.7565 - val_balanced_acc: 0.4733 - lr: 5.0000e-04\n",
            "Epoch 218/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2039 - accuracy: 0.9389 - balanced_acc: 0.9388\n",
            "Epoch 218: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2042 - accuracy: 0.9388 - balanced_acc: 0.9386 - val_loss: 0.7029 - val_accuracy: 0.7461 - val_balanced_acc: 0.4614 - lr: 5.0000e-04\n",
            "Epoch 219/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2002 - accuracy: 0.9406 - balanced_acc: 0.9400\n",
            "Epoch 219: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1999 - accuracy: 0.9409 - balanced_acc: 0.9401 - val_loss: 0.7141 - val_accuracy: 0.7565 - val_balanced_acc: 0.4684 - lr: 5.0000e-04\n",
            "Epoch 220/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.2064 - accuracy: 0.9369 - balanced_acc: 0.9363\n",
            "Epoch 220: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2062 - accuracy: 0.9371 - balanced_acc: 0.9365 - val_loss: 0.7142 - val_accuracy: 0.7409 - val_balanced_acc: 0.4629 - lr: 5.0000e-04\n",
            "Epoch 221/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2010 - accuracy: 0.9401 - balanced_acc: 0.9403\n",
            "Epoch 221: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2012 - accuracy: 0.9399 - balanced_acc: 0.9400 - val_loss: 0.7029 - val_accuracy: 0.7668 - val_balanced_acc: 0.4701 - lr: 5.0000e-04\n",
            "Epoch 222/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2031 - accuracy: 0.9391 - balanced_acc: 0.9395\n",
            "Epoch 222: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2032 - accuracy: 0.9389 - balanced_acc: 0.9391 - val_loss: 0.7269 - val_accuracy: 0.7409 - val_balanced_acc: 0.4657 - lr: 5.0000e-04\n",
            "Epoch 223/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2009 - accuracy: 0.9414 - balanced_acc: 0.9414\n",
            "Epoch 223: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2012 - accuracy: 0.9411 - balanced_acc: 0.9412 - val_loss: 0.7149 - val_accuracy: 0.7358 - val_balanced_acc: 0.4570 - lr: 5.0000e-04\n",
            "Epoch 224/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.1994 - accuracy: 0.9392 - balanced_acc: 0.9402\n",
            "Epoch 224: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1984 - accuracy: 0.9391 - balanced_acc: 0.9399 - val_loss: 0.7016 - val_accuracy: 0.7668 - val_balanced_acc: 0.4701 - lr: 5.0000e-04\n",
            "Epoch 225/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.2013 - accuracy: 0.9373 - balanced_acc: 0.9357\n",
            "Epoch 225: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2006 - accuracy: 0.9375 - balanced_acc: 0.9361 - val_loss: 0.7082 - val_accuracy: 0.7461 - val_balanced_acc: 0.4665 - lr: 5.0000e-04\n",
            "Epoch 226/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.1966 - accuracy: 0.9441 - balanced_acc: 0.9449\n",
            "Epoch 226: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1968 - accuracy: 0.9437 - balanced_acc: 0.9445 - val_loss: 0.7197 - val_accuracy: 0.7409 - val_balanced_acc: 0.4605 - lr: 5.0000e-04\n",
            "Epoch 227/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.1975 - accuracy: 0.9411 - balanced_acc: 0.9400\n",
            "Epoch 227: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9416 - balanced_acc: 0.9404 - val_loss: 0.6982 - val_accuracy: 0.7565 - val_balanced_acc: 0.4733 - lr: 5.0000e-04\n",
            "Epoch 228/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.1906 - accuracy: 0.9460 - balanced_acc: 0.9463\n",
            "Epoch 228: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1928 - accuracy: 0.9450 - balanced_acc: 0.9453 - val_loss: 0.6991 - val_accuracy: 0.7617 - val_balanced_acc: 0.4284 - lr: 5.0000e-04\n",
            "Epoch 229/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.1916 - accuracy: 0.9425 - balanced_acc: 0.9432\n",
            "Epoch 229: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1916 - accuracy: 0.9424 - balanced_acc: 0.9429 - val_loss: 0.6827 - val_accuracy: 0.7668 - val_balanced_acc: 0.4650 - lr: 5.0000e-04\n",
            "Epoch 230/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.1941 - accuracy: 0.9424 - balanced_acc: 0.9424\n",
            "Epoch 230: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1945 - accuracy: 0.9421 - balanced_acc: 0.9422 - val_loss: 0.7165 - val_accuracy: 0.7513 - val_balanced_acc: 0.4316 - lr: 5.0000e-04\n",
            "Epoch 231/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.1931 - accuracy: 0.9439 - balanced_acc: 0.9434\n",
            "Epoch 231: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1930 - accuracy: 0.9439 - balanced_acc: 0.9434 - val_loss: 0.7081 - val_accuracy: 0.7513 - val_balanced_acc: 0.4673 - lr: 5.0000e-04\n",
            "Epoch 232/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.1943 - accuracy: 0.9440 - balanced_acc: 0.9441\n",
            "Epoch 232: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1944 - accuracy: 0.9439 - balanced_acc: 0.9439 - val_loss: 0.7014 - val_accuracy: 0.7461 - val_balanced_acc: 0.4665 - lr: 5.0000e-04\n",
            "Epoch 233/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9427 - balanced_acc: 0.9427\n",
            "Epoch 233: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1911 - accuracy: 0.9428 - balanced_acc: 0.9428 - val_loss: 0.7160 - val_accuracy: 0.7565 - val_balanced_acc: 0.4733 - lr: 5.0000e-04\n",
            "Epoch 234/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.1917 - accuracy: 0.9437 - balanced_acc: 0.9453\n",
            "Epoch 234: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1919 - accuracy: 0.9435 - balanced_acc: 0.9447 - val_loss: 0.7067 - val_accuracy: 0.7461 - val_balanced_acc: 0.4665 - lr: 5.0000e-04\n",
            "Epoch 235/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.1886 - accuracy: 0.9447 - balanced_acc: 0.9430\n",
            "Epoch 235: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1893 - accuracy: 0.9447 - balanced_acc: 0.9433 - val_loss: 0.7029 - val_accuracy: 0.7565 - val_balanced_acc: 0.4684 - lr: 5.0000e-04\n",
            "Epoch 236/300\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.1883 - accuracy: 0.9453 - balanced_acc: 0.9449\n",
            "Epoch 236: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1878 - accuracy: 0.9456 - balanced_acc: 0.9452 - val_loss: 0.6971 - val_accuracy: 0.7513 - val_balanced_acc: 0.4622 - lr: 5.0000e-04\n",
            "Epoch 237/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.1900 - accuracy: 0.9435 - balanced_acc: 0.9432\n",
            "Epoch 237: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1892 - accuracy: 0.9438 - balanced_acc: 0.9436 - val_loss: 0.6999 - val_accuracy: 0.7617 - val_balanced_acc: 0.4693 - lr: 5.0000e-04\n",
            "Epoch 238/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9437 - balanced_acc: 0.9440\n",
            "Epoch 238: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1885 - accuracy: 0.9437 - balanced_acc: 0.9440 - val_loss: 0.7058 - val_accuracy: 0.7513 - val_balanced_acc: 0.4673 - lr: 5.0000e-04\n",
            "Epoch 239/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.1876 - accuracy: 0.9433 - balanced_acc: 0.9417\n",
            "Epoch 239: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1870 - accuracy: 0.9433 - balanced_acc: 0.9417 - val_loss: 0.7143 - val_accuracy: 0.7409 - val_balanced_acc: 0.4248 - lr: 5.0000e-04\n",
            "Epoch 240/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9453 - balanced_acc: 0.9443\n",
            "Epoch 240: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1881 - accuracy: 0.9453 - balanced_acc: 0.9443 - val_loss: 0.6962 - val_accuracy: 0.7720 - val_balanced_acc: 0.4761 - lr: 5.0000e-04\n",
            "Epoch 241/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 0.9470 - balanced_acc: 0.9472\n",
            "Epoch 241: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1818 - accuracy: 0.9470 - balanced_acc: 0.9472 - val_loss: 0.6892 - val_accuracy: 0.7824 - val_balanced_acc: 0.4480 - lr: 5.0000e-04\n",
            "Epoch 242/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.1820 - accuracy: 0.9462 - balanced_acc: 0.9457\n",
            "Epoch 242: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9468 - balanced_acc: 0.9466 - val_loss: 0.6921 - val_accuracy: 0.7668 - val_balanced_acc: 0.4293 - lr: 5.0000e-04\n",
            "Epoch 243/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.1872 - accuracy: 0.9433 - balanced_acc: 0.9423\n",
            "Epoch 243: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1878 - accuracy: 0.9430 - balanced_acc: 0.9424 - val_loss: 0.7028 - val_accuracy: 0.7617 - val_balanced_acc: 0.4284 - lr: 5.0000e-04\n",
            "Epoch 244/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.1834 - accuracy: 0.9459 - balanced_acc: 0.9469\n",
            "Epoch 244: val_balanced_acc did not improve from 0.47690\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1834 - accuracy: 0.9456 - balanced_acc: 0.9460 - val_loss: 0.6915 - val_accuracy: 0.7668 - val_balanced_acc: 0.4701 - lr: 5.0000e-04\n",
            "Epoch 245/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9475 - balanced_acc: 0.9471\n",
            "Epoch 245: val_balanced_acc improved from 0.47690 to 0.47716, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1792 - accuracy: 0.9475 - balanced_acc: 0.9471 - val_loss: 0.7003 - val_accuracy: 0.7772 - val_balanced_acc: 0.4772 - lr: 5.0000e-04\n",
            "Epoch 246/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.1829 - accuracy: 0.9448 - balanced_acc: 0.9462\n",
            "Epoch 246: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1835 - accuracy: 0.9446 - balanced_acc: 0.9459 - val_loss: 0.7382 - val_accuracy: 0.7358 - val_balanced_acc: 0.4291 - lr: 5.0000e-04\n",
            "Epoch 247/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.1822 - accuracy: 0.9455 - balanced_acc: 0.9450\n",
            "Epoch 247: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1823 - accuracy: 0.9448 - balanced_acc: 0.9437 - val_loss: 0.7050 - val_accuracy: 0.7617 - val_balanced_acc: 0.4744 - lr: 5.0000e-04\n",
            "Epoch 248/300\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.1789 - accuracy: 0.9477 - balanced_acc: 0.9478\n",
            "Epoch 248: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1788 - accuracy: 0.9479 - balanced_acc: 0.9479 - val_loss: 0.7000 - val_accuracy: 0.7668 - val_balanced_acc: 0.4295 - lr: 5.0000e-04\n",
            "Epoch 249/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.9465 - balanced_acc: 0.9473\n",
            "Epoch 249: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1801 - accuracy: 0.9465 - balanced_acc: 0.9473 - val_loss: 0.7177 - val_accuracy: 0.7513 - val_balanced_acc: 0.4291 - lr: 5.0000e-04\n",
            "Epoch 250/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.1793 - accuracy: 0.9477 - balanced_acc: 0.9479\n",
            "Epoch 250: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1789 - accuracy: 0.9481 - balanced_acc: 0.9482 - val_loss: 0.7187 - val_accuracy: 0.7461 - val_balanced_acc: 0.4256 - lr: 5.0000e-04\n",
            "Epoch 251/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.1761 - accuracy: 0.9509 - balanced_acc: 0.9493\n",
            "Epoch 251: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1762 - accuracy: 0.9508 - balanced_acc: 0.9494 - val_loss: 0.7089 - val_accuracy: 0.7565 - val_balanced_acc: 0.4276 - lr: 5.0000e-04\n",
            "Epoch 252/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.1770 - accuracy: 0.9466 - balanced_acc: 0.9469\n",
            "Epoch 252: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1777 - accuracy: 0.9465 - balanced_acc: 0.9468 - val_loss: 0.7010 - val_accuracy: 0.7513 - val_balanced_acc: 0.4267 - lr: 5.0000e-04\n",
            "Epoch 253/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.1731 - accuracy: 0.9518 - balanced_acc: 0.9517\n",
            "Epoch 253: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1737 - accuracy: 0.9513 - balanced_acc: 0.9510 - val_loss: 0.7127 - val_accuracy: 0.7513 - val_balanced_acc: 0.4265 - lr: 5.0000e-04\n",
            "Epoch 254/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9481 - balanced_acc: 0.9489\n",
            "Epoch 254: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1745 - accuracy: 0.9485 - balanced_acc: 0.9492 - val_loss: 0.6910 - val_accuracy: 0.7772 - val_balanced_acc: 0.4772 - lr: 5.0000e-04\n",
            "Epoch 255/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.1758 - accuracy: 0.9499 - balanced_acc: 0.9504\n",
            "Epoch 255: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1759 - accuracy: 0.9498 - balanced_acc: 0.9503 - val_loss: 0.6962 - val_accuracy: 0.7617 - val_balanced_acc: 0.4693 - lr: 5.0000e-04\n",
            "Epoch 256/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.1787 - accuracy: 0.9455 - balanced_acc: 0.9462\n",
            "Epoch 256: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1782 - accuracy: 0.9460 - balanced_acc: 0.9467 - val_loss: 0.7039 - val_accuracy: 0.7617 - val_balanced_acc: 0.4693 - lr: 5.0000e-04\n",
            "Epoch 257/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.1711 - accuracy: 0.9504 - balanced_acc: 0.9484\n",
            "Epoch 257: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1715 - accuracy: 0.9501 - balanced_acc: 0.9482 - val_loss: 0.6912 - val_accuracy: 0.7772 - val_balanced_acc: 0.4720 - lr: 5.0000e-04\n",
            "Epoch 258/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.1760 - accuracy: 0.9491 - balanced_acc: 0.9482\n",
            "Epoch 258: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1768 - accuracy: 0.9484 - balanced_acc: 0.9476 - val_loss: 0.7025 - val_accuracy: 0.7565 - val_balanced_acc: 0.4682 - lr: 5.0000e-04\n",
            "Epoch 259/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.1705 - accuracy: 0.9498 - balanced_acc: 0.9502\n",
            "Epoch 259: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1711 - accuracy: 0.9499 - balanced_acc: 0.9504 - val_loss: 0.6953 - val_accuracy: 0.7668 - val_balanced_acc: 0.4346 - lr: 5.0000e-04\n",
            "Epoch 260/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.1658 - accuracy: 0.9522 - balanced_acc: 0.9514\n",
            "Epoch 260: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9523 - balanced_acc: 0.9515 - val_loss: 0.7087 - val_accuracy: 0.7617 - val_balanced_acc: 0.4744 - lr: 5.0000e-04\n",
            "Epoch 261/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.9493 - balanced_acc: 0.9482\n",
            "Epoch 261: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1727 - accuracy: 0.9493 - balanced_acc: 0.9482 - val_loss: 0.6830 - val_accuracy: 0.7668 - val_balanced_acc: 0.4295 - lr: 5.0000e-04\n",
            "Epoch 262/300\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.1718 - accuracy: 0.9490 - balanced_acc: 0.9499\n",
            "Epoch 262: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1710 - accuracy: 0.9496 - balanced_acc: 0.9506 - val_loss: 0.7155 - val_accuracy: 0.7565 - val_balanced_acc: 0.4733 - lr: 5.0000e-04\n",
            "Epoch 263/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.1661 - accuracy: 0.9498 - balanced_acc: 0.9483\n",
            "Epoch 263: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9500 - balanced_acc: 0.9485 - val_loss: 0.6970 - val_accuracy: 0.7617 - val_balanced_acc: 0.4693 - lr: 5.0000e-04\n",
            "Epoch 264/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.1712 - accuracy: 0.9513 - balanced_acc: 0.9519\n",
            "Epoch 264: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1703 - accuracy: 0.9515 - balanced_acc: 0.9521 - val_loss: 0.7024 - val_accuracy: 0.7513 - val_balanced_acc: 0.4265 - lr: 5.0000e-04\n",
            "Epoch 265/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.9541 - balanced_acc: 0.9544\n",
            "Epoch 265: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1642 - accuracy: 0.9541 - balanced_acc: 0.9544 - val_loss: 0.7045 - val_accuracy: 0.7565 - val_balanced_acc: 0.4276 - lr: 5.0000e-04\n",
            "Epoch 266/300\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.1656 - accuracy: 0.9527 - balanced_acc: 0.9521\n",
            "Epoch 266: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1652 - accuracy: 0.9528 - balanced_acc: 0.9521 - val_loss: 0.7029 - val_accuracy: 0.7565 - val_balanced_acc: 0.4682 - lr: 5.0000e-04\n",
            "Epoch 267/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9515 - balanced_acc: 0.9517\n",
            "Epoch 267: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1669 - accuracy: 0.9512 - balanced_acc: 0.9512 - val_loss: 0.6883 - val_accuracy: 0.7824 - val_balanced_acc: 0.4405 - lr: 5.0000e-04\n",
            "Epoch 268/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.1694 - accuracy: 0.9515 - balanced_acc: 0.9508\n",
            "Epoch 268: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1696 - accuracy: 0.9513 - balanced_acc: 0.9507 - val_loss: 0.7079 - val_accuracy: 0.7461 - val_balanced_acc: 0.4256 - lr: 5.0000e-04\n",
            "Epoch 269/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9546 - balanced_acc: 0.9546\n",
            "Epoch 269: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1596 - accuracy: 0.9547 - balanced_acc: 0.9546 - val_loss: 0.7049 - val_accuracy: 0.7513 - val_balanced_acc: 0.4265 - lr: 5.0000e-04\n",
            "Epoch 270/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.1649 - accuracy: 0.9505 - balanced_acc: 0.9503\n",
            "Epoch 270: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.9503 - balanced_acc: 0.9501 - val_loss: 0.6965 - val_accuracy: 0.7720 - val_balanced_acc: 0.4337 - lr: 5.0000e-04\n",
            "Epoch 271/300\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.1681 - accuracy: 0.9505 - balanced_acc: 0.9511\n",
            "Epoch 271: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1672 - accuracy: 0.9513 - balanced_acc: 0.9516 - val_loss: 0.7088 - val_accuracy: 0.7565 - val_balanced_acc: 0.4276 - lr: 5.0000e-04\n",
            "Epoch 272/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.1634 - accuracy: 0.9523 - balanced_acc: 0.9515\n",
            "Epoch 272: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1630 - accuracy: 0.9524 - balanced_acc: 0.9516 - val_loss: 0.7102 - val_accuracy: 0.7565 - val_balanced_acc: 0.4276 - lr: 5.0000e-04\n",
            "Epoch 273/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.1620 - accuracy: 0.9539 - balanced_acc: 0.9541\n",
            "Epoch 273: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1635 - accuracy: 0.9533 - balanced_acc: 0.9537 - val_loss: 0.7149 - val_accuracy: 0.7668 - val_balanced_acc: 0.4346 - lr: 5.0000e-04\n",
            "Epoch 274/300\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.1589 - accuracy: 0.9551 - balanced_acc: 0.9563\n",
            "Epoch 274: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1594 - accuracy: 0.9547 - balanced_acc: 0.9559 - val_loss: 0.6978 - val_accuracy: 0.7668 - val_balanced_acc: 0.4346 - lr: 5.0000e-04\n",
            "Epoch 275/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.1606 - accuracy: 0.9542 - balanced_acc: 0.9538\n",
            "Epoch 275: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1603 - accuracy: 0.9542 - balanced_acc: 0.9539 - val_loss: 0.7111 - val_accuracy: 0.7565 - val_balanced_acc: 0.4278 - lr: 5.0000e-04\n",
            "Epoch 276/300\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.9548 - balanced_acc: 0.9538\n",
            "Epoch 276: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1590 - accuracy: 0.9548 - balanced_acc: 0.9538 - val_loss: 0.7220 - val_accuracy: 0.7461 - val_balanced_acc: 0.4290 - lr: 5.0000e-04\n",
            "Epoch 277/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.1624 - accuracy: 0.9537 - balanced_acc: 0.9538\n",
            "Epoch 277: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1613 - accuracy: 0.9541 - balanced_acc: 0.9542 - val_loss: 0.7077 - val_accuracy: 0.7461 - val_balanced_acc: 0.4256 - lr: 5.0000e-04\n",
            "Epoch 278/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.9546 - balanced_acc: 0.9534\n",
            "Epoch 278: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9549 - balanced_acc: 0.9537 - val_loss: 0.6961 - val_accuracy: 0.7720 - val_balanced_acc: 0.4337 - lr: 5.0000e-04\n",
            "Epoch 279/300\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9561 - balanced_acc: 0.9552\n",
            "Epoch 279: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1576 - accuracy: 0.9553 - balanced_acc: 0.9544 - val_loss: 0.7187 - val_accuracy: 0.7668 - val_balanced_acc: 0.4326 - lr: 5.0000e-04\n",
            "Epoch 280/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 0.9571 - balanced_acc: 0.9583\n",
            "Epoch 280: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1575 - accuracy: 0.9570 - balanced_acc: 0.9583 - val_loss: 0.7071 - val_accuracy: 0.7513 - val_balanced_acc: 0.4267 - lr: 5.0000e-04\n",
            "Epoch 281/300\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9555 - balanced_acc: 0.9558\n",
            "Epoch 281: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.1582 - accuracy: 0.9551 - balanced_acc: 0.9555 - val_loss: 0.7123 - val_accuracy: 0.7720 - val_balanced_acc: 0.4388 - lr: 5.0000e-04\n",
            "Epoch 282/300\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.1544 - accuracy: 0.9543 - balanced_acc: 0.9543\n",
            "Epoch 282: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1546 - accuracy: 0.9543 - balanced_acc: 0.9545 - val_loss: 0.6929 - val_accuracy: 0.7668 - val_balanced_acc: 0.4344 - lr: 5.0000e-04\n",
            "Epoch 283/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 0.9561 - balanced_acc: 0.9565\n",
            "Epoch 283: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1574 - accuracy: 0.9563 - balanced_acc: 0.9567 - val_loss: 0.7127 - val_accuracy: 0.7617 - val_balanced_acc: 0.4369 - lr: 5.0000e-04\n",
            "Epoch 284/300\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.1530 - accuracy: 0.9555 - balanced_acc: 0.9556\n",
            "Epoch 284: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1532 - accuracy: 0.9555 - balanced_acc: 0.9556 - val_loss: 0.7323 - val_accuracy: 0.7565 - val_balanced_acc: 0.4309 - lr: 5.0000e-04\n",
            "Epoch 285/300\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.1551 - accuracy: 0.9563 - balanced_acc: 0.9574\n",
            "Epoch 285: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1555 - accuracy: 0.9559 - balanced_acc: 0.9572 - val_loss: 0.6996 - val_accuracy: 0.7720 - val_balanced_acc: 0.4388 - lr: 5.0000e-04\n",
            "Epoch 286/300\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.1514 - accuracy: 0.9567 - balanced_acc: 0.9571\n",
            "Epoch 286: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1530 - accuracy: 0.9558 - balanced_acc: 0.9562 - val_loss: 0.6943 - val_accuracy: 0.7565 - val_balanced_acc: 0.4276 - lr: 5.0000e-04\n",
            "Epoch 287/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.1536 - accuracy: 0.9574 - balanced_acc: 0.9570\n",
            "Epoch 287: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1525 - accuracy: 0.9577 - balanced_acc: 0.9575 - val_loss: 0.7130 - val_accuracy: 0.7461 - val_balanced_acc: 0.4256 - lr: 5.0000e-04\n",
            "Epoch 288/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.1525 - accuracy: 0.9572 - balanced_acc: 0.9573\n",
            "Epoch 288: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1526 - accuracy: 0.9572 - balanced_acc: 0.9573 - val_loss: 0.7122 - val_accuracy: 0.7617 - val_balanced_acc: 0.4318 - lr: 5.0000e-04\n",
            "Epoch 289/300\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.9577 - balanced_acc: 0.9584\n",
            "Epoch 289: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1517 - accuracy: 0.9578 - balanced_acc: 0.9584 - val_loss: 0.7005 - val_accuracy: 0.7617 - val_balanced_acc: 0.4335 - lr: 5.0000e-04\n",
            "Epoch 290/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.1521 - accuracy: 0.9574 - balanced_acc: 0.9571\n",
            "Epoch 290: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1517 - accuracy: 0.9578 - balanced_acc: 0.9575 - val_loss: 0.7082 - val_accuracy: 0.7565 - val_balanced_acc: 0.4684 - lr: 5.0000e-04\n",
            "Epoch 291/300\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.1539 - accuracy: 0.9563 - balanced_acc: 0.9565\n",
            "Epoch 291: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1537 - accuracy: 0.9565 - balanced_acc: 0.9568 - val_loss: 0.7020 - val_accuracy: 0.7720 - val_balanced_acc: 0.4337 - lr: 5.0000e-04\n",
            "Epoch 292/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.1479 - accuracy: 0.9574 - balanced_acc: 0.9570\n",
            "Epoch 292: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9565 - balanced_acc: 0.9560 - val_loss: 0.6954 - val_accuracy: 0.7565 - val_balanced_acc: 0.4276 - lr: 5.0000e-04\n",
            "Epoch 293/300\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.1499 - accuracy: 0.9570 - balanced_acc: 0.9568\n",
            "Epoch 293: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1498 - accuracy: 0.9567 - balanced_acc: 0.9567 - val_loss: 0.7184 - val_accuracy: 0.7565 - val_balanced_acc: 0.4309 - lr: 5.0000e-04\n",
            "Epoch 294/300\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.1486 - accuracy: 0.9556 - balanced_acc: 0.9543\n",
            "Epoch 294: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1485 - accuracy: 0.9556 - balanced_acc: 0.9544 - val_loss: 0.7101 - val_accuracy: 0.7668 - val_balanced_acc: 0.4329 - lr: 5.0000e-04\n",
            "Epoch 295/300\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.1503 - accuracy: 0.9569 - balanced_acc: 0.9569\n",
            "Epoch 295: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 295: val_balanced_acc did not improve from 0.47716\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.1490 - accuracy: 0.9575 - balanced_acc: 0.9576 - val_loss: 0.6963 - val_accuracy: 0.7617 - val_balanced_acc: 0.4335 - lr: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "model = define_base_model('dense')\n",
        "model.summary()\n",
        "hst = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vXnW3lmCgln3",
        "outputId": "5eed4280-336f-41f2-fcc3-367f9351c78d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwwLiXUSG0IZ"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "#hst = model.fit(train_data_batches,\n",
        "#                    epochs = EPOCHS, validation_data = valid_data_batches,      \n",
        "                    #steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "#                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icgjmi-4UIT-"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPz8NH1Oylv9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS3ewyxO_anU",
        "outputId": "6b3706ff-f477-48ab-c1e7-145f67056050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.973644952759821\n",
            "balanced accuracy on training 0.9736449527598209\n",
            "accuracy on validation 0.7616580310880829\n",
            "balanced accuracy on validation 0.5643698055718961\n",
            "Score on val data:  (0.55101817853241, 0.5643698055718961, 0.5497438118798837, None)\n"
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3IyWjdGG4Xq",
        "outputId": "6ab21b2a-5308-486c-8250-d07637accad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.9646231441358244\n",
            "balanced accuracy on training 0.9646231441358244\n",
            "accuracy on validation 0.7772020725388601\n",
            "balanced accuracy on validation 0.7095498288006999\n",
            "Score on val data:  (0.6424402018872065, 0.7095498288006999, 0.6565091345390076, None)\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Oversampling on feature map level"
      ],
      "metadata": {
        "id": "kE8Ziq-BlEP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0xovUlnlhdR",
        "outputId": "ba5ba519-ebc7-4cfa-d8bd-fe0e17eee7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,214,279\n",
            "Trainable params: 26,161,159\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize feature map shapes\n",
        "for i in range(len(last_model.layers)):\n",
        "    layer = last_model.layers[i]\n",
        "    # summarize output shape\n",
        "    print(i, layer.name, layer.output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEGv-ph5lKsY",
        "outputId": "40e0aee0-4b6f-447a-dcd5-c8239e3ba745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_5 (None, 224, 224, 3)\n",
            "1 resnet50 (None, 7, 7, 2048)\n",
            "2 global_average_pooling2d_2 (None, 2048)\n",
            "3 flatten_2 (None, 2048)\n",
            "4 dense_6 (None, 1024)\n",
            "5 dense_7 (None, 512)\n",
            "6 dense_8 (None, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "i = 2\n",
        "model = Model(inputs=last_model.inputs, outputs=last_model.layers[i].output)"
      ],
      "metadata": {
        "id": "KqeSic6NmLsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get feature map for first hidden layer\n",
        "feature_maps = model.predict(X_train)"
      ],
      "metadata": {
        "id": "ZVHYG9Rwm28i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Model(inputs=last_model.layers[i].output, outputs=last_model.layers[6].output)"
      ],
      "metadata": {
        "id": "5qP4iyYcnAYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get feature map for first hidden layer\n",
        "feature_maps = model.predict(X_train)"
      ],
      "metadata": {
        "id": "IW-_U6vFpIci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_train_pred = pd.DataFrame(y_train_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QdyCbloQyWTC",
        "outputId": "4858a620-a785-4253-ab02-c76182de60fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          AKIEC           BCC       BKL        DF       MEL        NV  \\\n",
              "0  1.390465e-06  4.733610e-08  0.001533  0.000022  0.002198  0.996243   \n",
              "1  7.529122e-04  1.294077e-04  0.003562  0.000001  0.990041  0.005513   \n",
              "2  6.812071e-03  1.355026e-02  0.908789  0.015438  0.011777  0.043577   \n",
              "3  1.359046e-03  2.983967e-04  0.001583  0.000235  0.794354  0.202168   \n",
              "4  6.714983e-08  6.721391e-06  0.000430  0.000001  0.911764  0.087798   \n",
              "\n",
              "           VASC  0.0  0.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4  0.45  0.5  \n",
              "0  3.083446e-06    1     0    0     0    0     0    0     0    0     0    0  \n",
              "1  1.605807e-07    1     1    1     1    1     1    1     1    1     1    1  \n",
              "2  5.656496e-05    1     0    0     0    0     0    0     0    0     0    0  \n",
              "3  2.715136e-06    1     1    1     1    1     1    1     1    1     1    1  \n",
              "4  3.255211e-07    1     1    1     1    1     1    1     1    1     1    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3892d01-23e1-4aa9-9784-5ec2d1d0f674\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AKIEC</th>\n",
              "      <th>BCC</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>VASC</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.05</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.15</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.25</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.35</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.45</th>\n",
              "      <th>0.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.390465e-06</td>\n",
              "      <td>4.733610e-08</td>\n",
              "      <td>0.001533</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.002198</td>\n",
              "      <td>0.996243</td>\n",
              "      <td>3.083446e-06</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.529122e-04</td>\n",
              "      <td>1.294077e-04</td>\n",
              "      <td>0.003562</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.990041</td>\n",
              "      <td>0.005513</td>\n",
              "      <td>1.605807e-07</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.812071e-03</td>\n",
              "      <td>1.355026e-02</td>\n",
              "      <td>0.908789</td>\n",
              "      <td>0.015438</td>\n",
              "      <td>0.011777</td>\n",
              "      <td>0.043577</td>\n",
              "      <td>5.656496e-05</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.359046e-03</td>\n",
              "      <td>2.983967e-04</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>0.000235</td>\n",
              "      <td>0.794354</td>\n",
              "      <td>0.202168</td>\n",
              "      <td>2.715136e-06</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.714983e-08</td>\n",
              "      <td>6.721391e-06</td>\n",
              "      <td>0.000430</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.911764</td>\n",
              "      <td>0.087798</td>\n",
              "      <td>3.255211e-07</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3892d01-23e1-4aa9-9784-5ec2d1d0f674')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3892d01-23e1-4aa9-9784-5ec2d1d0f674 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3892d01-23e1-4aa9-9784-5ec2d1d0f674');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "numbers = [float(x)/20 for x in range(11)]\n",
        "\n",
        "for i in numbers:\n",
        "    df_train_pred[i]= df_train_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_train_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_train_true= [1 if x == 4 else 0 for x in np.argmax(y_train, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in num:\n",
        "    cm1 = confusion_matrix(y_train_true, df_train_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31LSzov1tCt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3b21952e-6930-49cc-e988-dcfde56af60e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3Rc1X33//d3LpJGGt0syRdJtmUbm/gOsYwLhCduEhLgV+4BQygEQ0JdHjAJbVf4NawkkLKeXNonQONwaZsQkmIg8AtxEtKsEJy0aSC2TI1kG7CE8WXkm2xrRtfR3Pbvj3NmNJJlaWyPNJqZ72utWXMue2b2kezPHO29zz5ijEEppVT2c2S6AkoppdJDA10ppXKEBrpSSuUIDXSllMoRGuhKKZUjXJn64OrqatPQ0JCpj1dKqay0bdu2Y8aYmpH2ZSzQGxoaaGpqytTHK6VUVhKRfafap00uSimVIzTQlVIqR2igK6VUjtBAV0qpHKGBrpRSOWLMQBeR74vIURHZcYr9IiKPi0ibiDSLyIfTX02llFJjSeUM/RngslH2Xw7Mtx93AU+cfbWUUkqdrjHHoRtj/lNEGkYpcjXwrLHm4X1TRCpEZIYx5lCa6jjUvjfg/dfH5a1T4iwAVyG4iqxntydpvWhwu6sI3MnrdjmRzNVdKZXT0nFhUR1wIGndZ287KdBF5C6ss3hmzZp1Zp/m2wL/+e0ze+1ZS8Pc8c7ksC88OfBP+iKwl90ecBdDgRcKSqDAXnYX2+tee1sJuEvAmbFrxpRSGTKh/+uNMU8DTwM0NjaeWTpefJ/1yJRoBCLBpMcAhPut5yHbR9o3AJGk9XBSufhr+o6N/LpwH6f1heIstIPefpwq+AtKRiiXVKbAC4WlUFhmfanoXxhqkjHGEDERIrGRH2ETPmlb1EQJx0beHolFhuyLb0tsNxGiscFt8c8Ox8KD24fXZ9j6Xy//ay6bM1pL9plJR6C3AzOT1uvtbbnJ6QKnFwq9E/u5xlghH+6DUA+E+iDUC+Fe6zn5MVqZrvakMr1WORNLrQ4OlxXshaVQVAaF5fZz2bBn+wugqPzkfQVe/VLIEtGYFXqhWIhQNEQ4GrbWo6HBbbEw4Wh4yHpie7ysXT5RNmk9XnakUB0erKcMbROZsJ+JQxy4xIXL4cLpcOJ2uBPr8W0uhwuXuKx99rZCKUyUcTlclBWUjUv90hHom4B7ROR5YBUQGLf283wmYp81F0NJdfre1xjrL4AhwW9/IYT7YKAHBrqsR9B+HugeXPYfgIHA4PpYXw7iGAz8k74Ikp4TZeJNTKWDf0UUeq0vBqc7fT+HDDPGEIwGhwRgfDk5+BJhmBSio+07KVRPEb7J7xNfj5poWo/R7SjA7XAnnl0ON26HG6e4cMZDUuxQlGIKnS6cbnufOHHG94sL50nr1jaXw4UDF047VB3iTDw7xDlY1jH4vm6HG5fT+ny3/Ygvu5xuXOKkwOHG7XTjdDgQAYfIkGdBcCSvi7Uef3bYJzGOYevpNmagi8hGYDVQLSI+4KuAG8AY8yTwKnAF0Ab0AWvHpaZqfIhYbfbuIqDq7N7LGOsLYUjoJ4X9kOduezkAPYfh2O7BfbFwap+XaFbyJgW/9xTbvEO/DEba7i4Bx8gDv2ImRjASpD/STzAapDfUR/dAL73hID2hXnrD/fSE+ugL99MX6ac33JcoH3/NQKSfgegAA7F+BqJBQrEBwrEg4dgAYTNAWvpoADFOBBeCC4zbWjYuwAXGaT9cGOMCU4yJOa3lmBNj7GXjsrc7MTEnMXt/LL49/poh7+XCDHl/J8Ss7daAusnwl5kBwvYjc/7hmiX85Z/NTvv7pjLK5eYx9hvgf6etRip7iVjBeDbNUcZY/QbBLrvZqMf6KyHePBSylweSlpPKmVAvse4j1hdGqBcJ9xKODdDlcNDtcJz0nFh2Ws8Bh4uAw0mvOOlzOBgQGBBDxHH6YWtiLkysAIzbeo4VYIzbeo6VQqwKYwogZu83BRg7AAUXDnFbZ5vJy+LGgRunuO2zTDcue93tdNtnuk6cDkl6OHAK1rMDXA7H0P0iOByC0xE/gxw8+xw86xxcHjzztLc5TrP8sLPb+Nlq8kmrxLcl/dMShpZL3scI+0Z8j8R+wWAwxvonFzOGmAGwnmPGJLYbAwZDLGavY/1FFUt6rbG3x2L29kSZ+PtY5bDLLK+vOO1/T6nQoRBqUghFYvj7QpzoC9HZG8bfF6Mr6KZ3oIzugQL8A266gg4CIegJG3rDMfojMYKxGAOxGCEDESPExIk4CsDrQZz9iCOIOEZvY3XGHBQaFx7jpMQ48BqhNhbFGwlTGhugLNpPSSyKx8Qoihk8xnoUGCcOVykOVznirsRZWIUUTcXpmYbDUwveqUSLp0LJVFxFHlwOB26ngwKXWMsuB26nUOB04HI6cDkEt9ORCEClTpcGukq7/lCUzr4QJ3pD+PvCdPaFrEfv4PLxvj6O9R3DHzpGT7iTAfyIqwtxdeNwdVvLzj7E0Y84Qyd/iNN+AIITt5RQLCUUOUvwOCspcc/G6/biLSilvKCMyqJyKj1lTPGUU+2poKaknCpPBaWFpRQ6C0c/IGMg6Ieeo9BzJOn5yNBtx1uh9xgjNp0UloF3KninjfCctFxcBY7c6RtQE0sDXZ2SMYbeUJQTPaHBUE6cQdtn0332cmJbNyECOOxwjj/i664Ca904+6DU+hwBigDBQam7koqCKqo9c6nyVDLFU26FcVE5pQWllBWUDXkuLSjF4/KM7xmtCHgqrUfNuaOXjUasoaejBf/hFuj5rdVnMBJ3iTVCyFNhPRdVpL6uo4jymgZ6nuoZiHCkK8iRriAd3QP28gBH7eWjXUGOdg/QF4oCBhz9g2fOrm4c7m6KinopKOjB4e7GVHQRrghQQJCCYZ/lEjdVnmqmFtcwtXg21Z5qajw11BTXJJ6rPdVUFlbidDgz8eNIH6cLSqdbj7GE+qD36GDYdx+Gfr/110D8ORiALh8c2WktDwRGf09x2iEfD/yxvgwq7fVKKJ6iXwZZTgM9x/QMRDiaCOcgR7vssO4eSIT0ka6gHdRxUcQdoMgToLy0B4+nC9e0TqbXnmCA4/RGTxA1J48KKHJ5qPFYYVxTPHdISCeHdllBmbYJj6SgGAoaoLIh9dfEotaZfb8d9vHQH3HdXg74BvdFR2i+inMW2F9GMwYfZfHl6VBaaz1P9DUYKmUa6FmiN3FGPRjUR7ut9eSz7N7QyWOHi9yG6oog5aXdTJkeYOpMPzHnCYIcoztylM7QMWL2mONeoA+hxlNDvbeOGSUrmFY8zQ7toUFd4i6Z4J+CwuEcbP45XfERRCOFf/8J6D5k/ZXQddD6i6DtNWv00HCFZUODv2zGyV8C3mk5dZ1AttBAn4R6ByI0+wK87fPz9gE/2w/4ORQInlSuyO1gWlkRNaUuGmYEWTS3C0dBJzHncQbMcboiRzk+cJiO/qMETIwAQBQkKkwtnkqdt44l3pXUemup89ZR662ltqSW6SXTKXAObzhRWU/EnhPIY4VuKga6oeuQHfb2I7F+GPb9t7UcGz6SSKCkxgr+stpTn/kXV2kzTxppoGdYJBpj95Eeth8YDO/Wo932mFiYNaWYxtkV1Nb04S60z6zNMboiR+noP8zB3oO09h0lFolBt/UahziYVjyNGSUzuKByWGB7a5lePB23nj2pVBSWQk0p1Cw4dZlYDPqOnyL0D1nTTfiarM7i4ZwF4J0OpdMGQ987LamZx97mqdTgT4EG+gQyxtDu7x8S3i3tAYJh63L5imI3582s4FOLp1JTfYJeeY+dJ95i25Ft/O5gd+J9HOJgevF0ar21XDD9gsSZdTy0p5VMw61D39REcTjAW2M9Ziw7dblIyO78TQ79g9BtbzvWCh/8p9UMNFwi+OPhbwe+Nyn0S6fnffBroI+jQH+YZp+f7fv9vO2zAvxYj9UpVeBysLi2jJsvmMWy+jKmVJzA17+DrUde5f870kTgkPWPelbpLD7Z8EmW1yynvrSeWm8tU4unamCr7OMqgIqZ1mM04X6rOaf7sBX0iS8B+7lj9yjBX2gF/pCgH+ELIEeDXwM9TQYiUd491D3k7HvPsd7E/nk1JfyvBTWcP7OCZfXlFBUf5386mthy+GW+814TnQOdANR56/jzmX/OBdMvYOX0lUwvSWH4m1K5xO2BKXOsx2hCfdY8QPGg7z5sr9tfBB3vwZ7fjzzU01lote1XL7Cak6oXQPW5UD3fGr6ZpTTQz4Axhr3H+9h+oJO3DwTYfsDProNdhKJW00m1t5DzZlZw/Yp6ltdXsKSujEDkEFsOb2Hroa18/42tHOu32hOnl0znkvpLaJzWyAUzLqDOW5fJQ1MqexQUw5S51mM0ieA/PPTM37/faubZ8zuIDgyWL6mxA37B0MAvqz/l5G2ThQb6aXjmvz/g9fc6ePuAn0C/NS7b43aytL6c2y9u4LyZFSyfWcGMskLae9vZengrvzi8ha9u38rRvqMA1HhquGD6BYlHfWm9jtFWajyNFfyxKPj3WeHe8Z418+ex3bDzp9bQzjh3MVSdY4e8fTZffS5UzbPuLjYJiDHpmbLzdDU2NpqmpqaMfPaZONod5IJHfsvsqmIunFvF8pkVnDezgvlTvbicDg71WGfgWw5vYevhrRzqtaaEn1I0hZXTVyaaUBrKGjTAlcoGxlhz8xzbDcfeSwr8VgjsHywnDuvisCFn9Xbgn8n1AmMQkW3GmMaR9ukZeopafFY73D/esJyVDVM40nuELYd/z8Y3t7L18FZ8PT4AKgorWDl9JWuXrGXltJXMq5inAa5UNhIZHL3TcPHQfaFeON5mddAmB/77rw+9Grdk6rB2evtRXj8unbIa6Clq9gVwe99jk28rD/1PE/u69gFQWlBK47RGbll4Cyunr2R+5XwcMrnb2ZRSZ6mgBGYstx7JohG7+cYO+njg73h56KicT/0fuPDutFdLAz1F29sPUVT/DL/ZX8yKaSu4YcENrJy+knMrz83+CaWUUunhdFlt6lXz4NzLB7cbA70dg230sy8al4/XQE+BMYYdHbthquGbl3yTj878aKarpJTKJiL2nPdTYc4l4/Yx2jaQgiNdA3RFDwAwv3J+hmujlFIj00BPQbPPj6PwMEVODzNKUpzUSCmlJpgGegpa2gM4i45wTsV8HbGilJq0NNBT0Nzux110hHOnaHOLUmry0kAfgzGGloM+Yo5ebT9XSk1qGuhjOBgIEojZHaIVGuhKqclLA30MLXaHKMA5ledkuDZKKXVqGuhjaGkP4Co8wpSiKUwpyt5pNZVSuU8DfQzNvgDF3g5tP1dKTXoa6KMwxtDc3knUdVjbz5VSk54G+ih8nf10hY8SZYBzKrT9XCk1uWmgj6LZF8Bpd4hqk4tSarLTQB9FS3sAt8e609C8inkZro1SSo0upUAXkctE5D0RaRORB0bYP0tENovI/4hIs4hckf6qTryWdj/l5ceo89ZR4i7JdHWUUmpUYwa6iDiBDcDlwCLgZhFZNKzYg8CLxpjzgZuA76W7ohPNGEOzL4Cj8Ih2iCqlskIqZ+gXAG3GmD3GmBDwPHD1sDIGKLOXy4GD6atiZuw73kd3MEhv7JBeUKSUygqpBHodcCBp3WdvS/Y14C9FxAe8Ctw70huJyF0i0iQiTR0dHWdQ3YnT3B7AUXiMGFE9Q1dKZYV0dYreDDxjjKkHrgB+JHLyjTWNMU8bYxqNMY01NTVp+ujxsaM9QIHnCKCX/CulskMqgd4OzExar7e3JbsTeBHAGPMGUARUp6OCmdLs81NT1YlLXMwpm5Pp6iil1JhSCfStwHwRmSMiBVidnpuGldkPfBxARBZiBfrkblMZRSxm2NHeRVHxURrKG3A73ZmuklJKjWnMQDfGRIB7gF8D72CNZtkpIg+LyFV2sb8BPi8ibwMbgduNMWa8Kj3ePjjeS89AhKAc1CtElVJZw5VKIWPMq1idncnbvpK0vAu4OL1Vy5wd7QFwDOAPH9YrRJVSWUOvFB1Bsy+Ap9hqMdIzdKVUttBAH0GLL0DtVD+gc7gopbKHBvow0Zhhx8EAZWXH8bg81HmHD7lXSqnJKaU29Hyyp6OHvlCUqOsQ87zzcJw8nF4ppSYlTathWtoDAJwI79PmFqVUVtFAH6bZF6DY008g1KkdokqprKKBPkxLe4CGGV2AdogqpbKLBnqSSDTGzoMBqio7AQ10pVR20U7RJG0dPQTDMVxFR6iIVlBVVJXpKimlVMr0DD1Ji8/qEO2OHWB+5XxEJMM1Ukqp1GmgJ2lpD+AtdHKgZ492iCqlso4GepJmX4D5tRH6In0a6EqprKOBbgtHY+w61MWMqVaH6ILKBRmukVJKnR4NdNvuI92EIjE8JccAmFcxL8M1Ukqp06OBbtthXyE6ID5mlMygtKA0wzVSSqnTo4Fua/YFKC1ycah/r7afK6Wykga6raU9wJK6Ej4IfKA3hVZKZSUNdCAUifHuoW5mT+8nHAszv0KvEFVKZR8NdOwO0WiM8rLjgF7yr5TKThroWO3nADH3QZziZE75nAzXSCmlTp8GOtDS7qfc4+ZocB+zymZR6CzMdJWUUuq0aaBjnaEvqy+nzd+mI1yUUlkr7wM9GI7y3uFuPlRbyIHuA9p+rpTKWnkf6O8d7iYSM0ydEsBgdISLUipr5X2gN9tXiLqKjgA6wkUplb3yPtBbfH6mlBRwLLSPQmch9d76TFdJKaXOSN4HerMvwNI6q0N0bvlcnA5npquklFJnJK8DPRiO0nq0h2X15bR2tmpzi1Iqq+V1oO861EU0Zpg7Tejo79AOUaVUVsvrQI/fQ7TY2wFoh6hSKrulFOgicpmIvCcibSLywCnK3Cgiu0Rkp4g8l95qjo9mX4BqbyEnQvsB9KIipVRWc41VQEScwAbgUsAHbBWRTcaYXUll5gP/L3CxMaZTRKaOV4XTqaXdb18h+galBaVMLc6Kaiul1IhSOUO/AGgzxuwxxoSA54Grh5X5PLDBGNMJYIw5mt5qpl9fKELb0R6W1pXT6m9lfsV8RCTT1VJKqTOWSqDXAQeS1n32tmQLgAUi8t8i8qaIXDbSG4nIXSLSJCJNHR0dZ1bjNNl1sIuYgaV1ZbR1tmn7uVIq66WrU9QFzAdWAzcD/yIiFcMLGWOeNsY0GmMaa2pq0vTRZyY+Ze6MqgG6w93afq6UynqpBHo7MDNpvd7elswHbDLGhI0xHwC7sQJ+0mppDzCtrJATYatDVM/QlVLZLpVA3wrMF5E5IlIA3ARsGlbmFayzc0SkGqsJZk8a65l2zT4/S+sqaPO3ATrCRSmV/cYMdGNMBLgH+DXwDvCiMWaniDwsIlfZxX4NHBeRXcBm4O+MMcfHq9Jnq2cgwp5jvYkrRKcWT6W8sDzT1VJKqbMy5rBFAGPMq8Crw7Z9JWnZAPfbj0lvZ3sAY2BpfTl/2N2mV4gqpXJCXl4p2mJPmbuo1sv7/ve1uUUplRPyMtCbfQFqy4voix0hFAtph6hSKifkZaC3tAdYat9DFOCcSj1DV0plv7wL9K5gmA+O9bKsvoLWzlYEYV75vExXSymlzlreBfoOu/18iX1Ti1llsyhyFWW4VkopdfbyLtDjU+YurbOGLGqHqFIqV+RdoDe3B6iv9FBcGGN/937tEFVK5Yy8C/Qd7QGW1ZfzQeADYiamZ+hKqZyRV4Ee6Auz73gfS+sqaPW3AjqHi1Iqd+RVoMcvKFpaV05bZxtuh5tZpbMyXCullEqPvAr05nY/QOKmFnPL5+JypDT7gVJKTXp5FegtvgCzq4opL3bT2tmqzS1KqZySX4HeHmBpXTldoS6O9B3RDlGlVE7Jm0A/0RvC19nPsvpy3ve/D2iHqFIqt+RNoLckXSHa2mmPcNFpc5VSOSR/At1ndYjGA93r9jK9ZHqGa6WUUumTN4He7Aswt7qEsiI3rX7rkn8RyXS1lFIqbfIm0HfYU+YaY2jzt+mUuUqpnJMXgd7RPcDBQJCldeUc6z9GYCCgI1yUUjknLwJ9R/vQGRYBFlQuyGSVlFIq7fIi0Jt9AURgsX2FKKBn6EqpnJMXgd7SHmBejRdvoYvWzlaqPdVUFlVmulpKKZVWeRLofpbVlQNYHaJ6dq6UykE5H+hHuoIc6RpgSV05MRPjff/7GuhKqZyU84Eev+XcsvpyfN0+gtGgdogqpXJSzgd6c3sAh8Ci2jLtEFVK5bScD/Qd7QHmTy2luMCVGLI4r2JehmullFLpl9OBboyh2WddIQpWh2i9t55id3GGa6aUUumX04F+uCvIsZ4BlsZHuHTqJf9KqdyV04HebHeILq0vJxQNsbdrr06Zq5TKWTkd6C2+AE6HsGhGGR8EPiBqonpTC6VUzkop0EXkMhF5T0TaROSBUcpdLyJGRBrTV8Uz19IeYMG0UorcTtr8bYDe1EIplbvGDHQRcQIbgMuBRcDNIrJohHKlwH3An9JdyTNhjLHvIVoGQGtnKy6Hi9llszNcM6WUGh+pnKFfALQZY/YYY0LA88DVI5T7OvBNIJjG+p2xdn8/J3pDLK2vAKwRLg1lDbid7gzXTCmlxkcqgV4HHEha99nbEkTkw8BMY8wvR3sjEblLRJpEpKmjo+O0K3s6EleI2iNcWjtbtf1cKZXTzrpTVEQcwP8F/masssaYp40xjcaYxpqamrP96FG1tAdwO4UPzSilJ9TDwd6D2n6ulMppqQR6OzAzab3e3hZXCiwBficie4E/AzZlumO0pT3AudNLKXQ5eT/wPoCeoSulcloqgb4VmC8ic0SkALgJ2BTfaYwJGGOqjTENxpgG4E3gKmNM07jUOAWJK0STmltA53BRSuW2MQPdGBMB7gF+DbwDvGiM2SkiD4vIVeNdwTNx4EQ/gf4wS+sGO0Q9Lg+13toM10wppcaPK5VCxphXgVeHbfvKKcquPvtqnZ3mdj9gTZkLdodoxXwcktPXUSml8lxOJlxLe4ACp4MF00oB+y5FOoeLUirH5Wag+wIsnFFKgcvB8f7jnAie0PZzpVTOy7lAj8WsK0SXxDtE7Zta6AgXpVSuy7lA33eij+5gJNF+3tZpzeGiZ+hKqVyXc4He7LM6ROMjXFr9rUwpmkK1pzqT1VJKqXGXc4G+oz1AocvB/GlewL6phZ6dK6XyQM4FerMvwMIZZbidDmImZo1w0UBXSuWBnAr0WMywoz2QaD8/2HOQvkifdogqpfJCTgX6nmO99Iaig/cQ9WuHqFIqf+RUoO9ot6fMtedA1zlclFL5JKcCvdkXwON2Mq+mBLBGuNSW1OIt8Ga4ZkopNf5yKtBb2v0sqi3D5bQOSy/5V0rlk5wJ9GjMsKO9K9F+Ho6F+SDwgd7UQimVN3Im0N/v6KE/HE2McNkX2EckFtEzdKVU3siZQE/cQ7R+6AgXPUNXSuWL3An09gAlBU7mVFsdoLs7d+MUJ3PK52S4ZkopNTFyJtCbfX4W15bjdAhgnaHPLptNgbMgwzVTSqmJkROBHonG2Hmwi6V2cwvYdynSK0SVUnkkJwK99WgPA5FYov28L9yHr8enFxQppfJKTgR6i32FaHzI4p7AHkBvaqGUyi+5Eei+AN5CFw1V9hWi9iX/OsJFKZVPciLQm9sDLKkrw2F3iLb6WylyFlHnrctwzZRSauJkfaCHozHeOdSVmJALrDP0eRXzcDqcGayZUkpNrKwP9N1HuglFYon2c0BvaqGUyktZH+jDrxDtDHZyrP+YdogqpfJO1gd6c3uAsiIXs6YUA3rJv1Iqf2V9oLf4AiytL0fE7hCN39RCJ+VSSuWZrA70gUiUdw93sbQuqUPU30p5YTk1npoM1kwppSZeVgf67sM9hKMm0X4O0NZpdYjGz9iVUipfZHWgN7f7gcErRI0xOsJFKZW3XKkUEpHLgMcAJ/CvxphvDNt/P/A5IAJ0AHcYY/alua4nafEFqCh2U1/pAeBw72F6wj0sqFww3h+tlALC4TA+n49gMJjpquScoqIi6uvrcbvdKb9mzEAXESewAbgU8AFbRWSTMWZXUrH/ARqNMX0i8tfAt4A1p1X7M9DsC7C0LqlD1G93iOoZulITwufzUVpaSkNDgzZzppExhuPHj+Pz+ZgzJ/V7OqTS5HIB0GaM2WOMCQHPA1cP+/DNxpg+e/VNoD7lGpyhYDjK7iPdQ9vP7SGLOsJFqYkRDAapqqrSME8zEaGqquq0//JJJdDrgANJ6z5726ncCfxqpB0icpeINIlIU0dHR+q1HMG7h7uJxMzQES6drUwrnkZZQdlZvbdSKnUa5uPjTH6uae0UFZG/BBqBb4+03xjztDGm0RjTWFNzdsMKW3xWh+jwM3Q9O1dK5atUAr0dmJm0Xm9vG0JEPgF8GbjKGDOQnuqdWrMvQFVJATPKiwCIxCLs8e9hQYV2iCqVb1555RVEhHfffTfTVcmoVAJ9KzBfROaISAFwE7ApuYCInA88hRXmR9NfzZO1tA+9QnR/935CsZCeoSuVhzZu3MhHPvIRNm7cOG6fEY1Gx+2902XMUS7GmIiI3AP8GmvY4veNMTtF5GGgyRizCauJxQv8xA7Y/caYq8ar0v2hKK1He/jkommJbW2dOoeLUpn00M93sutgV1rfc1FtGV+9cvGoZXp6evjDH/7A5s2bufLKK3nooYeIRqN86Utf4j/+4z9wOBx8/vOf595772Xr1q3cd9999Pb2UlhYyG9/+1tefvllmpqa+O53vwvAX/zFX/C3f/u3rF69Gq/Xy1/91V/x2muvsWHDBl5//XV+/vOf09/fz0UXXcRTTz2FiNDW1sa6devo6OjA6XTyk5/8hIceeojrrruOa665BoBbbrmFG2+8kauvvnq0wzkrKY1DN8a8Crw6bNtXkpY/keZ6jWrXoS6iMcPS+qGX/DvEwZzy1If4KKWy389+9jMuu+wyFixYQFVVFdu2bWPLli3s3buX7du343K5OHHiBKFQiDVr1vDCCy+wcuVKurq68Hg8o753b28vq1at4p/+6Z8AWLRoEV/5ihV9t956K7/4xS+48sorueWWW3jggQe49tprCQaDxGIx7rzzTr7zne9wzTXXEAgE+OMf/8gPf20WESkAAA/jSURBVPjDcf1ZpBTok028Q3TIHOidbcwqnUWRqyhT1VIqr411Jj1eNm7cyH333QfATTfdxMaNG/nggw9Yt24dLpcVcVOmTKGlpYUZM2awcuVKAMrKxh4N53Q6uf766xPrmzdv5lvf+hZ9fX2cOHGCxYsXs3r1atrb27n22msB64IggI9+9KPcfffddHR08PLLL3P99dcn6jNesjLQm9sD1JQWMq2sMLGt1d+qV4gqlWdOnDjB66+/TktLCyJCNBpFRBKhnQqXy0UsFkusJ4/9Lioqwul0JrbffffdNDU1MXPmTL72ta+NOU78tttu48c//jHPP/88P/jBD07z6E5fVs7l0uILsCzpCtFgJMj+rv16hahSeeall17i1ltvZd++fezdu5cDBw4wZ84cli9fzlNPPUUkEgGs4D/33HM5dOgQW7duBaC7u5tIJEJDQwPbt28nFotx4MABtmzZMuJnxcO7urqanp4eXnrpJQBKS0upr6/nlVdeAWBgYIC+Pus6y9tvv51HH30UsJprxlvWBXrvQIT3O3pYmjT+fE9gDwajdylSKs9s3Lgx0dQRd/3113Po0CFmzZrFsmXLWL58Oc899xwFBQW88MIL3HvvvSxfvpxLL72UYDDIxRdfzJw5c1i0aBHr16/nwx/+8IifVVFRwec//3mWLFnCpz71qSF/BfzoRz/i8ccfZ9myZVx00UUcPnwYgGnTprFw4ULWrl07fj+EJGKMmZAPGq6xsdE0NTWd9uu27j3BDU++wfdvb+RjH7JGufys7Wc8+N8PsumaTdopqtQEeuedd1i4cGGmqzFp9fX1sXTpUt566y3Ky8vHfsEwI/18RWSbMaZxpPJZd4bebN9DdMmwm0IXOAqYWTrzVC9TSqkJ9dprr7Fw4ULuvffeMwrzM5F1naJ/NncKX75iIVNLB0eztHa2Mq9iHi5H1h2OUipHfeITn2DfvnGfRXyIrEvAxbXlLK4d+m3X6m9l1fRVGaqRUkpNDlnX5DJcYCDA0b6jesm/UirvZX2gx+dA10v+lVL5LvsDPT6Hiw5ZVErluawP9FZ/K6XuUqYVTxu7sFIq5zzyyCMsXryYZcuWcd555/GnP/0pbe990UUXAbB3716ee+65xPampibWr18/6muffPJJnn32WQCeeeYZDh48mLZ6nUrWdYoO19rZyjmV5+hdU5TKQ2+88Qa/+MUveOuttygsLOTYsWOEQqG0vf8f//hHYDDQP/OZzwDQ2NhIY+OIQ8ET1q1bl1h+5plnWLJkCbW1tWmr20iyOtCNMbT52/hUw6cyXRWl1K8egMMt6X3P6Uvh8m+ccvehQ4eorq6msNCa16m6uhqAbdu2cf/999PT00N1dTXPPPMMM2bMYPXq1axatYrNmzfj9/v5t3/7Ny655BJ27tzJ2rVrCYVCxGIxXn75ZebPn4/X66Wnp4cHHniAd955h/POO4/PfvaznH/++fzjP/4jmzZtYu7cuWzfvp2KCmv21/nz5/OHP/yBJ554Aq/XS0NDA01NTdxyyy14PB4eeeQR/uVf/iUxVcBvfvMbvve97/HTn/70rH9cWd3kcrTvKF2hLm0/VypPffKTn+TAgQMsWLCAu+++m9///veEw2HuvfdeXnrpJbZt28Ydd9zBl7/85cRrIpEIW7Zs4dFHH+Whhx4CrOaR++67j+3bt9PU1ER9/dD73H/jG9/gkksuYfv27Xzxi19MbHc4HFx99dWJMP7Tn/7E7NmzmTZtsAn405/+NI2Njfz7v/8727dv54orruDdd98lfl/lH/zgB9xxxx1p+Xlk9Rl6fISLTsql1CQwypn0ePF6vWzbto3/+q//YvPmzaxZs4YHH3yQHTt2cOmllwLWnYZmzJiReM11110HwIoVK9i7dy8AF154IY888gg+n4/rrruO+fNTP0lcs2YNDz/8MGvXruX5559nzZo1o5YXEW699VZ+/OMfs3btWt54441EW/vZyolA1yGLSuUvp9PJ6tWrWb16NUuXLmXDhg0sXryYN954Y8Ty8eYZp9OZmI3xM5/5DKtWreKXv/wlV1xxBU899RQf+9jHUvr8Cy+8kLa2Njo6OnjllVd48MEHx3zN2rVrufLKKykqKuKGG25I2zzpWd3ksrtzNzWeGiqKKsYurJTKOe+99x6tra2J9e3bt7Nw4UI6OjoSgR4Oh9m5c+eo77Nnzx7mzp3L+vXrufrqq2lubh6yv7S0lO7u7hFfKyJce+213H///SxcuJCqqqqTygx/fW1tLbW1tfzDP/xDWmdizPozdG1uUSp/9fT0cO+99+L3+3G5XJxzzjk8/fTT3HXXXaxfv55AIEAkEuELX/gCixef+o5KL774Ij/60Y9wu91Mnz6dv//7vx+yf9myZTidTpYvX87tt9/O+eefP2T/mjVrWLlyJc8888yI73/77bezbt06PB4Pb7zxBh6Ph1tuuYWOjo60zlaZddPnxkVjUVY9t4o1567h71b+XRprppRKlU6fe+buuecezj//fO68885Tljnd6XOz9gzd1+NjIDqgZ+hKqayzYsUKSkpKEjefTpesDfT4Jf96H1GlVLbZtm3buLxv1naK7vbvRhC9Q5FSStmyNtDbOtuoL62n2F2c6aoopdSkkLWB3upv1fHnSimVJCsDfSA6wP6u/XpTC6WUSpKVgb43sJeoieocLkqpcZ0+94orrsDv9wPw+OOPs3DhQm655RY2bdrEN74x+lQHp5p6dzxl5SiX3Z27Ab3kX6l8N97T57766quJ5e9973u89tpriYm7rrrqqlFfe6qpd8dTVgZ6m78Nl8PFrLJZma6KUsr2zS3f5N0T76b1PT805UN86YIvnXL/qabPbWho4MYbb+RXv/oVHo+H5557jnPOOYeOjg7WrVvH/v37AXj00Ue5+OKLE1ecNjU1ISJ89atf5frrr09Mffvggw+yZ88eLr/8cu644w4qKytpamriu9/9LkeOHGHdunXs2bMHgCeeeIKLLrrolFPv/vSnP+Xxxx/nvPPOA+AjH/kIGzZsYPny5Wf988rKJpfWzlbmls/F7XBnuipKqQwaafrcuPLyclpaWrjnnnv4whe+AMB9993HF7/4RbZu3crLL7/M5z73OQC+/vWvJ8o3NzefNDHXk08+SW1tLZs3bx4yfS7A+vXr+ehHP8rbb7/NW2+9ddIUA8On3r3zzjsTUwTs3r2bYDCYljCHLD5DP3/q+WMXVEpNmNHOpMfLSNPnxtu2b7755sRzPIRfe+01du3alXh9V1cXPT09vPbaazz//POJ7ZWVlSnX4fXXX09Mf+t0OikvLx+1/A033MDXv/51vv3tb/P973+f22+/PeXPGktKgS4ilwGPAU7gX40x3xi2vxB4FlgBHAfWGGP2pq2WSXpCPRzqPcSNlTeOx9srpbLM8Olzf/jDHwIMuS1lfDkWi/Hmm29SVFSUkboCFBcXc+mll/Kzn/2MF198Ma1XjY7Z5CIiTmADcDmwCLhZRBYNK3Yn0GmMOQf4DvDNtNVwGJ0DXSkVN9L0ubNnzwbghRdeSDxfeOGFgNVE88///M9DygNceumlbNiwIbG9s7Mz5Tp8/OMf54knngCsm2kEAoEh+0eaevdzn/sc69evZ+XKlaf118BYUmlDvwBoM8bsMcaEgOeBq4eVuRr4ob38EvBxGae7Nrf6rV+ejkFXSvX09PDZz36WRYsWsWzZMnbt2sXXvvY1wArlZcuW8dhjj/Gd73wHsIYeNjU1sWzZMhYtWsSTTz4JwIMPPkhnZydLlixh+fLlbN68OeU6PPbYY2zevJmlS5eyYsWKIU06MHTq3Xg9VqxYQVlZWVrnQocUps8VkU8DlxljPmev3wqsMsbck1Rmh13GZ6+/b5c5Nuy97gLuApg1a9aKffv2nXaFX9//Oq+0vcJjf/4Y4/SdoZRK0WSdPjc+OiU+6mWyOXjwIKtXr+bdd9/F4Tj1efXpTp87oaNcjDFPG2MajTGNNTU1Z/QeH5v1MR7/2OMa5kqprPTss8+yatUqHnnkkVHD/Eyk0inaDsxMWq+3t41UxiciLqAcq3NUKaUmXPzmz5PRbbfdxm233TYu753K18NWYL6IzBGRAuAmYNOwMpuAz9rLnwZeN5m6FZJSakLpf/XxcSY/1zED3RgTAe4Bfg28A7xojNkpIg+LSPza138DqkSkDbgfeOC0a6KUyjpFRUUcP35cQz3NjDEcP378tIdXZu09RZVSmRcOh/H5fASDwUxXJecUFRVRX1+P2z30ivicvKeoUirz3G43c+boXcMmi6ycy0UppdTJNNCVUipHaKArpVSOyFinqIh0AKd/qailGjg2ZqncosecH/SY88PZHPNsY8yIV2ZmLNDPhog0naqXN1fpMecHPeb8MF7HrE0uSimVIzTQlVIqR2RroD+d6QpkgB5zftBjzg/jcsxZ2YaulFLqZNl6hq6UUmoYDXSllMoRkzrQReQyEXlPRNpE5KQZHEWkUEResPf/SUQaJr6W6ZXCMf8vEXlLRCL23aSyXgrHfL+I7BKRZhH5rYjMzkQ90ymFY14nIi0isl1E/jDCfXyzzljHnFTuehExIpLVQxlT+B3fLiId9u94u4h87qw/1BgzKR+AE3gfmAsUAG8Di4aVuRt40l6+CXgh0/WegGNuAJYBzwKfznSdJ+iY/xwotpf/Ok9+z2VJy1cB/5Hpeo/3MdvlSoH/BN4EGjNd73H+Hd8OfDednzuZz9An1c2pJ8iYx2yM2WuMaQZimajgOEjlmDcbY/rs1Tex7pqVzVI55q6k1RIg20cvpPL/GeDrwDeBbJ+PN9XjTavJHOh1wIGkdZ+9bcQyxroRRwCompDajY9UjjnXnO4x3wn8alxrNP5SOmYR+d/2Dde/BayfoLqNlzGPWUQ+DMw0xvxyIis2TlL9d3293ZT4kojMHGH/aZnMga7UECLyl0Aj8O1M12UiGGM2GGPmAV8CHsx0fcaTiDiA/wv8TabrMoF+DjQYY5YBv2GwteGMTeZAP52bU5MjN6dO5ZhzTUrHLCKfAL4MXGWMGZiguo2X0/09Pw9cM641Gn9jHXMpsAT4nYjsBf4M2JTFHaNj/o6NMceT/i3/K7DibD90Mgd6Pt6cOpVjzjVjHrOInA88hRXmRzNQx3RL5ZjnJ63+P0DrBNZvPIx6zMaYgDGm2hjTYIxpwOorucoYk633qUzldzwjafUqrHs2n51M9waP0VN8BbAbq7f4y/a2h7F+0QBFwE+ANmALMDfTdZ6AY16J1R7Xi/XXyM5M13kCjvk14Aiw3X5synSdJ+CYHwN22se7GVic6TqP9zEPK/s7sniUS4q/4/9j/47ftn/HHzrbz9RL/5VSKkdM5iYXpZRSp0EDXSmlcoQGulJK5QgNdKWUyhEa6EoplSM00JVSKkdooCulVI74/wGxk/iGetKWXgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.05\n",
        "cm1 = confusion_matrix(y_train_true, df_train_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U2tkFebL_VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12ec0ed-7c97-47b3-a6ef-92d5a2a26e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.904027846842367\n",
            "Sensitivity:  1.0\n",
            "Specificity:  0.8880324879827615\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_train_pred[df_train_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_train_pred[i] == 4\n",
        "y_train_pred2 = np.where(condition, df_train_pred[i], np.argmax(y_train_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVl6dWlTDLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae693260-994a-4aa5-c01e-52bf95107a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8957164168501811\n",
            "Balanced accuracy:  0.8957164168501812\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_train, axis=1), y_train_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_train, axis=1), y_train_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqvYutTKRhR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a8fda1-3bc0-4085-ab2b-3c545514dfd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1902    5    8    1   95    0    0]\n",
            " [   5 1910    5    0   91    0    0]\n",
            " [  16   14 1489    1  478   13    0]\n",
            " [   0    0    0 2011    0    0    0]\n",
            " [   0    0    0    0 2011    0    0]\n",
            " [   3   16   23    3  685 1277    4]\n",
            " [   0    0    0    0    2    0 2009]]\n"
          ]
        }
      ],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_train, axis=1), y_train_pred2)\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtvW3YeaLlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "9a27a770-16d4-44f7-cef6-d8e13a107e1f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "#labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "#f = plt.figure(figsize=(15, 6))\n",
        "#s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "#s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']\n",
        "#df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60LYAT7VsNOZ",
        "outputId": "a88e6b30-af1d-4dc5-a3ee-7b970fad4d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.asarray(df_test['image_px'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = res50.predict(X_test)"
      ],
      "metadata": {
        "id": "KeDTXdaMLmyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIX0AmEFNv3Y",
        "outputId": "c2b3ca26-3d59-4c4d-c7dc-9f0273a5c415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_pred2 (1512, 7)\n"
          ]
        }
      ],
      "source": [
        "# predicting\n",
        "#CHANGE THE MODEL IF NECESSARY\n",
        "Y_pred2 = best_model.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_Oversampling_featuremaps.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3P7IjyLuZGY"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = 0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2IncA-_o_n5w",
        "outputId": "6db08704-addd-42d9-9371-4d805a2db101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Text(0, 0, 'DF'),\n",
              " Text(0, 0, 'VASC'),\n",
              " Text(0, 0, 'AKIEC'),\n",
              " Text(0, 0, 'BCC'),\n",
              " Text(0, 0, 'BKL'),\n",
              " Text(0, 0, 'MEL'),\n",
              " Text(0, 0, 'NV')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "#labels = sorted(df_train['Labels'].unique())\n",
        "#for label in range(7):\n",
        "#    plot_images_per_label(y_train, 3, (12,9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(WK+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False), # 8\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),#14\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out = (H_in1)*stride[0]  2padding[0] + dilation[0](kernel_size[0]1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4), #10\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4), #13\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 4),# 16\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving..')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_enc.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_dec.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/'\n",
        "\n",
        "  path_enc = modpth + '/bst_enc.pth'\n",
        "  path_dec = modpth + '/bst_dec.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6qneWL_Bs2U",
        "outputId": "cc7899de-f169-4850-dbe2-44ffb5a994d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data:  (11261, 224, 224, 3)\n",
            "Remaining Data:  (2816, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3K908bbiYwbS",
        "RcRGeofw-8tK",
        "cNBXx28B9yGu",
        "0jrJ33lUDkCM",
        "B2PgksTFkOAq"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}