{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Skin-Cancer-Diagnosis/blob/main/Skin_Cancer_Diagnosis_using_ISIC_2018_Dataset_SMOTE_Dev-split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUusDE1Z9TNb"
      },
      "source": [
        "Prepare the dataset. \n",
        "Currently, we use skin cancer ISIC dataset from Kaggle https://www.kaggle.com/datasets/nodoubttome/skin-cancer9-classesisic\n",
        "\n",
        "Tutorial for how to load Kaggle dataset can be found in https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "13b5a9ee-43ac-4718-f4fa-3136fbb8ba2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR2MJBYq-oiB",
        "outputId": "faa6b904-e49c-42dd-f270-e04019d99de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "!pip install imbalanced-learn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 224\n",
        "IMAGE_H = 224\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "\n",
        "#Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2), \n",
        "  layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3)),\n",
        "  layers.experimental.preprocessing.RandomTranslation(0.3, 0.3, fill_mode='reflect', interpolation='bilinear',)\n",
        "])\n",
        "\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_no.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_no.h5'\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=10, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=30,monitor='val_balanced_acc')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images):\n",
        "  input_images = input_images.astype('float32')\n",
        "  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "\t# load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "  X_train = preprocess_image_input(X_train)\n",
        "  X_val = preprocess_image_input(X_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def balanced_acc(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    \n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    return balanced_acc\n",
        "\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "def define_model_resnet():\n",
        "  input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "  #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  x = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)(input_tensor, training=False)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tplt.subplot(211)\n",
        "\tplt.title('Cross Entropy Loss')\n",
        "\tplt.plot(history.history['loss'], color='blue', label='train')\n",
        "\tplt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tplt.subplot(212)\n",
        "\tplt.title('Classification Accuracy')\n",
        "\tplt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tplt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\tplt.close()\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train)\n",
        "  X_val = preprocess_image_input(X_val)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val, df_train, df_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train)\n",
        "  X_val = preprocess_image_input(X_val)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, IMAGE_W * IMAGE_H * 3)), y)\n",
        "  X_resampled = X_resampled.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3P7IjyLuZGY"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = 0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2IncA-_o_n5w",
        "outputId": "6db08704-addd-42d9-9371-4d805a2db101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Text(0, 0, 'DF'),\n",
              " Text(0, 0, 'VASC'),\n",
              " Text(0, 0, 'AKIEC'),\n",
              " Text(0, 0, 'BCC'),\n",
              " Text(0, 0, 'BKL'),\n",
              " Text(0, 0, 'MEL'),\n",
              " Text(0, 0, 'NV')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "#labels = sorted(df_train['Labels'].unique())\n",
        "#for label in range(7):\n",
        "#    plot_images_per_label(y_train, 3, (12,9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(W−K+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False), # 8\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),#14\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out ​= (H_in​−1)*stride[0] − 2×padding[0] + dilation[0]×(kernel_size[0]−1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4), #10\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4), #13\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 4),# 16\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving..')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_enc.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_dec.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/'\n",
        "\n",
        "  path_enc = modpth + '/bst_enc.pth'\n",
        "  path_dec = modpth + '/bst_dec.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "e6qneWL_Bs2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "701f956e-871c-49f2-a88d-08d5ae5a9221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data:  (11261, 224, 224, 3)\n",
            "Remaining Data:  (2816, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bw4C7Fwwxad"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_cifar10_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9QM00erNGU32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d3559f-ba09-4b4a-9567-193afd4536fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 224, 224, 3)\n",
            "(5321, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "X_train, y_train, X_val, y_val, df_train, df_val = load_isic2018_dataset(train_under_frac = 0.7)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xArGWuciBt_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3575e22-57e9-4572-8d75-cae2c4e4e739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 224, 224, 3)\n",
            "(14077, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train, True, 3)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpueuzs7ZBw9"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val= reset_dataset(df_train, df_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8eRZiucdYnP"
      },
      "outputs": [],
      "source": [
        "#USe TF.data\n",
        "training_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "validation_data = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "\n",
        "autotune = tf.data.AUTOTUNE\n",
        "train_data_batches = training_data.shuffle(buffer_size=40000).batch(BATCH_SIZE).prefetch(buffer_size=autotune)\n",
        "valid_data_batches = validation_data.shuffle(buffer_size=10000).batch(BATCH_SIZE).prefetch(buffer_size=autotune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAMBgWqIsAAB",
        "outputId": "f48bee2f-dd46-4034-8073-f143a1c31b5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11261, 224, 224, 3)\n",
            "(11261, 7)\n",
            "(2816, 224, 224, 3)\n",
            "(2816, 7)\n",
            "Counter train data:  Counter({4: 1609, 2: 1609, 5: 1609, 0: 1609, 6: 1609, 3: 1608, 1: 1608})\n",
            "Counter val data:  Counter({3: 403, 1: 403, 6: 402, 4: 402, 5: 402, 0: 402, 2: 402})\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vIygrW81Ln4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54a73b4-e27f-457c-803f-39441ead42c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 1.2255 - accuracy: 0.5397 - balanced_acc: 0.5397\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.68374, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 90s 411ms/step - loss: 1.2255 - accuracy: 0.5397 - balanced_acc: 0.5397 - val_loss: 0.8744 - val_accuracy: 0.6836 - val_balanced_acc: 0.6837 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.7319 - accuracy: 0.7300 - balanced_acc: 0.7300\n",
            "Epoch 2: val_balanced_acc improved from 0.68374 to 0.74459, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 67s 379ms/step - loss: 0.7319 - accuracy: 0.7300 - balanced_acc: 0.7300 - val_loss: 0.6854 - val_accuracy: 0.7486 - val_balanced_acc: 0.7446 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.7913 - balanced_acc: 0.7909\n",
            "Epoch 3: val_balanced_acc improved from 0.74459 to 0.78629, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 378ms/step - loss: 0.5655 - accuracy: 0.7913 - balanced_acc: 0.7909 - val_loss: 0.5719 - val_accuracy: 0.7873 - val_balanced_acc: 0.7863 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.8335 - balanced_acc: 0.8352\n",
            "Epoch 4: val_balanced_acc improved from 0.78629 to 0.78651, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 378ms/step - loss: 0.4598 - accuracy: 0.8335 - balanced_acc: 0.8352 - val_loss: 0.5618 - val_accuracy: 0.7901 - val_balanced_acc: 0.7865 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8609 - balanced_acc: 0.8613\n",
            "Epoch 5: val_balanced_acc improved from 0.78651 to 0.83200, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 380ms/step - loss: 0.3834 - accuracy: 0.8609 - balanced_acc: 0.8613 - val_loss: 0.4648 - val_accuracy: 0.8327 - val_balanced_acc: 0.8320 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.3338 - accuracy: 0.8844 - balanced_acc: 0.8849\n",
            "Epoch 6: val_balanced_acc improved from 0.83200 to 0.85441, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 379ms/step - loss: 0.3338 - accuracy: 0.8844 - balanced_acc: 0.8849 - val_loss: 0.4006 - val_accuracy: 0.8558 - val_balanced_acc: 0.8544 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.2639 - accuracy: 0.9040 - balanced_acc: 0.9041\n",
            "Epoch 7: val_balanced_acc improved from 0.85441 to 0.88139, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 377ms/step - loss: 0.2639 - accuracy: 0.9040 - balanced_acc: 0.9041 - val_loss: 0.3250 - val_accuracy: 0.8835 - val_balanced_acc: 0.8814 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 0.9124 - balanced_acc: 0.9128\n",
            "Epoch 8: val_balanced_acc did not improve from 0.88139\n",
            "175/175 [==============================] - 65s 370ms/step - loss: 0.2497 - accuracy: 0.9124 - balanced_acc: 0.9128 - val_loss: 0.3163 - val_accuracy: 0.8842 - val_balanced_acc: 0.8805 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.2085 - accuracy: 0.9276 - balanced_acc: 0.9266\n",
            "Epoch 9: val_balanced_acc did not improve from 0.88139\n",
            "175/175 [==============================] - 64s 368ms/step - loss: 0.2085 - accuracy: 0.9276 - balanced_acc: 0.9266 - val_loss: 0.3230 - val_accuracy: 0.8828 - val_balanced_acc: 0.8806 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.9470 - balanced_acc: 0.9467\n",
            "Epoch 10: val_balanced_acc did not improve from 0.88139\n",
            "175/175 [==============================] - 64s 368ms/step - loss: 0.1545 - accuracy: 0.9470 - balanced_acc: 0.9467 - val_loss: 0.3238 - val_accuracy: 0.8789 - val_balanced_acc: 0.8768 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9513 - balanced_acc: 0.9507\n",
            "Epoch 11: val_balanced_acc improved from 0.88139 to 0.89116, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 378ms/step - loss: 0.1462 - accuracy: 0.9513 - balanced_acc: 0.9507 - val_loss: 0.2913 - val_accuracy: 0.8928 - val_balanced_acc: 0.8912 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9552 - balanced_acc: 0.9548\n",
            "Epoch 12: val_balanced_acc did not improve from 0.89116\n",
            "175/175 [==============================] - 64s 368ms/step - loss: 0.1379 - accuracy: 0.9552 - balanced_acc: 0.9548 - val_loss: 0.5378 - val_accuracy: 0.8011 - val_balanced_acc: 0.7978 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9660 - balanced_acc: 0.9648\n",
            "Epoch 13: val_balanced_acc did not improve from 0.89116\n",
            "175/175 [==============================] - 65s 369ms/step - loss: 0.1035 - accuracy: 0.9660 - balanced_acc: 0.9648 - val_loss: 0.3262 - val_accuracy: 0.8828 - val_balanced_acc: 0.8817 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9701 - balanced_acc: 0.9695\n",
            "Epoch 14: val_balanced_acc improved from 0.89116 to 0.90357, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 377ms/step - loss: 0.1060 - accuracy: 0.9701 - balanced_acc: 0.9695 - val_loss: 0.2618 - val_accuracy: 0.9070 - val_balanced_acc: 0.9036 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9458 - balanced_acc: 0.9456\n",
            "Epoch 15: val_balanced_acc did not improve from 0.90357\n",
            "175/175 [==============================] - 64s 368ms/step - loss: 0.1765 - accuracy: 0.9458 - balanced_acc: 0.9456 - val_loss: 0.2823 - val_accuracy: 0.9045 - val_balanced_acc: 0.9029 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9856 - balanced_acc: 0.9851\n",
            "Epoch 16: val_balanced_acc improved from 0.90357 to 0.91911, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 378ms/step - loss: 0.0544 - accuracy: 0.9856 - balanced_acc: 0.9851 - val_loss: 0.2544 - val_accuracy: 0.9208 - val_balanced_acc: 0.9191 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9845 - balanced_acc: 0.9848\n",
            "Epoch 17: val_balanced_acc did not improve from 0.91911\n",
            "175/175 [==============================] - 64s 368ms/step - loss: 0.0563 - accuracy: 0.9845 - balanced_acc: 0.9848 - val_loss: 0.2375 - val_accuracy: 0.9183 - val_balanced_acc: 0.9183 - lr: 0.0010\n",
            "Epoch 18/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9963 - balanced_acc: 0.9966\n",
            "Epoch 18: val_balanced_acc improved from 0.91911 to 0.92967, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 377ms/step - loss: 0.0234 - accuracy: 0.9963 - balanced_acc: 0.9966 - val_loss: 0.2289 - val_accuracy: 0.9308 - val_balanced_acc: 0.9297 - lr: 0.0010\n",
            "Epoch 19/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9513 - balanced_acc: 0.9505\n",
            "Epoch 19: val_balanced_acc did not improve from 0.92967\n",
            "175/175 [==============================] - 65s 369ms/step - loss: 0.1688 - accuracy: 0.9513 - balanced_acc: 0.9505 - val_loss: 0.2286 - val_accuracy: 0.9233 - val_balanced_acc: 0.9217 - lr: 0.0010\n",
            "Epoch 20/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9935 - balanced_acc: 0.9938\n",
            "Epoch 20: val_balanced_acc did not improve from 0.92967\n",
            "175/175 [==============================] - 65s 369ms/step - loss: 0.0277 - accuracy: 0.9935 - balanced_acc: 0.9938 - val_loss: 0.2802 - val_accuracy: 0.9183 - val_balanced_acc: 0.9157 - lr: 0.0010\n",
            "Epoch 21/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9973 - balanced_acc: 0.9974\n",
            "Epoch 21: val_balanced_acc did not improve from 0.92967\n",
            "175/175 [==============================] - 65s 369ms/step - loss: 0.0157 - accuracy: 0.9973 - balanced_acc: 0.9974 - val_loss: 0.2501 - val_accuracy: 0.9283 - val_balanced_acc: 0.9282 - lr: 0.0010\n",
            "Epoch 22/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9999 - balanced_acc: 0.9999\n",
            "Epoch 22: val_balanced_acc improved from 0.92967 to 0.93196, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 379ms/step - loss: 0.0063 - accuracy: 0.9999 - balanced_acc: 0.9999 - val_loss: 0.2431 - val_accuracy: 0.9332 - val_balanced_acc: 0.9320 - lr: 0.0010\n",
            "Epoch 23/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9998 - balanced_acc: 0.9997\n",
            "Epoch 23: val_balanced_acc improved from 0.93196 to 0.93279, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 379ms/step - loss: 0.0046 - accuracy: 0.9998 - balanced_acc: 0.9997 - val_loss: 0.2488 - val_accuracy: 0.9343 - val_balanced_acc: 0.9328 - lr: 0.0010\n",
            "Epoch 24/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 24: val_balanced_acc did not improve from 0.93279\n",
            "175/175 [==============================] - 65s 370ms/step - loss: 0.0031 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9322 - val_balanced_acc: 0.9312 - lr: 0.0010\n",
            "Epoch 25/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 25: val_balanced_acc improved from 0.93279 to 0.93417, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "175/175 [==============================] - 66s 379ms/step - loss: 0.0024 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9354 - val_balanced_acc: 0.9342 - lr: 0.0010\n",
            "Epoch 26/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 26: val_balanced_acc did not improve from 0.93417\n",
            "175/175 [==============================] - 64s 369ms/step - loss: 0.0021 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9350 - val_balanced_acc: 0.9332 - lr: 0.0010\n",
            "Epoch 27/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 27: val_balanced_acc did not improve from 0.93417\n",
            "175/175 [==============================] - 65s 369ms/step - loss: 0.0017 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9325 - val_balanced_acc: 0.9312 - lr: 0.0010\n",
            "Epoch 28/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 28: val_balanced_acc did not improve from 0.93417\n",
            "175/175 [==============================] - 65s 370ms/step - loss: 0.0015 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9350 - val_balanced_acc: 0.9339 - lr: 0.0010\n",
            "Epoch 29/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 29: val_balanced_acc did not improve from 0.93417\n",
            "175/175 [==============================] - 65s 369ms/step - loss: 0.0013 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9339 - val_balanced_acc: 0.9322 - lr: 0.0010\n",
            "Epoch 30/30\n",
            "175/175 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 30: val_balanced_acc did not improve from 0.93417\n",
            "175/175 [==============================] - 65s 369ms/step - loss: 0.0012 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9332 - val_balanced_acc: 0.9320 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "model = define_model_resnet()\n",
        "hst = model.fit(X_train, y_train, epochs=30, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwwLiXUSG0IZ"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "#hst = model.fit(train_data_batches,\n",
        "#                    epochs = EPOCHS, validation_data = valid_data_batches,      \n",
        "                    #steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "#                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vXnW3lmCgln3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e89456f9-1e61-40b6-9148-0652f163382c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate"
      ],
      "metadata": {
        "id": "icgjmi-4UIT-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SPz8NH1Oylv9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lS3ewyxO_anU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a3aec61-3158-4488-9882-322daf688363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.9807299529349081\n",
            "balanced accuracy on training 0.9807333747669359\n",
            "accuracy on validation 0.9382102272727273\n",
            "balanced accuracy on validation 0.938176011117754\n",
            "Score on val data:  (0.937638914211572, 0.938176011117754, 0.9377399812176882, None)\n"
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3IyWjdGG4Xq"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_val_pred = pd.DataFrame(y_val_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdyCbloQyWTC"
      },
      "outputs": [],
      "source": [
        "numbers = [float(x)/20 for x in range(11)]\n",
        "\n",
        "for i in numbers:\n",
        "    df_val_pred[i]= df_val_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_val_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_val_true= [1 if x == 4 else 0 for x in np.argmax(y_val, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in num:\n",
        "    cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31LSzov1tCt"
      },
      "outputs": [],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.05\n",
        "cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U2tkFebL_VC"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_val_pred[df_val_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_val_pred[i] == 4\n",
        "y_val_pred2 = np.where(condition, df_val_pred[i], np.argmax(y_val_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVl6dWlTDLo"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqvYutTKRhR_"
      },
      "outputs": [],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), y_val_pred2)\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtvW3YeaLlC"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "Ey-1yjWGeKs7",
        "outputId": "b27447c6-bd65-4449-c265-d68ee8b0f0df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Text(0, 0, 'AKIEC'),\n",
              " Text(0, 0, 'BCC'),\n",
              " Text(0, 0, 'BKL'),\n",
              " Text(0, 0, 'DF'),\n",
              " Text(0, 0, 'MEL'),\n",
              " Text(0, 0, 'NV'),\n",
              " Text(0, 0, 'VASC')]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_val.value_counts().sort_index()\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']\n",
        "#df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60LYAT7VsNOZ"
      },
      "outputs": [],
      "source": [
        "X_test = np.asarray(df_test['image_px'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIX0AmEFNv3Y"
      },
      "outputs": [],
      "source": [
        "# predicting\n",
        "Y_pred2 = best_model.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_SMOTEOversampling_cut-off_val-split.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "E_x4c0_DTkaa",
        "RcRGeofw-8tK",
        "cNBXx28B9yGu",
        "B2PgksTFkOAq",
        "3K908bbiYwbS"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}